[
  {
    "task_id": 10000,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For products whose {{filter_key}} is {{condition}}, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and {{filter_key}}. Note that the filtering of the {{filter_key}} might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "intent": "For products whose color is black, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and color. Note that the filtering of the color might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "required_obs": "any",
    "type_main": "others",
    "type_sub": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute set and {{filter_key}}, check 'X records found' at the top. Note that color should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "filter_key": "color",
      "condition": "black",
      "answer": "tops: 170, bottoms: 94, others: 1"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "tops: 170, bottoms: 94, others: 1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "tops: 170, bottoms: 94, others: 1"
    }
  },
  {
    "task_id": 10001,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For products whose {{filter_key}} is {{condition}}, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and {{filter_key}}. Note that the filtering of the {{filter_key}} might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "intent": "For products whose color is blue, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and color. Note that the filtering of the color might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "required_obs": "any",
    "type_main": "others",
    "type_sub": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute set and {{filter_key}}, check 'X records found' at the top. Note that color should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "filter_key": "color",
      "condition": "blue",
      "answer": "tops: 233, bottoms: 106, others: 3"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "tops: 233, bottoms: 106, others: 3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "tops: 233, bottoms: 106, others: 3"
    }
  },
  {
    "task_id": 10002,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For products whose {{filter_key}} is {{condition}}, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and {{filter_key}}. Note that the filtering of the {{filter_key}} might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "intent": "For products whose color is red, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and color. Note that the filtering of the color might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "required_obs": "any",
    "type_main": "others",
    "type_sub": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute set and {{filter_key}}, check 'X records found' at the top. Note that color should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "filter_key": "color",
      "condition": "red",
      "answer": "tops: 193, bottoms: 56, others: 3"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "tops: 193, bottoms: 56, others: 3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "tops: 193, bottoms: 56, others: 3"
    }
  },
  {
    "task_id": 10003,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For products whose {{filter_key}} is {{condition}}, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and {{filter_key}}. Note that the filtering of the {{filter_key}} might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "intent": "For products whose price is below 30, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and price. Note that the filtering of the price might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "required_obs": "any",
    "type_main": "others",
    "type_sub": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute set and {{filter_key}}, check 'X records found' at the top. Note that color should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "filter_key": "price",
      "condition": "below 30",
      "answer": "tops: 432, bottoms: 120, others: 18"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "tops: 432, bottoms: 120, others: 18"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "tops: 432, bottoms: 120, others: 18"
    }
  },
  {
    "task_id": 10004,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For products whose {{filter_key}} is {{condition}}, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and {{filter_key}}. Note that the filtering of the {{filter_key}} might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "intent": "For products whose price is between 30 and 100, count the number of records for tops, bottoms, and the other attributes. There is no need for a filtering except for attribute set and price. Note that the filtering of the price might not be visible by default. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: 'tops: ${number_of_tops}, bottoms: ${number_of_bottoms}, others: ${number_of_others}'.",
    "required_obs": "any",
    "type_main": "others",
    "type_sub": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute set and {{filter_key}}, check 'X records found' at the top. Note that color should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "filter_key": "price",
      "condition": "between 30 and 100",
      "answer": "tops: 1029, bottoms: 412, others: 26"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "tops: 1029, bottoms: 412, others: 26"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "tops: 1029, bottoms: 412, others: 26"
    }
  },
  {
    "task_id": 10010,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between {{period1}} and {{period2}} in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between January and April in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the average of 'Grand Total'. You will get the following numbers... Jan:144.7(=1591.9/11), Feb:132.9(=2125.7/16), Mar:131.6(=1841.8/14), Apr:155.7(=1090.0/7), May:149.2(=1193.6/8), Jun:107.0(=1390.7/13), Jul:142.0(=1278.1/9), Aug:119.3(=954.5/8), Sep:136.2(=1361.7/10), Oct:111.2(=444.8/4), Nov:110.1(=550.7/5), Dec:161.2(=1612.4/10)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "April",
      "checkpoint": "",
      "answer_month": "April",
      "answer_amount": "156"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "April, 156"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "April, 156"
    }
  },
  {
    "task_id": 10011,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between {{period1}} and {{period2}} in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between May and August in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the average of 'Grand Total'. You will get the following numbers... Jan:144.7(=1591.9/11), Feb:132.9(=2125.7/16), Mar:131.6(=1841.8/14), Apr:155.7(=1090.0/7), May:149.2(=1193.6/8), Jun:107.0(=1390.7/13), Jul:142.0(=1278.1/9), Aug:119.3(=954.5/8), Sep:136.2(=1361.7/10), Oct:111.2(=444.8/4), Nov:110.1(=550.7/5), Dec:161.2(=1612.4/10)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "May",
      "period2": "August",
      "checkpoint": "",
      "answer_month": "May",
      "answer_amount": "149"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "May, 149"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "May, 149"
    }
  },
  {
    "task_id": 10012,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between {{period1}} and {{period2}} in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between September and December in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the average of 'Grand Total'. You will get the following numbers... Jan:144.7(=1591.9/11), Feb:132.9(=2125.7/16), Mar:131.6(=1841.8/14), Apr:155.7(=1090.0/7), May:149.2(=1193.6/8), Jun:107.0(=1390.7/13), Jul:142.0(=1278.1/9), Aug:119.3(=954.5/8), Sep:136.2(=1361.7/10), Oct:111.2(=444.8/4), Nov:110.1(=550.7/5), Dec:161.2(=1612.4/10)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "September",
      "period2": "December",
      "checkpoint": "",
      "answer_month": "December",
      "answer_amount": "161"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "December, 161"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "December, 161"
    }
  },
  {
    "task_id": 10013,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between {{period1}} and {{period2}} in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between January and June in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the average of 'Grand Total'. You will get the following numbers... Jan:144.7(=1591.9/11), Feb:132.9(=2125.7/16), Mar:131.6(=1841.8/14), Apr:155.7(=1090.0/7), May:149.2(=1193.6/8), Jun:107.0(=1390.7/13), Jul:142.0(=1278.1/9), Aug:119.3(=954.5/8), Sep:136.2(=1361.7/10), Oct:111.2(=444.8/4), Nov:110.1(=550.7/5), Dec:161.2(=1612.4/10)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "June",
      "checkpoint": "",
      "answer_month": "April",
      "answer_amount": "156"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "April, 156"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "April, 156"
    }
  },
  {
    "task_id": 10014,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between {{period1}} and {{period2}} in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Considering only transactions with a status of 'Complete', which month has the highest average purchase amount between January and December in 2022? Final answer should be 'month, amount' (separated by a comma and a space, without '$') without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the average of 'Grand Total'. You will get the following numbers... Jan:144.7(=1591.9/11), Feb:132.9(=2125.7/16), Mar:131.6(=1841.8/14), Apr:155.7(=1090.0/7), May:149.2(=1193.6/8), Jun:107.0(=1390.7/13), Jul:142.0(=1278.1/9), Aug:119.3(=954.5/8), Sep:136.2(=1361.7/10), Oct:111.2(=444.8/4), Nov:110.1(=550.7/5), Dec:161.2(=1612.4/10)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "December",
      "checkpoint": "",
      "answer_month": "December",
      "answer_amount": "161"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "December, 161"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "December, 161"
    }
  },
  {
    "task_id": 10020,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Who is the first, tenth, and last person in alphabetical order among those living in {{state1}}, {{state2}}, {{state3}} or {{state4}}? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "intent": "Who is the first, tenth, and last person in alphabetical order among those living in California, Florida, Illinois or New York? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given states, and memorize the name for each state. Then sort the names in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "state1": "California",
      "state2": "Florida",
      "state3": "Illinois",
      "state4": "New York",
      "checkpoint": "Alex Johnson, Alex Martin, Alexander Thomas, Ava Brown, Emily Wilson, Emma Lopez, Isabella Santos, James Kim, Jane Doe, Jane Doe, Jane Smith, Jennifer White, Jessica Wong, John Doe, John Lee, Julia Williams, Julie Nguyen, Kate Jones, Lily Potter, Mary Martin, Maxwell Baker, Michael Nguyen, Roberto Lopez, Sam Wilson, Samantha Jones, Samantha Wu, Sarah Miller, Sophie Taylor",
      "answer_first": "Alex Johnson",
      "answer_tenth": "Jane Doe",
      "answer_last": "Sophie Taylor"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "(1) Alex Johnson (2) Jane Doe (3) Sophie Taylor"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Alex Johnson (2) Jane Doe (3) Sophie Taylor"
    }
  },
  {
    "task_id": 10021,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Who is the first, tenth, and last person in alphabetical order among those living in {{state1}}, {{state2}}, {{state3}} or {{state4}}? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "intent": "Who is the first, tenth, and last person in alphabetical order among those living in California, Florida, New York or Texas? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given states, and memorize the name for each state. Then sort the names in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "state1": "California",
      "state2": "Florida",
      "state3": "New York",
      "state4": "Texas",
      "checkpoint": "Alex Johnson, Alex Martin, Alexander Thomas, Anna Nguyen, Ava Brown, Bob Johnson, Bob Jones, David Smith, Emma Davis, Emma Lopez, Ethan Garcia, Isabella Santos, James Baker, Jane Doe, Jane Doe, Jane Smith, Jennifer White, John Doe, John Smith, Julia Williams, Julie Nguyen, Kate Jones, Lisa Green, Lisa Kim, Mary Martin, Olivia Lee, Roberto Lopez, Sam Wilson, Samantha Jones, Samantha Nguyen, Samantha Wu, Sarah Miller, Sophie Taylor",
      "answer_first": "Alex Johnson",
      "answer_tenth": "Emma Lopez",
      "answer_last": "Sophie Taylor"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "(1) Alex Johnson (2) Emma Lopez (3) Sophie Taylor"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Alex Johnson (2) Emma Lopez (3) Sophie Taylor"
    }
  },
  {
    "task_id": 10022,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Who is the first, tenth, and last person in alphabetical order among those living in {{state1}}, {{state2}}, {{state3}} or {{state4}}? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "intent": "Who is the first, tenth, and last person in alphabetical order among those living in Florida, Illinois, New York or Texas? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given states, and memorize the name for each state. Then sort the names in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "state1": "Florida",
      "state2": "Illinois",
      "state3": "New York",
      "state4": "Texas",
      "checkpoint": "Alex Martin, Anna Nguyen, Bob Johnson, Bob Jones, David Smith, Emily Wilson, Emma Davis, Ethan Garcia, Isabella Santos, James Baker, James Kim, Jane Doe, Jane Doe, Jessica Wong, John Doe, John Lee, John Smith, Julia Williams, Kate Jones, Lily Potter, Lisa Green, Lisa Kim, Mary Martin, Maxwell Baker, Michael Nguyen, Olivia Lee, Roberto Lopez, Samantha Jones, Samantha Nguyen, Samantha Wu, Sophie Taylor",
      "answer_first": "Alex Martin",
      "answer_tenth": "James Baker",
      "answer_last": "Sophie Taylor"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "(1) Alex Martin (2) James Baker (3) Sophie Taylor"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Alex Martin (2) James Baker (3) Sophie Taylor"
    }
  },
  {
    "task_id": 10023,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Who is the first, tenth, and last person in alphabetical order among those living in {{state1}}, {{state2}}, {{state3}} or {{state4}}? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "intent": "Who is the first, tenth, and last person in alphabetical order among those living in Illinois, New York, Texas or Washington? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given states, and memorize the name for each state. Then sort the names in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "state1": "Illinois",
      "state2": "New York",
      "state3": "Texas",
      "state4": "Washington",
      "checkpoint": "Adam Garcia, Alex Martin, Anna Nguyen, Bob Johnson, Bob Jones, David Smith, Emily Wilson, Emma Davis, Ethan Garcia, James Baker, James Kim, Jane Doe, Jane Smith, Jessica Chang, Jessica Nguyen, Jessica Wong, John Doe, John Lee, John Smith, Julia Williams, Kate Jones, Katie Wong, Lily Potter, Lisa Green, Lisa Kim, Maxwell Baker, Michael Nguyen, Olivia Lee, Roberto Lopez, Samantha Nguyen, William Chang",
      "answer_first": "Adam Garcia",
      "answer_tenth": "James Baker",
      "answer_last": "William Chang"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "(1) Adam Garcia (2) James Baker (3) William Chang"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Adam Garcia (2) James Baker (3) William Chang"
    }
  },
  {
    "task_id": 10024,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Who is the first, tenth, and last person in alphabetical order among those living in {{state1}}, {{state2}}, {{state3}} or {{state4}}? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "intent": "Who is the first, tenth, and last person in alphabetical order among those living in Arizona, Colorado, Massachusetts or New Jersey? There are sometimes multiple people with the same name in different states. In that case, you should consider them as different people. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${first person} (2) ${tenth person} (3) ${last person}'",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given states, and memorize the name for each state. Then sort the names in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "state1": "Arizona",
      "state2": "Colorado",
      "state3": "Massachusetts",
      "state4": "New Jersey",
      "checkpoint": "Adam Garcia, Amanda Kim, David Lee, Emily Chen, Grace Nguyen, Isaac Rodriguez, Jacob Rivera, Jason Miller, Lucy Garcia, Matthew Kim, Natalie Kim, Nathan Chen, Olivia Jackson, Robert Johnson, Sophia Young",
      "answer_first": "Adam Garcia",
      "answer_tenth": "Matthew Kim",
      "answer_last": "Sophia Young"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "(1) Adam Garcia (2) Matthew Kim (3) Sophia Young"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Adam Garcia (2) Matthew Kim (3) Sophia Young"
    }
  },
  {
    "task_id": 10030,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the total amount of canceled records (in monetary terms) for each month from {{period1}} to {{period2}} in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Calculate the total amount of canceled records (in monetary terms) for each month from January to April in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... Jan($637.20,cnt=6), Feb($737.49,cnt=6), Mar($937.91,cnt=9), Apr($1353.30,cnt=12), May($649.70,cnt=7), Jun($1957.50,cnt=15), Jul($720.85,cnt=7), Aug($1568.79,cnt=11), Sep($810.50,cnt=6), Oct($584.75,cnt=5), Nov($1234.70,cnt=9), Dec($519.76,cnt=6)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "April",
      "answer": "April, 1,353"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "April, 1,353"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "April, 1,353"
    }
  },
  {
    "task_id": 10031,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the total amount of canceled records (in monetary terms) for each month from {{period1}} to {{period2}} in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Calculate the total amount of canceled records (in monetary terms) for each month from May to August in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... Jan($637.20,cnt=6), Feb($737.49,cnt=6), Mar($937.91,cnt=9), Apr($1353.30,cnt=12), May($649.70,cnt=7), Jun($1957.50,cnt=15), Jul($720.85,cnt=7), Aug($1568.79,cnt=11), Sep($810.50,cnt=6), Oct($584.75,cnt=5), Nov($1234.70,cnt=9), Dec($519.76,cnt=6)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "May",
      "period2": "August",
      "answer": "June, 1,957 |OR| June, 1,958"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "June, 1,957 |OR| June, 1,958"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "June, 1,957 |OR| June, 1,958"
    }
  },
  {
    "task_id": 10032,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the total amount of canceled records (in monetary terms) for each month from {{period1}} to {{period2}} in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Calculate the total amount of canceled records (in monetary terms) for each month from September to December in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... Jan($637.20,cnt=6), Feb($737.49,cnt=6), Mar($937.91,cnt=9), Apr($1353.30,cnt=12), May($649.70,cnt=7), Jun($1957.50,cnt=15), Jul($720.85,cnt=7), Aug($1568.79,cnt=11), Sep($810.50,cnt=6), Oct($584.75,cnt=5), Nov($1234.70,cnt=9), Dec($519.76,cnt=6)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "September",
      "period2": "December",
      "answer": "November, 1,235"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "November, 1,235"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "November, 1,235"
    }
  },
  {
    "task_id": 10033,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the total amount of canceled records (in monetary terms) for each month from {{period1}} to {{period2}} in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Calculate the total amount of canceled records (in monetary terms) for each month from January to June in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... Jan($637.20,cnt=6), Feb($737.49,cnt=6), Mar($937.91,cnt=9), Apr($1353.30,cnt=12), May($649.70,cnt=7), Jun($1957.50,cnt=15), Jul($720.85,cnt=7), Aug($1568.79,cnt=11), Sep($810.50,cnt=6), Oct($584.75,cnt=5), Nov($1234.70,cnt=9), Dec($519.76,cnt=6)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "June",
      "answer": "June, 1,957 |OR| June, 1,958"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "June, 1,957 |OR| June, 1,958"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "June, 1,957 |OR| June, 1,958"
    }
  },
  {
    "task_id": 10034,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the total amount of canceled records (in monetary terms) for each month from {{period1}} to {{period2}} in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "intent": "Calculate the total amount of canceled records (in monetary terms) for each month from January to December in 2022. Which month has the most cancellations? Final answer should be 'month, amount_of_cancellations' (separated by a comma and a space, without '$', and formatted with a comma as a thousands separator (e.g., April, 12,345)) without reasoning. Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... Jan($637.20,cnt=6), Feb($737.49,cnt=6), Mar($937.91,cnt=9), Apr($1353.30,cnt=12), May($649.70,cnt=7), Jun($1957.50,cnt=15), Jul($720.85,cnt=7), Aug($1568.79,cnt=11), Sep($810.50,cnt=6), Oct($584.75,cnt=5), Nov($1234.70,cnt=9), Dec($519.76,cnt=6)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "December",
      "answer": "June, 1,957 |OR| June, 1,958"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "June, 1,957 |OR| June, 1,958"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "June, 1,957 |OR| June, 1,958"
    }
  },
  {
    "task_id": 10040,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Find the cheapest product for each of {{attribute1}} and {{attribute2}}. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "intent": "Find the cheapest product for each of tops and bottoms. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute, and find the cheapest product. Filter by the name of the found product and calculate the sum of Price * 'Salable Quantity'.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "medium",
      "attribute1": "tops",
      "attribute2": "bottoms",
      "hint": "Since the prices cannot be sorted, filtering is needed to narrow down the results to a manageable number.",
      "checkpoint": "tops:18 (Atlas Fitness Tank, salable=492), bottoms: 20(Arcadio Gym Short, salable=1189) -> 18*492+20*1189=32636",
      "answer": "32636 |OR| 32,636"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "32636 |OR| 32,636"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "32636 |OR| 32,636"
    }
  },
  {
    "task_id": 10041,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Find the cheapest product for each of {{attribute1}} and {{attribute2}}. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "intent": "Find the cheapest product for each of bag and bottoms. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute, and find the cheapest product. Filter by the name of the found product and calculate the sum of Price * 'Salable Quantity'.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "medium",
      "attribute1": "bag",
      "attribute2": "bottoms",
      "hint": "Since the prices cannot be sorted, filtering is needed to narrow down the results to a manageable number.",
      "checkpoint": "bag: 32 (Compete Track Tote, salable=100), bottoms: 20 (Arcadio Gym Short, salable=1189) -> 32*100+20*1189=26980",
      "answer": "26980 |OR| 26,980"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "26980 |OR| 26,980"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "26980 |OR| 26,980"
    }
  },
  {
    "task_id": 10042,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Find the cheapest product for each of {{attribute1}} and {{attribute2}}. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "intent": "Find the cheapest product for each of Gear and bottoms. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute, and find the cheapest product. Filter by the name of the found product and calculate the sum of Price * 'Salable Quantity'.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "medium",
      "attribute1": "Gear",
      "attribute2": "bottoms",
      "hint": "Since the prices cannot be sorted, filtering is needed to narrow down the results to a manageable number.",
      "checkpoint": "Gear: 5 (Sprite Foam Yoga Brick, salable=94), bottoms: 20 (Arcadio Gym Short, salable=1189) -> 5*94+20*1189=24250",
      "answer": "24250 |OR| 24,250"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "24250 |OR| 24,250"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "24250 |OR| 24,250"
    }
  },
  {
    "task_id": 10043,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Find the cheapest product for each of {{attribute1}} and {{attribute2}}. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "intent": "Find the cheapest product for each of tops and Gear. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute, and find the cheapest product. Filter by the name of the found product and calculate the sum of Price * 'Salable Quantity'.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "medium",
      "attribute1": "tops",
      "attribute2": "Gear",
      "hint": "Since the prices cannot be sorted, filtering is needed to narrow down the results to a manageable number.",
      "checkpoint": "tops: 18 (Atlas Fitness Tank, salable=492), Gear: 5 (Sprite Foam Yoga Brick, salable=94) -> 18*492+5*94=9326",
      "answer": "9326 |OR| 9,326"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "9326 |OR| 9,326"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "9326 |OR| 9,326"
    }
  },
  {
    "task_id": 10044,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Find the cheapest product for each of {{attribute1}} and {{attribute2}}. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "intent": "Find the cheapest product for each of bag and Gear. If there are multiple products with the same price for the same attribute, choose the first one in the alphabetical order. If we sell all (every colors and sizes) of the salable quantity by the specified price for both of the products, how much money do we make? Final answer should be '{amount}' without reasoning, without '$', and formatted with a comma as a thousands separator (e.g., 12,345). Round the purchase amount to the nearest integer.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Go to 'catalog' -> 'products', filter by attribute, and find the cheapest product. Filter by the name of the found product and calculate the sum of Price * 'Salable Quantity'.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "medium",
      "attribute1": "bag",
      "attribute2": "Gear",
      "hint": "Since the prices cannot be sorted, some heuristic filtering is needed to narrow down the results to a manageable number.",
      "checkpoint": "bag: 32 (Compete Track Tote, salable=100), Gear: 5 (Sprite Foam Yoga Brick, salable=94) -> 32*100+5*94=3670",
      "answer": "3670 |OR| 3,670"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "3670 |OR| 3,670"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "3670 |OR| 3,670"
    }
  },
  {
    "task_id": 10050,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between {{period1}} and {{period2}} in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between {{period1}} and {{period2}}). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "intent": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between January and March in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between January and March). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Sales' -> 'Orders', filter by status and month for each month, and calculate the sum of 'Grand Total' for each person. For each person obtained, calculate the total amount without filtering by month. You will get the following result: Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "March",
      "checkpoint": "Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9)",
      "answer": "Grace Nguyen(1,070), Samantha Jones(964), Michael Nguyen(893)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Grace Nguyen(1,070), Samantha Jones(964), Michael Nguyen(893)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Grace Nguyen(1,070), Samantha Jones(964), Michael Nguyen(893)"
    }
  },
  {
    "task_id": 10051,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between {{period1}} and {{period2}} in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between {{period1}} and {{period2}}). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "intent": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between January and April in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between January and April). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Sales' -> 'Orders', filter by status and month for each month, and calculate the sum of 'Grand Total' for each person. For each person obtained, calculate the total amount without filtering by month. You will get the following result: Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "April",
      "checkpoint": "Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1)",
      "answer": "Grace Nguyen(1,070), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Grace Nguyen(1,070), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Grace Nguyen(1,070), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
    }
  },
  {
    "task_id": 10052,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between {{period1}} and {{period2}} in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between {{period1}} and {{period2}}). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "intent": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between January and June in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between January and June). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Sales' -> 'Orders', filter by status and month for each month, and calculate the sum of 'Grand Total' for each person. For each person obtained, calculate the total amount without filtering by month. You will get the following result: Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "June",
      "checkpoint": "Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8),",
      "answer": "Grace Nguyen(1,070), Ava Brown(1,069), Jennifer White(988), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Grace Nguyen(1,070), Ava Brown(1,069), Jennifer White(988), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Grace Nguyen(1,070), Ava Brown(1,069), Jennifer White(988), Samantha Jones(964), Lucy Garcia(899), Michael Nguyen(893)"
    }
  },
  {
    "task_id": 10053,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between {{period1}} and {{period2}} in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between {{period1}} and {{period2}}). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "intent": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between January and September in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between January and September). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Sales' -> 'Orders', filter by status and month for each month, and calculate the sum of 'Grand Total' for each person. For each person obtained, calculate the total amount without filtering by month. You will get the following result: Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "September",
      "checkpoint": "Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2)",
      "answer": "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Lily Potter(682)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Lily Potter(682)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Lily Potter(682)"
    }
  },
  {
    "task_id": 10054,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between {{period1}} and {{period2}} in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between {{period1}} and {{period2}}). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "intent": "Identify the person who placed the largest total purchase amount (in monetary terms) 'for each month' between January and December in 2022. Sort them in descending order by 'total purchase amount across all recorded time periods' (not just between January and December). Consider only transactions with a status of 'Complete' throughout the question. Final answer should be in the following format: '${name1}(${total amount across all period}), ${name2}(${total amount across all period}), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345). If the same person has recorded maximums in more than one month, omit duplicates in the output.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Sales' -> 'Orders', filter by status and month for each month, and calculate the sum of 'Grand Total' for each person. For each person obtained, calculate the total amount without filtering by month. You will get the following result: Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "medium",
      "period1": "January",
      "period2": "December",
      "checkpoint": "Jan(Samantha Jones, sum=964.0), Feb(Michael Nguyen, sum=893.2), Mar(Grace Nguyen, sum=1069.9), Apr(Lucy Garcia, sum=899.1), May(Ava Brown, sum=1068.8), Jun(Jennifer White, sum=987.8), Jul(Jane Smith, sum=998.0), Aug(John Smith, sum=957.8), Sep(Lily Potter, sum=682.2), Oct(Jane Doe, sum=889.9), Nov(Grace Nguyen, sum=1069.9), Dec(Jason Miller, sum=842.4)",
      "answer": "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Jane Doe(890), Jason Miller(842), Lily Potter(682)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Jane Doe(890), Jason Miller(842), Lily Potter(682)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Grace Nguyen(1,070), Ava Brown(1,069), Jane Smith(998), Jennifer White(988), Samantha Jones(964), John Smith(958), Lucy Garcia(899), Michael Nguyen(893), Jane Doe(890), Jason Miller(842), Lily Potter(682)"
    }
  },
  {
    "task_id": 10060,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For each zip code that belongs to {{state}}, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "For each zip code that belongs to California, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Go to 'Customers' -> 'All Customers', filter by state, and memorize the zip codes that appears in the filtered table. Then go to 'Sales' -> 'Orders', filter by status and zip code (you can add the Shipping Address column from 'Columns' with gear icon. There you can type the zip code for filtering), and calculate the sum of 'Grand Total' in the filtered table.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "hard",
      "state": "California",
      "hint": "Zip can be found in 'Customers', but 'edit' -> 'orders' here includes canceled orders, so you have to use 'orders' page. Identify users with the same name by email.",
      "checkpoint": "94602: Sarah Miller(helloworld@yahoo.com, cnt=8, total=$1212.6), total: 1212.6",
      "answer": "94602: 1,213"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "94602: 1,213"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "94602: 1,213"
    }
  },
  {
    "task_id": 10061,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For each zip code that belongs to {{state}}, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "For each zip code that belongs to Illinois, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Go to 'Customers' -> 'All Customers', filter by state, and memorize the zip codes that appears in the filtered table. Then go to 'Sales' -> 'Orders', filter by status and zip code (you can add the Shipping Address column from 'Columns' with gear icon. There you can type the zip code for filtering), and calculate the sum of 'Grand Total' in the filtered table.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "hard",
      "state": "Illinois",
      "hint": "Zip can be found in 'Customers', but 'edit' -> 'orders' here includes canceled orders, so you have to use 'orders' page. Identify users with the same name by email.",
      "checkpoint": "60606: Michael Nguyen(michael.nguyen@yahoo.com, cnt=8, total=$893.2), total: 893.2",
      "answer": "60606: 893"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "60606: 893"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "60606: 893"
    }
  },
  {
    "task_id": 10062,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For each zip code that belongs to {{state}}, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "For each zip code that belongs to Colorado, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Go to 'Customers' -> 'All Customers', filter by state, and memorize the zip codes that appears in the filtered table. Then go to 'Sales' -> 'Orders', filter by status and zip code (you can add the Shipping Address column from 'Columns' with gear icon. There you can type the zip code for filtering), and calculate the sum of 'Grand Total' in the filtered table.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "hard",
      "state": "Colorado",
      "hint": "Zip can be found in 'Customers', but 'edit' -> 'orders' here includes canceled orders, so you have to use 'orders' page. Identify users with the same name by email.",
      "checkpoint": "Lucy Garcia(artsygal123@hotmail.com, cnt=6, total=$899.1), Jason Miller(jason.miller@yahoo.com, cnt=5, total=$842.4), Olivia Jackson(olivia.jackson@gmail.com, cnt=0, total=$0.0), Nathan Chen(nathan.chen@gmail.com, cnt=0, total=$0.0), total: 1741.6",
      "answer": "80202: 1,742"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "80202: 1,742"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "80202: 1,742"
    }
  },
  {
    "task_id": 10063,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For each zip code that belongs to {{state}}, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "For each zip code that belongs to Texas, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Go to 'Customers' -> 'All Customers', filter by state, and memorize the zip codes that appears in the filtered table. Then go to 'Sales' -> 'Orders', filter by status and zip code (you can add the Shipping Address column from 'Columns' with gear icon. There you can type the zip code for filtering), and calculate the sum of 'Grand Total' in the filtered table.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "hard",
      "state": "Texas",
      "hint": "Zip can be found in 'Customers', but 'edit' -> 'orders' here includes canceled orders, so you have to use 'orders' page. Identify users with the same name by email.",
      "checkpoint": "75202: Bob Jones(bbjones@gmail.com, cnt=6, total=$530.0), total: 530.0",
      "answer": "75202: 530"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "75202: 530"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "75202: 530"
    }
  },
  {
    "task_id": 10064,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "For each zip code that belongs to {{state}}, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "For each zip code that belongs to New York, calculate the total completed purchase amount (in monetary terms) by the people living in the zip code. Which zip has the highest purchase amount and how high is it? Final answer should be in the following format: '${zip}: ${purchase_amount}'. Round the purchase amount to the nearest integer just before answering each question. Amounts should be without '$',formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Go to 'Customers' -> 'All Customers', filter by state, and memorize the zip codes that appears in the filtered table. Then go to 'Sales' -> 'Orders', filter by status and zip code (you can add the Shipping Address column from 'Columns' with gear icon. There you can type the zip code for filtering), and calculate the sum of 'Grand Total' in the filtered table.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "hard",
      "state": "New York",
      "hint": "Zip can be found in 'Customers', but 'edit' -> 'orders' here includes canceled orders, so you have to use 'orders' page. Identify users with the same name by email.",
      "checkpoint": "10065: Julia Williams(jla_7781@gmail.com, cnt=2, total=$265.6), total: 265.6, 10001: John Doe(johndoe123@gmail.com, cnt=3, total=$371.0), Alex Martin(alex.martin@gmail.com, cnt=6, total=$733.0), Kate Jones(kate.jones@gmail.com, cnt=0, total=$0.0), Roberto Lopez(roberto.lopez@hotmail.com, cnt=0, total=$0.0), Jane Doe(jane.doe@gmail.com, cnt=0, total=$0.0), total: 1104.0",
      "answer": "10001: 1,104"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "10001: 1,104"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "10001: 1,104"
    }
  },
  {
    "task_id": 10070,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to analyze the total purchase amount (in monetary terms) for each month between {{period1}} and {{period2}} in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "intent": "I want to analyze the total purchase amount (in monetary terms) for each month between January and April in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... COMPLETE: Jan($1592), Feb($2126), Mar($1842), Apr($1090), May($1194), Jun($1391), Jul($1278), Aug($954), Sep($1362), Oct($445), Nov($551), Dec($1612), CANCELED: Jan($637), Feb($737), Mar($938), Apr($1353), May($650), Jun($1958), Jul($721), Aug($1569), Sep($810), Oct($585), Nov($1235), Dec($520) GAP: Jan($955), Feb($1388), Mar($904), Apr($263), May($544), Jun($567), Jul($557), Aug($614), Sep($551), Oct($140), Nov($684), Dec($1093)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "hard",
      "period1": "January",
      "period2": "April",
      "checkpoint": "",
      "answer": "February(1388), January(955), March(904), April(263) |OR| February(1,388), January(955), March(904), April(263)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "February(1388), January(955), March(904), April(263) |OR| February(1,388), January(955), March(904), April(263)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "February(1388), January(955), March(904), April(263) |OR| February(1,388), January(955), March(904), April(263)"
    }
  },
  {
    "task_id": 10071,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to analyze the total purchase amount (in monetary terms) for each month between {{period1}} and {{period2}} in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "intent": "I want to analyze the total purchase amount (in monetary terms) for each month between May and August in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... COMPLETE: Jan($1592), Feb($2126), Mar($1842), Apr($1090), May($1194), Jun($1391), Jul($1278), Aug($954), Sep($1362), Oct($445), Nov($551), Dec($1612), CANCELED: Jan($637), Feb($737), Mar($938), Apr($1353), May($650), Jun($1958), Jul($721), Aug($1569), Sep($810), Oct($585), Nov($1235), Dec($520) GAP: Jan($955), Feb($1388), Mar($904), Apr($263), May($544), Jun($567), Jul($557), Aug($614), Sep($551), Oct($140), Nov($684), Dec($1093)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "hard",
      "period1": "May",
      "period2": "August",
      "checkpoint": "",
      "answer": "August(614), June(567), July(557), May(544)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "August(614), June(567), July(557), May(544)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "August(614), June(567), July(557), May(544)"
    }
  },
  {
    "task_id": 10072,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to analyze the total purchase amount (in monetary terms) for each month between {{period1}} and {{period2}} in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "intent": "I want to analyze the total purchase amount (in monetary terms) for each month between September and December in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... COMPLETE: Jan($1592), Feb($2126), Mar($1842), Apr($1090), May($1194), Jun($1391), Jul($1278), Aug($954), Sep($1362), Oct($445), Nov($551), Dec($1612), CANCELED: Jan($637), Feb($737), Mar($938), Apr($1353), May($650), Jun($1958), Jul($721), Aug($1569), Sep($810), Oct($585), Nov($1235), Dec($520) GAP: Jan($955), Feb($1388), Mar($904), Apr($263), May($544), Jun($567), Jul($557), Aug($614), Sep($551), Oct($140), Nov($684), Dec($1093)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "hard",
      "period1": "September",
      "period2": "December",
      "checkpoint": "",
      "answer": "December(1093), November(684), September(551), October(140) |OR| December(1,093), November(684), September(551), October(140)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "December(1093), November(684), September(551), October(140) |OR| December(1,093), November(684), September(551), October(140)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "December(1093), November(684), September(551), October(140) |OR| December(1,093), November(684), September(551), October(140)"
    }
  },
  {
    "task_id": 10073,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to analyze the total purchase amount (in monetary terms) for each month between {{period1}} and {{period2}} in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "intent": "I want to analyze the total purchase amount (in monetary terms) for each month between January and June in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... COMPLETE: Jan($1592), Feb($2126), Mar($1842), Apr($1090), May($1194), Jun($1391), Jul($1278), Aug($954), Sep($1362), Oct($445), Nov($551), Dec($1612), CANCELED: Jan($637), Feb($737), Mar($938), Apr($1353), May($650), Jun($1958), Jul($721), Aug($1569), Sep($810), Oct($585), Nov($1235), Dec($520) GAP: Jan($955), Feb($1388), Mar($904), Apr($263), May($544), Jun($567), Jul($557), Aug($614), Sep($551), Oct($140), Nov($684), Dec($1093)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "hard",
      "period1": "January",
      "period2": "June",
      "checkpoint": "",
      "answer": "February(1388), January(955), March(904), June(567), May(544), April(263) |OR| February(1,388), January(955), March(904), June(567), May(544), April(263)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "February(1388), January(955), March(904), June(567), May(544), April(263) |OR| February(1,388), January(955), March(904), June(567), May(544), April(263)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "February(1388), January(955), March(904), June(567), May(544), April(263) |OR| February(1,388), January(955), March(904), June(567), May(544), April(263)"
    }
  },
  {
    "task_id": 10074,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to analyze the total purchase amount (in monetary terms) for each month between {{period1}} and {{period2}} in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "intent": "I want to analyze the total purchase amount (in monetary terms) for each month between July and December in 2022. Sort the months in the descending order of absolute difference between complete and canceled purchase amount. Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '${month1}(${absolute gap}), ${month2}(${absolute gap}), ...'. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering the question. Amounts should be without '$' and months should be without year.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'sales' -> 'orders', filter by status and month, and calculate the sum of 'Grand Total'. You will get the following numbers... COMPLETE: Jan($1592), Feb($2126), Mar($1842), Apr($1090), May($1194), Jun($1391), Jul($1278), Aug($954), Sep($1362), Oct($445), Nov($551), Dec($1612), CANCELED: Jan($637), Feb($737), Mar($938), Apr($1353), May($650), Jun($1958), Jul($721), Aug($1569), Sep($810), Oct($585), Nov($1235), Dec($520) GAP: Jan($955), Feb($1388), Mar($904), Apr($263), May($544), Jun($567), Jul($557), Aug($614), Sep($551), Oct($140), Nov($684), Dec($1093)",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "difficulty": "hard",
      "period1": "July",
      "period2": "December",
      "checkpoint": "",
      "answer": "December(1093), November(684), August(614), July(557), September(551), October(140) |OR| December(1,093), November(684), August(614), July(557), September(551), October(140)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "December(1093), November(684), August(614), July(557), September(551), October(140) |OR| December(1,093), November(684), August(614), July(557), September(551), October(140)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "December(1093), November(684), August(614), July(557), September(551), October(140) |OR| December(1,093), November(684), August(614), July(557), September(551), October(140)"
    }
  },
  {
    "task_id": 10080,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Count the number of configurations registered for {{product_name1}} and {{product_name2}}. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "intent": "Count the number of configurations registered for Breathe-Easy Tank and Cronus Yoga Pant. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to 'catalog' -> 'products', filter by product name, and press the 'Configurable Product' row. There you can find/count each numbers. Note that the color column should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "product_name1": "Breathe-Easy Tank",
      "product_name2": "Cronus Yoga Pant",
      "checkpoint": "Breathe-Easy Tank:15, Hero Cronus Yoga Pant:12",
      "answer_product_name": "Breathe-Easy Tank",
      "answer_num_configs": "15",
      "answer_num_reviews": "2",
      "answer_num_related": "8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "(1) Breathe-Easy Tank, (2) 15, (3) 2, (4) 8"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Breathe-Easy Tank, (2) 15, (3) 2, (4) 8"
    }
  },
  {
    "task_id": 10081,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Count the number of configurations registered for {{product_name1}} and {{product_name2}}. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "intent": "Count the number of configurations registered for Electra Bra Top and Stellar Solar Jacket. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to 'catalog' -> 'products', filter by product name, and press the 'Configurable Product' row. There you can find/count each numbers. Note that the color column should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "product_name1": "Electra Bra Top",
      "product_name2": "Stellar Solar Jacket",
      "checkpoint": "Electra Bra Top:15, Stellar Solar Jacket:9",
      "answer_product_name": "Electra Bra Top",
      "answer_num_configs": "15",
      "answer_num_reviews": "4",
      "answer_num_related": "8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "(1) Electra Bra Top, (2) 15, (3) 4, (4) 8"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Electra Bra Top, (2) 15, (3) 4, (4) 8"
    }
  },
  {
    "task_id": 10082,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Count the number of configurations registered for {{product_name1}} and {{product_name2}}. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "intent": "Count the number of configurations registered for Bardot Capri and Hera Pullover Hoodie. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to 'catalog' -> 'products', filter by product name, and press the 'Configurable Product' row. There you can find/count each numbers. Note that the color column should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "product_name1": "Bardot Capri",
      "product_name2": "Hera Pullover Hoodie",
      "checkpoint": "Bardot Capri:6, Hera Pullover Hoodie:15",
      "answer_product_name": "Hera Pullover Hoodie",
      "answer_num_configs": "15",
      "answer_num_reviews": "3",
      "answer_num_related": "8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "(1) Hera Pullover Hoodie, (2) 15, (3) 3, (4) 8"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Hera Pullover Hoodie, (2) 15, (3) 3, (4) 8"
    }
  },
  {
    "task_id": 10083,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Count the number of configurations registered for {{product_name1}} and {{product_name2}}. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "intent": "Count the number of configurations registered for Orestes Fitness Short and Portia Capri. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to 'catalog' -> 'products', filter by product name, and press the 'Configurable Product' row. There you can find/count each numbers. Note that the color column should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "product_name1": "Orestes Fitness Short",
      "product_name2": "Portia Capri",
      "checkpoint": "Orestes Fitness Short:12, Portia Capri:6",
      "answer_product_name": "Orestes Fitness Short",
      "answer_num_configs": "12",
      "answer_num_reviews": "2",
      "answer_num_related": "8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "(1) Orestes Fitness Short, (2) 12, (3) 2, (4) 8"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Orestes Fitness Short, (2) 12, (3) 2, (4) 8"
    }
  },
  {
    "task_id": 10084,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Count the number of configurations registered for {{product_name1}} and {{product_name2}}. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "intent": "Count the number of configurations registered for WJ05 and MP01. (1) Which product has more variety? (2) How many configurations are registered for the product in (1)? (3) How many reviews are assigned for the product in (1)? (4) How many 'Related Products, Up-Sells, and Cross-Sells' are registered in total for the product in (1)? Final answer should be in the following format by carefully following the instructions on the use of commas and spaces: '(1) ${product name}, (2) ${number of configs}, (3) ${number of reviews}, (4) ${total number of related, up-sell, cross-sell products}'.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to 'catalog' -> 'products', filter by product name, and press the 'Configurable Product' row. There you can find/count each numbers. Note that the color column should be added via 'Columns' tab",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "difficulty": "hard",
      "product_name1": "WJ05",
      "product_name2": "MP01",
      "checkpoint": "WJ05(Riona Full Zip Jacket):15, MP01(Caesar Warm-Up Pant):12",
      "answer_product_name": "Riona Full Zip Jacket",
      "answer_num_configs": "15",
      "answer_num_reviews": "3",
      "answer_num_related": "8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "(1) Riona Full Zip Jacket, (2) 15, (3) 3, (4) 8"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "(1) Riona Full Zip Jacket, (2) 15, (3) 3, (4) 8"
    }
  },
  {
    "task_id": 10090,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Among people in {{place}}, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "Among people in California, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given place, and memorize the name and email adress of the people. Here, email adress is important to identify the same person as there are sometimes people with the same name. Then, go to 'Sales' -> 'Orders', filter by each person, calculate the average of 'Grand Total' for the people in the area.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "place": "California",
      "checkpoint": "Sarah Miller(cnt=8, total=$1212.6), Jane Smith(cnt=9, total=$998.0), Ava Brown(cnt=7, total=$1068.8), Alex Johnson(cnt=6, total=$845.4), Jennifer White(cnt=5, total=$987.8), Alexander Thomas(cnt=2, total=$189.0), avg=$883.6",
      "answer": "Sarah Miller(1,213), Ava Brown(1,069), Jane Smith(998), Jennifer White(988)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Sarah Miller(1,213), Ava Brown(1,069), Jane Smith(998), Jennifer White(988)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Sarah Miller(1,213), Ava Brown(1,069), Jane Smith(998), Jennifer White(988)"
    }
  },
  {
    "task_id": 10091,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Among people in {{place}}, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "Among people in Texas, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given place, and memorize the name and email adress of the people. Here, email adress is important to identify the same person as there are sometimes people with the same name. Then, go to 'Sales' -> 'Orders', filter by each person, calculate the average of 'Grand Total' for the people in the area.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "place": "Texas",
      "checkpoint": "Bob Jones(cnt=6, total=$530.0), Bob Johnson(cnt=6, total=$528.0), Lisa Kim(cnt=2, total=$263.1), Olivia Lee(cnt=3, total=$374.2), Emma Davis(cnt=1, total=$109.0), Lisa Green(cnt=2, total=$269.4), Samantha Nguyen(cnt=1, total=$230.1), avg=$329.1",
      "answer": "Bob Jones(530), Bob Johnson(528), Olivia Lee(374)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Bob Jones(530), Bob Johnson(528), Olivia Lee(374)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Bob Jones(530), Bob Johnson(528), Olivia Lee(374)"
    }
  },
  {
    "task_id": 10092,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Among people in {{place}}, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "Among people in Colorado, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given place, and memorize the name and email adress of the people. Here, email adress is important to identify the same person as there are sometimes people with the same name. Then, go to 'Sales' -> 'Orders', filter by each person, calculate the average of 'Grand Total' for the people in the area.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "place": "Colorado",
      "checkpoint": "Lucy Garcia(cnt=6, total=$899.1), Jason Miller(cnt=5, total=$842.4), avg=$870.8",
      "answer": "Lucy Garcia(899)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Lucy Garcia(899)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Lucy Garcia(899)"
    }
  },
  {
    "task_id": 10093,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Among people in {{place}}, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "Among people in Illinois, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given place, and memorize the name and email adress of the people. Here, email adress is important to identify the same person as there are sometimes people with the same name. Then, go to 'Sales' -> 'Orders', filter by each person, calculate the average of 'Grand Total' for the people in the area.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "place": "Illinois",
      "checkpoint": "John Lee(cnt=4, total=$578.0), Lily Potter(cnt=4, total=$682.2), Michael Nguyen(cnt=8, total=$893.2), avg=$717.8",
      "answer": "Michael Nguyen(893)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Michael Nguyen(893)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Michael Nguyen(893)"
    }
  },
  {
    "task_id": 10094,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Among people in {{place}}, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "intent": "Among people in New York, list the name of the people whose total amount is larger than the average of the people in the area. Consider only transactions with a status of 'Complete' and when calculating the average, exclude people who do not have complete purchase. Final answer should be in descending order of purchase amount and in the following format by carefully following the instructions on the use of commas and spaces: '${person1}(${purchase amount}), ${person2}(purchase amount), ...'. Round the purchase amount to the nearest integer. Amounts should be without '$', formatted with a comma as a thousands separator (e.g., 12,345).",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to 'Customers' -> 'All Customers', filter by the given place, and memorize the name and email adress of the people. Here, email adress is important to identify the same person as there are sometimes people with the same name. Then, go to 'Sales' -> 'Orders', filter by each person, calculate the average of 'Grand Total' for the people in the area.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "difficulty": "medium",
      "place": "New York",
      "checkpoint": "Julia Williams(cnt=2, total=$265.6), John Doe(cnt=3, total=$371.0), Alex Martin(cnt=6, total=$733.0), avg=$456.5",
      "answer": "Alex Martin(733)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Alex Martin(733)"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Alex Martin(733)"
    }
  },
  {
    "task_id": 10100,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How much time has passed between the newest review and the oldest review in Approved status? Provide the answer in seconds. Answer only with the result and the unit, like 3 s.",
    "intent": "How much time has passed between the newest review and the oldest review in Approved status? Provide the answer in seconds. Answer only with the result and the unit, like 3 s.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Identify both the most recent and the oldest review. Finally, calculate the difference between them.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
      "contents": "10 s",
      "checkpoint1": "12:15:10",
      "checkpoint2": "12:15:20",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "10 s"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "10 s"
    }
  },
  {
    "task_id": 10110,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the average of the top {{number}} {{order}} submitted reviews with a status of {{status}}. Round to the nearest tenth. Output the final answer concisely.",
    "intent": "Calculate the average of the top 5 newest submitted reviews with a status of Approved. Round to the nearest tenth. Output the final answer concisely.",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Sort the reviews in either newest or oldest order. Next, click the top 5 reviews in that order and retrieve the number of stars for each.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
      "number": "5",
      "order": "newest",
      "status": "Approved",
      "contents": "3.8",
      "checkpoint1": "4, 5, 4, 2, 4",
      "checkpoint2": "19",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "3.8"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "3.8"
    }
  },
  {
    "task_id": 10111,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Calculate the average of the top {{number}} {{order}} submitted reviews with a status of {{status}}. Round to the nearest tenth. Output the final answer concisely.",
    "intent": "Calculate the average of the top 5 oldest submitted reviews with a status of Approved. Round to the nearest tenth. Output the final answer concisely.",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Sort the reviews in either newest or oldest order. Next, click the top 5 reviews in that order and retrieve the number of stars for each.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/filter//internal_reviews//form_key/RXMoSJ9fUA70DBmM/",
      "number": "5",
      "order": "oldest",
      "status": "Approved",
      "contents": "3.0",
      "checkpoint1": "2, 2, 2, 4, 5",
      "checkpoint2": "15",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "3.0"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "3.0"
    }
  },
  {
    "task_id": 10120,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the difference in average price between the top {{number}} {{state}} Simple Products with the Attribute {{attribute1}} and those with the Attribute {{attribute2}}? Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "What is the difference in average price between the top 10 most recently updated Simple Products with the Attribute Bag and those with the Attribute Gear? Here, if the same updated time appears beyond the top 10, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the Product page. Then, apply filters using attribute1 and Simple Products. Sort the products to matches the specified status. Retrieve the prices of the top number products and calculate their average. Repeat the same process for attribute2, and compute the difference between the two averages.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
      "contents": "6",
      "number": "10",
      "state": "most recently updated",
      "condition": "updated time",
      "attribute1": "Bag",
      "attribute2": "Gear",
      "checkpoint1": "42.45454545",
      "checkpoint2": "48.25",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "6"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "6"
    }
  },
  {
    "task_id": 10121,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the difference in average price between the top {{number}} {{state}} Simple Products with the Attribute {{attribute1}} and those with the Attribute {{attribute2}}? Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "What is the difference in average price between the top 50 oldest updated Simple Products with the Attribute Bottom and those with the Attribute Top? Here, if the same updated time appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the Product page. Then, apply filters using attribute1 and Simple Products. Sort the products to matches the specified status. Retrieve the prices of the top number products and calculate their average. Repeat the same process for attribute2, and compute the difference between the two averages.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
      "contents": "13",
      "number": "50",
      "state": "oldest updated",
      "condition": "updated time",
      "attribute1": "Bottom",
      "attribute2": "Top",
      "checkpoint1": "45.45283019",
      "checkpoint2": "58.3125",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "13"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "13"
    }
  },
  {
    "task_id": 10122,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the difference in average price between the top {{number}} {{state}} Simple Products with the Attribute {{attribute1}} and those with the Attribute {{attribute2}}? Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "What is the difference in average price between the top 10 lowest price Simple Products with the Attribute Bag and those with the Attribute Gear? Here, if the same price appears beyond the top 10, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the Product page. Then, apply filters using attribute1 and Simple Products. Sort the products to matches the specified status. Retrieve the prices of the top number products and calculate their average. Repeat the same process for attribute2, and compute the difference between the two averages.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
      "contents": "20",
      "number": "10",
      "state": "lowest price",
      "condition": "price",
      "attribute1": "Bag",
      "attribute2": "Gear",
      "checkpoint1": "37.41666667",
      "checkpoint2": "17.4",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "20"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "20"
    }
  },
  {
    "task_id": 10123,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the difference in average price between the top {{number}} {{state}} Simple Products with the Attribute {{attribute1}} and those with the Attribute {{attribute2}}? Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "What is the difference in average price between the top 50 most recently updated Simple Products with the Attribute Bottom and those with the Attribute Top? Here, if the same updated time appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the Product page. Then, apply filters using attribute1 and Simple Products. Sort the products to matches the specified status. Retrieve the prices of the top number products and calculate their average. Repeat the same process for attribute2, and compute the difference between the two averages.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
      "contents": "6",
      "number": "50",
      "state": "most recently updated",
      "condition": "updated time",
      "attribute1": "Bottom",
      "attribute2": "Top",
      "checkpoint1": "40.40909091",
      "checkpoint2": "34.28125",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "6"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "6"
    }
  },
  {
    "task_id": 10124,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the difference in average price between the top {{number}} {{state}} Simple Products with the Attribute {{attribute1}} and those with the Attribute {{attribute2}}? Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "What is the difference in average price between the top 50 higest price Simple Products with the Attribute Bottom and those with the Attribute Top? Here, if the same price appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the Product page. Then, apply filters using attribute1 and Simple Products. Sort the products to matches the specified status. Retrieve the prices of the top number products and calculate their average. Repeat the same process for attribute2, and compute the difference between the two averages.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product",
      "contents": "9",
      "number": "50",
      "state": "higest price",
      "condition": "price",
      "attribute1": "Bottom",
      "attribute2": "Top",
      "checkpoint1": "74.8",
      "checkpoint2": "84.25",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "9"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "9"
    }
  },
  {
    "task_id": 10130,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are registered with a domain other than {{domain_name}}?",
    "intent": "How many users are registered with a domain other than gmail.com?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users with the specified domain_name. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "33",
      "domain_name": "gmail.com",
      "checkpoint1": "70",
      "checkpoint2": "37",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number with domain_name",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "33"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "33"
    }
  },
  {
    "task_id": 10131,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are registered with a domain other than {{domain_name}}?",
    "intent": "How many users are registered with a domain other than yahoo.com?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users with the specified domain_name. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "52",
      "domain_name": "yahoo.com",
      "checkpoint1": "70",
      "checkpoint2": "18",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number with domain_name",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "52"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "52"
    }
  },
  {
    "task_id": 10132,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are registered with a domain other than {{domain_name}}?",
    "intent": "How many users are registered with a domain other than hotmail.com?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users with the specified domain_name. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "56",
      "domain_name": "hotmail.com",
      "checkpoint1": "70",
      "checkpoint2": "14",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number with domain_name",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "56"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "56"
    }
  },
  {
    "task_id": 10140,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are there outside {{state1}} and {{state2}} states?",
    "intent": "How many users are there outside New York and New Jersey states?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users in state1 and state2. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "61",
      "state1": "New York",
      "state2": "New Jersey",
      "checkpoint1": "70",
      "checkpoint2": "6",
      "checkpoint3": "3",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number in state1, checkpoint3: user number in state2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "61"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "61"
    }
  },
  {
    "task_id": 10141,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are there outside {{state1}} and {{state2}} states?",
    "intent": "How many users are there outside New Jersey and Florida states?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users in state1 and state2. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "61",
      "state1": "New Jersey",
      "state2": "Florida",
      "checkpoint1": "70",
      "checkpoint2": "3",
      "checkpoint3": "6",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number in state1, checkpoint3: user number in state2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "61"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "61"
    }
  },
  {
    "task_id": 10142,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are there outside {{state1}} and {{state2}} states?",
    "intent": "How many users are there outside Alabama and Illinois states?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users in state1 and state2. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "62",
      "state1": "Alabama",
      "state2": "Illinois",
      "checkpoint1": "70",
      "checkpoint2": "1",
      "checkpoint3": "7",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number in state1, checkpoint3: user number in state2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "62"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "62"
    }
  },
  {
    "task_id": 10143,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are there outside {{state1}} and {{state2}} states?",
    "intent": "How many users are there outside Colorado and Washington states?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users in state1 and state2. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "60",
      "state1": "Colorado",
      "state2": "Washington",
      "checkpoint1": "70",
      "checkpoint2": "4",
      "checkpoint3": "6",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number in state1, checkpoint3: user number in state2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "60"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "60"
    }
  },
  {
    "task_id": 10144,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many users are there outside {{state1}} and {{state2}} states?",
    "intent": "How many users are there outside Massachusetts and New York states?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, navigate to the customer page. Then, count the number of users in state1 and state2. Finally, subtract this number from the total number of users.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/customer/index/",
      "contents": "59",
      "state1": "Massachusetts",
      "state2": "New York",
      "checkpoint1": "70",
      "checkpoint2": "5",
      "checkpoint3": "6",
      "checkpoint_info": "checkpoint1: total user number, checkpoint2: user number in state1, checkpoint3: user number in state2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "59"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "59"
    }
  },
  {
    "task_id": 10150,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Please provide the top 10 days with the highest sales from {{month1}}/{{year1}} to {{month2}}/{{year2}}. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "intent": "Please provide the top 10 days with the highest sales from 1/2022 to 6/2022. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Order Count Report in the reports section. Then, retrieve the sales data for the specified period. Finally, identify the top 10 days with the highest sales.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
      "contents": "2/8/2022, 5/2/2022, 4/21/2022, 2/3/2022, 3/17/2022, 1/20/2022, 2/6/2022, 1/28/2022, 4/6/2022, 5/29/2022",
      "year1": "2022",
      "year2": "2022",
      "month1": "1",
      "month2": "6",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[2/8/2022, 5/2/2022, 4/21/2022, 2/3/2022, 3/17/2022, 1/20/2022, 2/6/2022, 1/28/2022, 4/6/2022, 5/29/2022]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[2/8/2022, 5/2/2022, 4/21/2022, 2/3/2022, 3/17/2022, 1/20/2022, 2/6/2022, 1/28/2022, 4/6/2022, 5/29/2022]"
    }
  },
  {
    "task_id": 10151,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Please provide the top 10 days with the highest sales from {{month1}}/{{year1}} to {{month2}}/{{year2}}. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "intent": "Please provide the top 10 days with the highest sales from 7/2022 to 12/2022. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Order Count Report in the reports section. Then, retrieve the sales data for the specified period. Finally, identify the top 10 days with the highest sales.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
      "contents": "12/11/2022, 8/28/2022, 12/6/2022, 9/2/2022, 7/6/2022, 12/24/2022, 9/23/2022, 7/12/2022, 9/30/2022, 11/3/2022",
      "year1": "2022",
      "year2": "2022",
      "month1": "7",
      "month2": "12",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[12/11/2022, 8/28/2022, 12/6/2022, 9/2/2022, 7/6/2022, 12/24/2022, 9/23/2022, 7/12/2022, 9/30/2022, 11/3/2022]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[12/11/2022, 8/28/2022, 12/6/2022, 9/2/2022, 7/6/2022, 12/24/2022, 9/23/2022, 7/12/2022, 9/30/2022, 11/3/2022]"
    }
  },
  {
    "task_id": 10152,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Please provide the top 10 days with the highest sales from {{month1}}/{{year1}} to {{month2}}/{{year2}}. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "intent": "Please provide the top 10 days with the highest sales from 1/2023 to 5/2023. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Order Count Report in the reports section. Then, retrieve the sales data for the specified period. Finally, identify the top 10 days with the highest sales.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
      "contents": "4/5/2023, 3/31/2023, 1/9/2023, 1/12/2023, 5/31/2023, 1/28/2023, 1/6/2023, 5/28/2023, 1/16/2023, 1/13/2023",
      "year1": "2023",
      "year2": "2023",
      "month1": "1",
      "month2": "5",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[4/5/2023, 3/31/2023, 1/9/2023, 1/12/2023, 5/31/2023, 1/28/2023, 1/6/2023, 5/28/2023, 1/16/2023, 1/13/2023]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[4/5/2023, 3/31/2023, 1/9/2023, 1/12/2023, 5/31/2023, 1/28/2023, 1/6/2023, 5/28/2023, 1/16/2023, 1/13/2023]"
    }
  },
  {
    "task_id": 10153,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Please provide the top 10 days with the highest sales from {{month1}}/{{year1}} to {{month2}}/{{year2}}. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "intent": "Please provide the top 10 days with the highest sales from 1/2022 to 5/2023. Present the dates in the MM/DD/YYYY format (e.g., January 1st in 2022 should be written as 1/1/2022). List them in descending order of sales. Example: [2/5/2022, 1/1/2022, 3/15/2022, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Order Count Report in the reports section. Then, retrieve the sales data for the specified period. Finally, identify the top 10 days with the highest sales.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_customer/orders/",
      "contents": "4/5/2023, 12/11/2022, 2/8/2022, 5/2/2022, 8/28/2022, 4/21/2022, 2/3/2022, 12/6/2022, 3/17/2022, 1/20/2022",
      "year1": "2022",
      "year2": "2023",
      "month1": "1",
      "month2": "5",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[4/5/2023, 12/11/2022, 2/8/2022, 5/2/2022, 8/28/2022, 4/21/2022, 2/3/2022, 12/6/2022, 3/17/2022, 1/20/2022]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[4/5/2023, 12/11/2022, 2/8/2022, 5/2/2022, 8/28/2022, 4/21/2022, 2/3/2022, 12/6/2022, 3/17/2022, 1/20/2022]"
    }
  },
  {
    "task_id": 10160,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total cost for completed orders that {{user1}} and {{user2}} purchased?",
    "intent": "What is the total cost for completed orders that Alex Martin and Grace Nguyen purchased?",
    "required_obs": "any",
    "type_main": "calc",
    "description": "First, navigate to the sales order page. Then, calculate the total cost of completed orders for user1 and user2. Finally, sum the total costs for user1 and user2.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "1802.88 |OR| 1,802.88",
      "user1": "Alex Martin",
      "user2": "Grace Nguyen",
      "checkpoint1": "733.00",
      "checkpoint2": "1069.88",
      "checkpoint_info": "checkpoint1: total cost for user1, checkpoint2: total cost for user2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1802.88 |OR| 1,802.88"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1802.88 |OR| 1,802.88"
    }
  },
  {
    "task_id": 10161,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total cost for completed orders that {{user1}} and {{user2}} purchased?",
    "intent": "What is the total cost for completed orders that Jane Doe and Julia Williams purchased?",
    "required_obs": "any",
    "type_main": "calc",
    "description": "First, navigate to the sales order page. Then, calculate the total cost of completed orders for user1 and user2. Finally, sum the total costs for user1 and user2.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "1155.52 |OR| 1,155.52",
      "user1": "Jane Doe",
      "user2": "Julia Williams",
      "checkpoint1": "889.92",
      "checkpoint2": "265.60",
      "checkpoint_info": "checkpoint1: total cost for user1, checkpoint2: total cost for user2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1155.52 |OR| 1,155.52"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1155.52 |OR| 1,155.52"
    }
  },
  {
    "task_id": 10162,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total cost for completed orders that {{user1}} and {{user2}} purchased?",
    "intent": "What is the total cost for completed orders that Lily Potter and Daniel Jackson purchased?",
    "required_obs": "any",
    "type_main": "calc",
    "description": "First, navigate to the sales order page. Then, calculate the total cost of completed orders for user1 and user2. Finally, sum the total costs for user1 and user2.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "843.6",
      "user1": "Lily Potter",
      "user2": "Daniel Jackson",
      "checkpoint1": "682.20",
      "checkpoint2": "161.40",
      "checkpoint_info": "checkpoint1: total cost for user1, checkpoint2: total cost for user2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "843.6"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "843.6"
    }
  },
  {
    "task_id": 10163,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total cost for completed orders that {{user1}} and {{user2}} purchased?",
    "intent": "What is the total cost for completed orders that Sarah Miller and Michael Nguyen purchased?",
    "required_obs": "any",
    "type_main": "calc",
    "description": "First, navigate to the sales order page. Then, calculate the total cost of completed orders for user1 and user2. Finally, sum the total costs for user1 and user2.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "2105.84 |OR| 2,105.84",
      "user1": "Sarah Miller",
      "user2": "Michael Nguyen",
      "checkpoint1": "1212.60",
      "checkpoint2": "893.24",
      "checkpoint_info": "checkpoint1: total cost for user1, checkpoint2: total cost for user2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "2105.84 |OR| 2,105.84"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2105.84 |OR| 2,105.84"
    }
  },
  {
    "task_id": 10164,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total cost for completed orders that {{user1}} and {{user2}} purchased?",
    "intent": "What is the total cost for completed orders that Samantha Jones and Adam Garcia purchased?",
    "required_obs": "any",
    "type_main": "calc",
    "description": "First, navigate to the sales order page. Then, calculate the total cost of completed orders for user1 and user2. Finally, sum the total costs for user1 and user2.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "1834.56 |OR| 1,834.56",
      "user1": "Samantha Jones",
      "user2": "Adam Garcia",
      "checkpoint1": "964.00",
      "checkpoint2": "870.56",
      "checkpoint_info": "checkpoint1: total cost for user1, checkpoint2: total cost for user2",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1834.56 |OR| 1,834.56"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1834.56 |OR| 1,834.56"
    }
  },
  {
    "task_id": 10170,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List the IDs of approved reviews that contain the word {{word}} from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "intent": "List the IDs of approved reviews that contain the word good from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Retrieve the top 50 most recently created approved reviews. Finally, identify the IDs of those reviews that contain the word {{word}}.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product",
      "contents": "338, 343, 308, 330, 329, 326, 282",
      "word": "good",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "[338, 343, 308, 330, 329, 326, 282]"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "338, 343, 308, 330, 329, 326, 282"
    }
  },
  {
    "task_id": 10171,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List the IDs of approved reviews that contain the word {{word}} from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "intent": "List the IDs of approved reviews that contain the word never from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Retrieve the top 50 most recently created approved reviews. Finally, identify the IDs of those reviews that contain the word {{word}}.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product",
      "contents": "337, 307, 326",
      "word": "never",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "[337, 307, 326]"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "337, 307, 326"
    }
  },
  {
    "task_id": 10172,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List the IDs of approved reviews that contain the word {{word}} from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "intent": "List the IDs of approved reviews that contain the word love from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Retrieve the top 50 most recently created approved reviews. Finally, identify the IDs of those reviews that contain the word {{word}}.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product",
      "contents": "352, 340, 344, 346, 314, 315, 310, 306, 323",
      "word": "love",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "[352, 340, 344, 346, 314, 315, 310, 306, 323]"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "352, 340, 344, 346, 314, 315, 310, 306, 323"
    }
  },
  {
    "task_id": 10173,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List the IDs of approved reviews that contain the word {{word}} from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "intent": "List the IDs of approved reviews that contain the word cute from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Retrieve the top 50 most recently created approved reviews. Finally, identify the IDs of those reviews that contain the word {{word}}.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product",
      "contents": "339, 346, 315, 312, 311, 305, 328, 327, 326, 322",
      "word": "cute",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "[339, 346, 315, 312, 311, 305, 328, 327, 326, 322]"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "339, 346, 315, 312, 311, 305, 328, 327, 326, 322"
    }
  },
  {
    "task_id": 10174,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List the IDs of approved reviews that contain the word {{word}} from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "intent": "List the IDs of approved reviews that contain the word comfortable from the top 50 most recently created approved reviews. Sort them by creation date, from newest to oldest. When creation dates are the same, treat those appearing earlier in the system display-when sorted from newest to oldest-as being earlier. Provide the answer in the following format: [ID1, ID2, ID3, ...]",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Review page. Then, filter to show only the Approved reviews. Retrieve the top 50 most recently created approved reviews. Finally, identify the IDs of those reviews that contain the word {{word}}.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product",
      "contents": "352, 351, 347, 341, 345, 316, 312, 305, 322, 324, 283",
      "word": "comfortable",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "[352, 351, 347, 341, 345, 316, 312, 305, 322, 324, 283]"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "352, 351, 347, 341, 345, 316, 312, 305, 322, 324, 283"
    }
  },
  {
    "task_id": 10180,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for {{status}} Simple Products with {{attribute}}, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "intent": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for most recently updated Simple Products with Top, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Product page. Then, filter by attribute. Next, sort by status. Retrieve the product IDs in the state of 50 items per page. After that, retrieve the product IDs in the state of 20 items per page. Finally, compare both IDs and extract the different ones.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "1810, 1809, 1811, 1808, 1768, 1763, 1792, 1785, 1752, 1775, 1776, 1779, 1758, 1765, 1772, 1789, 1756, 1791, 1782, 1750, 1773, 1788, 1784, 1790, 1771, 1754, 1747, 1794, 1749, 1774, 1759, 1760, 1786, 1770, 1793, 1769, 1777, 1757, 1781, 1797, 1766, 1795, 1762, 1787, 1783, 1751",
      "status": "most recently updated",
      "attribute": "Top",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "1810, 1809, 1811, 1808, 1768, 1763, 1792, 1785, 1752, 1775, 1776, 1779, 1758, 1765, 1772, 1789, 1756, 1791, 1782, 1750, 1773, 1788, 1784, 1790, 1771, 1754, 1747, 1794, 1749, 1774, 1759, 1760, 1786, 1770, 1793, 1769, 1777, 1757, 1781, 1797, 1766, 1795, 1762, 1787, 1783, 1751"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1810, 1809, 1811, 1808, 1768, 1763, 1792, 1785, 1752, 1775, 1776, 1779, 1758, 1765, 1772, 1789, 1756, 1791, 1782, 1750, 1773, 1788, 1784, 1790, 1771, 1754, 1747, 1794, 1749, 1774, 1759, 1760, 1786, 1770, 1793, 1769, 1777, 1757, 1781, 1797, 1766, 1795, 1762, 1787, 1783, 1751"
    }
  },
  {
    "task_id": 10181,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for {{status}} Simple Products with {{attribute}}, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "intent": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for lowest price Simple Products with Bottom, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Product page. Then, filter by attribute. Next, sort by status. Retrieve the product IDs in the state of 50 items per page. After that, retrieve the product IDs in the state of 20 items per page. Finally, compare both IDs and extract the different ones.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "1011, 1004, 1008, 1012, 1005, 1009, 1013, 1006, 1010, 1003, 1014, 1007, 984, 1994, 977, 988, 981, 1991, 985, 1995, 978, 982, 1992, 986, 1996, 979, 983, 1993, 987, 980, 1019, 1023, 1016, 1027, 1020, 1024, 1017, 1021, 1025, 1018, 1022, 1026, 1932, 795, 1978, 1925, 1971, 799, 1929, 1982",
      "status": "lowest price",
      "attribute": "Bottom",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "1011, 1004, 1008, 1012, 1005, 1009, 1013, 1006, 1010, 1003, 1014, 1007, 984, 1994, 977, 988, 981, 1991, 985, 1995, 978, 982, 1992, 986, 1996, 979, 983, 1993, 987, 980, 1019, 1023, 1016, 1027, 1020, 1024, 1017, 1021, 1025, 1018, 1022, 1026, 1932, 795, 1978, 1925, 1971, 799, 1929, 1982"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1011, 1004, 1008, 1012, 1005, 1009, 1013, 1006, 1010, 1003, 1014, 1007, 984, 1994, 977, 988, 981, 1991, 985, 1995, 978, 982, 1992, 986, 1996, 979, 983, 1993, 987, 980, 1019, 1023, 1016, 1027, 1020, 1024, 1017, 1021, 1025, 1018, 1022, 1026, 1932, 795, 1978, 1925, 1971, 799, 1929, 1982"
    }
  },
  {
    "task_id": 10182,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for {{status}} Simple Products with {{attribute}}, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "intent": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for highest price Simple Products with Top, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Product page. Then, filter by attribute. Next, sort by status. Retrieve the product IDs in the state of 50 items per page. After that, retrieve the product IDs in the state of 20 items per page. Finally, compare both IDs and extract the different ones.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "333, 326, 319, 330, 323, 327, 320, 331, 324, 328, 321, 332, 325, 329, 322, 1263, 1256, 1267, 1260, 1253, 1264, 1257, 1261, 1254, 1265, 1258, 1262, 1255, 1266, 1259, 1381, 1373, 1366, 1392, 1385, 1377, 1370, 1389, 1382, 1374, 1367, 1393, 1386, 1378, 1371, 1390, 1383, 1375, 1368, 1394",
      "status": "highest price",
      "attribute": "Top",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "333, 326, 319, 330, 323, 327, 320, 331, 324, 328, 321, 332, 325, 329, 322, 1263, 1256, 1267, 1260, 1253, 1264, 1257, 1261, 1254, 1265, 1258, 1262, 1255, 1266, 1259, 1381, 1373, 1366, 1392, 1385, 1377, 1370, 1389, 1382, 1374, 1367, 1393, 1386, 1378, 1371, 1390, 1383, 1375, 1368, 1394"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "333, 326, 319, 330, 323, 327, 320, 331, 324, 328, 321, 332, 325, 329, 322, 1263, 1256, 1267, 1260, 1253, 1264, 1257, 1261, 1254, 1265, 1258, 1262, 1255, 1266, 1259, 1381, 1373, 1366, 1392, 1385, 1377, 1370, 1389, 1382, 1374, 1367, 1393, 1386, 1378, 1371, 1390, 1383, 1375, 1368, 1394"
    }
  },
  {
    "task_id": 10183,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for {{status}} Simple Products with {{attribute}}, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "intent": "The product page of this website has a specification where changing the number of items displayed per page causes the order of some products to change. Please analyze this specification. Specifically, for most recently updated Simple Products with Bottom, identify the top 50 products based on their ranking when displayed on 50 items per page. Then, compare this ranking with the rankings when displayed on 20 items per page. Extract the IDs of products whose rankings differ between these page settings. As a note, list all product IDs whose rankings are misaligned. For example, if the order for 50 items per page is: 1, 2, 3, 4, 5 and for 20 items per page it's: 1, 14, 2, 3, 4 then the correct answer is: 2, 3, 4, 5. Format your answer as follows, listing IDs in the order they appear earliest on the 50 items per page setting:\nID7, ID2, ID3, ..., ID20",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, navigate to the Product page. Then, filter by attribute. Next, sort by status. Retrieve the product IDs in the state of 50 items per page. After that, retrieve the product IDs in the state of 20 items per page. Finally, compare both IDs and extract the different ones.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "2039, 2015, 2007, 2005, 2008, 2019, 2011, 2037, 2023, 2030, 2033, 2036, 2020, 2009, 2031, 2028, 2038, 2035, 2025, 2006, 2002, 2013, 2032, 2012, 2018, 2029, 2014, 2016, 2026, 2004, 2027, 2022, 2021, 2034, 1976, 1981, 1977, 1995, 1991, 1989, 1988, 1980, 1994, 1985, 1979, 1984, 1986, 1993",
      "status": "most recently updated",
      "attribute": "Bottom",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "2039, 2015, 2007, 2005, 2008, 2019, 2011, 2037, 2023, 2030, 2033, 2036, 2020, 2009, 2031, 2028, 2038, 2035, 2025, 2006, 2002, 2013, 2032, 2012, 2018, 2029, 2014, 2016, 2026, 2004, 2027, 2022, 2021, 2034, 1976, 1981, 1977, 1995, 1991, 1989, 1988, 1980, 1994, 1985, 1979, 1984, 1986, 1993"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2039, 2015, 2007, 2005, 2008, 2019, 2011, 2037, 2023, 2030, 2033, 2036, 2020, 2009, 2031, 2028, 2038, 2035, 2025, 2006, 2002, 2013, 2032, 2012, 2018, 2029, 2014, 2016, 2026, 2004, 2027, 2022, 2021, 2034, 1976, 1981, 1977, 1995, 1991, 1989, 1988, 1980, 1994, 1985, 1979, 1984, 1986, 1993"
    }
  },
  {
    "task_id": 10190,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to replenish 40 units of each Simple Product that has the Attribute {{attribute}}. These products should be among the top {{number}} {{status}} products within that category. Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "I want to replenish 40 units of each Simple Product that has the Attribute Top. These products should be among the top 50 most recently updated products within that category. Here, if the same updated time appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the Product page. Then, apply filters using attribute and Simple Products. Sort the products to match the specified status. Next, retrieve the prices of the top number products, multiply each by 0.6, sum them up, and finally multiply by 40.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "52656 |OR| 52,656",
      "attribute": "Top",
      "condition": "updated time",
      "status": "most recently updated",
      "number": "50",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "52656 |OR| 52,656"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "52656 |OR| 52,656"
    }
  },
  {
    "task_id": 10191,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to replenish 40 units of each Simple Product that has the Attribute {{attribute}}. These products should be among the top {{number}} {{status}} products within that category. Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "I want to replenish 40 units of each Simple Product that has the Attribute Bottom. These products should be among the top 50 highest price products within that category. Here, if the same price appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the Product page. Then, apply filters using attribute and Simple Products. Sort the products to match the specified status. Next, retrieve the prices of the top number products, multiply each by 0.6, sum them up, and finally multiply by 40.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "107712 |OR| 107,712",
      "attribute": "Bottom",
      "condition": "price",
      "status": "highest price",
      "number": "50",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "107712 |OR| 107,712"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "107712 |OR| 107,712"
    }
  },
  {
    "task_id": 10192,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to replenish 40 units of each Simple Product that has the Attribute {{attribute}}. These products should be among the top {{number}} {{status}} products within that category. Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "I want to replenish 40 units of each Simple Product that has the Attribute Top. These products should be among the top 30 lowest price products within that category. Here, if the same price appears beyond the top 30, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the Product page. Then, apply filters using attribute and Simple Products. Sort the products to match the specified status. Next, retrieve the prices of the top number products, multiply each by 0.6, sum them up, and finally multiply by 40.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "17040 |OR| 17,040",
      "attribute": "Top",
      "condition": "price",
      "status": "lowest price",
      "number": "30",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "17040 |OR| 17,040"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "17040 |OR| 17,040"
    }
  },
  {
    "task_id": 10193,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "I want to replenish 40 units of each Simple Product that has the Attribute {{attribute}}. These products should be among the top {{number}} {{status}} products within that category. Here, if the same {{condition}} appears beyond the top {{number}}, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "intent": "I want to replenish 40 units of each Simple Product that has the Attribute Bottom. These products should be among the top 50 oldest last-updated products within that category. Here, if the same updated time appears beyond the top 50, include those as well. If a product with the same ID appears more than once, it is a bug, so please ignore it. If the purchase unit price for restocking is 60% of the selling price, how much will the total cost be? Do all calculations in decimals and round the purchase amount to the nearest integer just before answering.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the Product page. Then, apply filters using attribute and Simple Products. Sort the products to match the specified status. Next, retrieve the prices of the top number products, multiply each by 0.6, sum them up, and finally multiply by 40.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/catalog/product/",
      "contents": "57816 |OR| 57,816",
      "attribute": "Bottom",
      "condition": "updated time",
      "status": "oldest last-updated",
      "number": "50",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "57816 |OR| 57,816"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "57816 |OR| 57,816"
    }
  },
  {
    "task_id": 10200,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many products did {{user1}} purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "intent": "How many products did Sarah Miller purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, navigate to the sales order page. Then, retrieve the list of completed orders for user1. After that, click on each order to find out how many products were purchased. Finally, sum the total number of products purchased.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "26",
      "user1": "Sarah Miller",
      "checkpoint1": "26",
      "checkpoint_info": "checkpoint1: total products purchased by user1, checkpoint2: total products purchased by user2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "26"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "26"
    }
  },
  {
    "task_id": 10201,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many products did {{user1}} purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "intent": "How many products did Adam Garcia purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, navigate to the sales order page. Then, retrieve the list of completed orders for user1. After that, click on each order to find out how many products were purchased. Finally, sum the total number of products purchased.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "20",
      "user1": "Adam Garcia",
      "checkpoint1": "20",
      "checkpoint_info": "checkpoint1: total products purchased by user1, checkpoint2: total products purchased by user2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "20"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "20"
    }
  },
  {
    "task_id": 10202,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "How many products did {{user1}} purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "intent": "How many products did Grace Nguyen purchase in completed orders? Note that the 'Grand Total' on the order page represents the total amount for multiple products purchased in a single transaction.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, navigate to the sales order page. Then, retrieve the list of completed orders for user1. After that, click on each order to find out how many products were purchased. Finally, sum the total number of products purchased.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order",
      "contents": "24",
      "user1": "Grace Nguyen",
      "checkpoint1": "24",
      "checkpoint_info": "checkpoint1: total products purchased by user1, checkpoint2: total products purchased by user2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "24"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "24"
    }
  },
  {
    "task_id": 10210,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average rating (including pending and not approved review) for all {{product_type}} products? The product name must contain '{{product_type}}'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "intent": "What is the average rating (including pending and not approved review) for all hoodie products? The product name must contain 'hoodie'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to Reports -> Reviews -> By Products, and search for {{product type}} in the Product field. Then, calculate the weighted average using the average rating and the number of reviews of the search results.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_type": "hoodie",
      "contents": "71",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "71"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "71"
    }
  },
  {
    "task_id": 10211,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average rating (including pending and not approved review) for all {{product_type}} products? The product name must contain '{{product_type}}'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "intent": "What is the average rating (including pending and not approved review) for all bra products? The product name must contain 'bra'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to Reports -> Reviews -> By Products, and search for {{product type}} in the Product field. Then, calculate the weighted average using the average rating and the number of reviews of the search results.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_type": "bra",
      "contents": "61",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "61"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "61"
    }
  },
  {
    "task_id": 10212,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average rating (including pending and not approved review) for all {{product_type}} products? The product name must contain '{{product_type}}'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "intent": "What is the average rating (including pending and not approved review) for all bag products? The product name must contain 'bag'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to Reports -> Reviews -> By Products, and search for {{product type}} in the Product field. Then, calculate the weighted average using the average rating and the number of reviews of the search results.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_type": "bag",
      "contents": "64",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "64"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "64"
    }
  },
  {
    "task_id": 10213,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average rating (including pending and not approved review) for all {{product_type}} products? The product name must contain '{{product_type}}'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "intent": "What is the average rating (including pending and not approved review) for all tank products? The product name must contain 'tank'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to Reports -> Reviews -> By Products, and search for {{product type}} in the Product field. Then, calculate the weighted average using the average rating and the number of reviews of the search results.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_type": "tank",
      "contents": "65",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "65"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "65"
    }
  },
  {
    "task_id": 10214,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average rating (including pending and not approved review) for all {{product_type}} products? The product name must contain '{{product_type}}'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "intent": "What is the average rating (including pending and not approved review) for all jacket products? The product name must contain 'jacket'. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be 'average_rating' without reasoning.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "",
    "description": "Go to Reports -> Reviews -> By Products, and search for {{product type}} in the Product field. Then, calculate the weighted average using the average rating and the number of reviews of the search results.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_type": "jacket",
      "contents": "75",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "75"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "75"
    }
  },
  {
    "task_id": 10220,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is {{adj}}? The review must contain the word '{{adj}}' and should not include contexts where it is stated as not {{adj}}. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "intent": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is expensive? The review must contain the word 'expensive' and should not include contexts where it is stated as not expensive. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Marketing -> User Content -> All Reviews, and search for {{adj}} in the Review field. Click the Edit button to view the content of each review in the search results and confirm that the review is not actually using {{adj}} in a negative context. Finally, search for the prices of the corresponding products in Catalog -> Products, and calculate the average.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
      "adj": "expensive",
      "contents": "19",
      "checkpoint1": "Quest Lumaflex™ Band",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "19"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "19"
    }
  },
  {
    "task_id": 10221,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is {{adj}}? The review must contain the word '{{adj}}' and should not include contexts where it is stated as not {{adj}}. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "intent": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is bulky? The review must contain the word 'bulky' and should not include contexts where it is stated as not bulky. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Marketing -> User Content -> All Reviews, and search for {{adj}} in the Review field. Click the Edit button to view the content of each review in the search results and confirm that the review is not actually using {{adj}} in a negative context. Finally, search for the prices of the corresponding products in Catalog -> Products, and calculate the average.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
      "adj": "bulky",
      "contents": "62",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "62"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "62"
    }
  },
  {
    "task_id": 10222,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is {{adj}}? The review must contain the word '{{adj}}' and should not include contexts where it is stated as not {{adj}}. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "intent": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is high quality? The review must contain the word 'high quality' and should not include contexts where it is stated as not high quality. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Marketing -> User Content -> All Reviews, and search for {{adj}} in the Review field. Click the Edit button to view the content of each review in the search results and confirm that the review is not actually using {{adj}} in a negative context. Finally, search for the prices of the corresponding products in Catalog -> Products, and calculate the average.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
      "adj": "high quality",
      "contents": "N/A",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "N/A"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "N/A"
    }
  },
  {
    "task_id": 10223,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is {{adj}}? The review must contain the word '{{adj}}' and should not include contexts where it is stated as not {{adj}}. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "intent": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is versatile? The review must contain the word 'versatile' and should not include contexts where it is stated as not versatile. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Marketing -> User Content -> All Reviews, and search for {{adj}} in the Review field. Click the Edit button to view the content of each review in the search results and confirm that the review is not actually using {{adj}} in a negative context. Finally, search for the prices of the corresponding products in Catalog -> Products, and calculate the average.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
      "adj": "versatile",
      "contents": "49 |OR| 50",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "49 |OR| 50"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "49 |OR| 50"
    }
  },
  {
    "task_id": 10224,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is {{adj}}? The review must contain the word '{{adj}}' and should not include contexts where it is stated as not {{adj}}. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "intent": "What is the average price of the product(s) that received a review (any statuses are acceptable) stating it is lightweight? The review must contain the word 'lightweight' and should not include contexts where it is stated as not lightweight. Answer should be rounded to the nearest integer. Final answer should be 'average_price' without reasoning. If there is no applicable review, answer 'N/A'",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Marketing -> User Content -> All Reviews, and search for {{adj}} in the Review field. Click the Edit button to view the content of each review in the search results and confirm that the review is not actually using {{adj}} in a negative context. Finally, search for the prices of the corresponding products in Catalog -> Products, and calculate the average.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/review/product/index/",
      "adj": "lightweight",
      "contents": "51",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "51"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "51"
    }
  },
  {
    "task_id": 10230,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the dates in {{month}} when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "intent": "List all the dates in March, 2022 when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Reports -> Products -> Bestsellers, set the Period to Month, and retrieve the best-selling products for {{month}}. Then, check the dates on which each product was sold during {{month}} in Reports -> Products -> Ordered.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
      "month": "March, 2022",
      "contents": "[12, 22]",
      "checkpoint1": "Quest Lumaflex™ Band",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[12, 22]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[12, 22]"
    }
  },
  {
    "task_id": 10231,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the dates in {{month}} when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "intent": "List all the dates in April, 2022 when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Reports -> Products -> Bestsellers, set the Period to Month, and retrieve the best-selling products for {{month}}. Then, check the dates on which each product was sold during {{month}} in Reports -> Products -> Ordered.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
      "month": "April, 2022",
      "contents": "[23]",
      "checkpoint1": "Hera Pullover Hoodie-XS-Green",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[23]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[23]"
    }
  },
  {
    "task_id": 10232,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the dates in {{month}} when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "intent": "List all the dates in June, 2022 when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Reports -> Products -> Bestsellers, set the Period to Month, and retrieve the best-selling products for {{month}}. Then, check the dates on which each product was sold during {{month}} in Reports -> Products -> Ordered.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
      "month": "June, 2022",
      "contents": "[2, 14, 18]",
      "checkpoint1": "Affirm Water Bottle, Harmony Lumaflex™ Strength Band Kit",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[2, 14, 18]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[2, 14, 18]"
    }
  },
  {
    "task_id": 10233,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the dates in {{month}} when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "intent": "List all the dates in February, 2022 when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Reports -> Products -> Bestsellers, set the Period to Month, and retrieve the best-selling products for {{month}}. Then, check the dates on which each product was sold during {{month}} in Reports -> Products -> Ordered.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
      "month": "February, 2022",
      "contents": "[3, 4, 6, 8, 19]",
      "checkpoint1": "Dash Digital Watch, Sprite Yoga Strap 6 foot, Sprite Yoga Strap 8 foot",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[3, 4, 6, 8, 19]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[3, 4, 6, 8, 19]"
    }
  },
  {
    "task_id": 10234,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the dates in {{month}} when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "intent": "List all the dates in May, 2022 when the best-selling product(s) of that month were sold. If there are multiple best-selling products, include the dates for all of them. The date should be an integer without including the month or year. Final answer should be in the format '[date1, date2, ...]' without reasoning, sorted in chronological order.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Reports -> Products -> Bestsellers, set the Period to Month, and retrieve the best-selling products for {{month}}. Then, check the dates on which each product was sold during {{month}} in Reports -> Products -> Ordered.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/bestsellers/",
      "month": "May, 2022",
      "contents": "[2, 12, 15, 16, 20, 29]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[2, 12, 15, 16, 20, 29]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[2, 12, 15, 16, 20, 29]"
    }
  },
  {
    "task_id": 10240,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales total order(s) in each month of the first half of 2022, where the sales total of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales total. If multiple months have the same sales total, those months should be ordered chronologically. If multiple customers placed the highest sales total order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "first",
      "attribute": "sales total",
      "contents": "[Grace Nguyen, Lily Potter, Samantha Jones, Jennifer White]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Grace Nguyen, Lily Potter, Samantha Jones, Jennifer White]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Grace Nguyen, Lily Potter, Samantha Jones, Jennifer White]"
    }
  },
  {
    "task_id": 10241,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales total order(s) in each month of the second half of 2022, where the sales total of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales total. If multiple months have the same sales total, those months should be ordered chronologically. If multiple customers placed the highest sales total order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "second",
      "attribute": "sales total",
      "contents": "[Lucy Garcia, Lily Potter]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Lucy Garcia, Lily Potter]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Lucy Garcia, Lily Potter]"
    }
  },
  {
    "task_id": 10242,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales items order(s) in each month of the first half of 2022, where the sales items of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales items. If multiple months have the same sales items, those months should be ordered chronologically. If multiple customers placed the highest sales items order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "first",
      "attribute": "sales items",
      "contents": "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]"
    }
  },
  {
    "task_id": 10243,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales items order(s) in each month of the second half of 2022, where the sales items of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales items. If multiple months have the same sales items, those months should be ordered chronologically. If multiple customers placed the highest sales items order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "second",
      "attribute": "sales items",
      "contents": "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Jones]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Jones]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Jones]"
    }
  },
  {
    "task_id": 10244,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales shipping order(s) in each month of the first half of 2022, where the sales shipping of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales shipping. If multiple months have the same sales shipping, those months should be ordered chronologically. If multiple customers placed the highest sales shipping order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "first",
      "attribute": "sales shipping",
      "contents": "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Alex Johnson, Grace Nguyen, Michael Nguyen, Grace Nguyen, Jane Smith, Katie Wong, Lily Potter, Alex Martin, Samantha Jones, Jennifer White, Lily Potter]"
    }
  },
  {
    "task_id": 10245,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the customer names (bill-to) who placed the highest {{attribute}} order(s) in each month of the {{number}} half of 2022, where the {{attribute}} of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's {{attribute}}. If multiple months have the same {{attribute}}, those months should be ordered chronologically. If multiple customers placed the highest {{attribute}} order in the same month, their names should be sorted alphabetically.",
    "intent": "List all the customer names (bill-to) who placed the highest sales shipping order(s) in each month of the second half of 2022, where the sales shipping of completed orders exceeded the monthly average for that year. The final answer should be in the format '[name1, name2, ...]' without reasoning, where names are sorted based on the descending order of their corresponding month's sales shipping. If multiple months have the same sales shipping, those months should be ordered chronologically. If multiple customers placed the highest sales shipping order in the same month, their names should be sorted alphabetically.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Go to Reports -> Sales -> Orders, set the Period to Month and the Order Status to Specified -> Complete, and display the Orders Report for 2022. Use this to calculate the monthly average of {{attribute}}, and identify the months that meet the criteria. Next, change the Period to Day, display the report for each of those months, and obtain candidate dates for the highest {{attribute}} order(s). Finally, go to Sales -> Orders, check the orders on each of those dates, and retrieve the customer name(s) associated with the highest {{attribute}} order(s).",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_sales/sales/",
      "number": "second",
      "attribute": "sales shipping",
      "contents": "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Nguyen, Samantha Jones]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Nguyen, Samantha Jones]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Lucy Garcia, Mary Martin, Olivia Lee, Samantha Nguyen, Samantha Jones]"
    }
  },
  {
    "task_id": 10250,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during {{period}}? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "intent": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during from February 1, 2022 to February 10, 2022? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "As seen in Marketing -> Catalog Price Rule and Marketing -> Cart Price Rules, pants are discounted by 20%, and purchases over $200 also receive a 20% discount. Go to Sales -> Orders, set the Status to Complete, and apply filtering based on Purchase Date. Check the discounts for each order and calculate the total. Note that the difference between Original Price and Price in the Items Ordered section corresponds to the catalog price discount, while the Discount in the Order Totals section corresponds to the cart price discount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "period": "from February 1, 2022 to February 10, 2022",
      "contents": "[96.4, 64.12]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[96.4, 64.12]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[96.4, 64.12]"
    }
  },
  {
    "task_id": 10251,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during {{period}}? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "intent": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during from July 10, 2022 to July 20, 2022? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "As seen in Marketing -> Catalog Price Rule and Marketing -> Cart Price Rules, pants are discounted by 20%, and purchases over $200 also receive a 20% discount. Go to Sales -> Orders, set the Status to Complete, and apply filtering based on Purchase Date. Check the discounts for each order and calculate the total. Note that the difference between Original Price and Price in the Items Ordered section corresponds to the catalog price discount, while the Discount in the Order Totals section corresponds to the cart price discount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "period": "from July 10, 2022 to July 20, 2022",
      "contents": "[12.6, 45.28]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[12.6, 45.28]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[12.6, 45.28]"
    }
  },
  {
    "task_id": 10252,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during {{period}}? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "intent": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during from June 20, 2022 to June 30, 2022? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "As seen in Marketing -> Catalog Price Rule and Marketing -> Cart Price Rules, pants are discounted by 20%, and purchases over $200 also receive a 20% discount. Go to Sales -> Orders, set the Status to Complete, and apply filtering based on Purchase Date. Check the discounts for each order and calculate the total. Note that the difference between Original Price and Price in the Items Ordered section corresponds to the catalog price discount, while the Discount in the Order Totals section corresponds to the cart price discount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "period": "from June 20, 2022 to June 30, 2022",
      "contents": "[23.2, 20.96]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[23.2, 20.96]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[23.2, 20.96]"
    }
  },
  {
    "task_id": 10253,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during {{period}}? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "intent": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during from January 1, 2023 to January 10, 2023? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "As seen in Marketing -> Catalog Price Rule and Marketing -> Cart Price Rules, pants are discounted by 20%, and purchases over $200 also receive a 20% discount. Go to Sales -> Orders, set the Status to Complete, and apply filtering based on Purchase Date. Check the discounts for each order and calculate the total. Note that the difference between Original Price and Price in the Items Ordered section corresponds to the catalog price discount, while the Discount in the Order Totals section corresponds to the cart price discount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "period": "from January 1, 2023 to January 10, 2023",
      "contents": "[27.4, 45.6]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[27.4, 45.6]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[27.4, 45.6]"
    }
  },
  {
    "task_id": 10254,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during {{period}}? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "intent": "What is the total discount amount for both catalog price discount and cart price discount for complete orders during from January 10, 2023 to January 20, 2023? Make sure to check what kind of sales are applied to both the catalog price and cart price. Amount should not be rounded and do not output trailing zeros after the decimal point. Final answer should be in the format '[discount_amount_catalog_price, discount_amount_cart_price]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "As seen in Marketing -> Catalog Price Rule and Marketing -> Cart Price Rules, pants are discounted by 20%, and purchases over $200 also receive a 20% discount. Go to Sales -> Orders, set the Status to Complete, and apply filtering based on Purchase Date. Check the discounts for each order and calculate the total. Note that the difference between Original Price and Price in the Items Ordered section corresponds to the catalog price discount, while the Discount in the Order Totals section corresponds to the cart price discount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "period": "from January 10, 2023 to January 20, 2023",
      "contents": "[13.2, 172.01]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[13.2, 172.01]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[13.2, 172.01]"
    }
  },
  {
    "task_id": 10260,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Tell me the date of the most recent completed order for the product(s) with the {{number}}highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "intent": "Tell me the date of the most recent completed order for the product(s) with the highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "others",
    "description": "Go to Reports -> Reviews -> By Product, and sort by the Average (approved) column to retrieve the product(s) with the {{number}}highest average approved rating. Then, go to Reports -> Products -> Ordered, display the report from 1/8/22 to 5/31/23, and identify the most recent order date for those products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "number": "",
      "contents": "[Dual Handle Cardio Ball, 03/10/23]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Dual Handle Cardio Ball, 03/10/23]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Dual Handle Cardio Ball, 03/10/23]"
    }
  },
  {
    "task_id": 10261,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Tell me the date of the most recent completed order for the product(s) with the {{number}}highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "intent": "Tell me the date of the most recent completed order for the product(s) with the second-highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "others",
    "description": "Go to Reports -> Reviews -> By Product, and sort by the Average (approved) column to retrieve the product(s) with the {{number}}highest average approved rating. Then, go to Reports -> Products -> Ordered, display the report from 1/8/22 to 5/31/23, and identify the most recent order date for those products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "number": "second-",
      "contents": "[Kenobi Trail Jacket, 03/13/22]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Kenobi Trail Jacket, 03/13/22]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Kenobi Trail Jacket, 03/13/22]"
    }
  },
  {
    "task_id": 10262,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Tell me the date of the most recent completed order for the product(s) with the {{number}}highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "intent": "Tell me the date of the most recent completed order for the product(s) with the third-highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "others",
    "description": "Go to Reports -> Reviews -> By Product, and sort by the Average (approved) column to retrieve the product(s) with the {{number}}highest average approved rating. Then, go to Reports -> Products -> Ordered, display the report from 1/8/22 to 5/31/23, and identify the most recent order date for those products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "number": "third-",
      "contents": "[Hyperion Elements Jacket, 09/12/22]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Hyperion Elements Jacket, 09/12/22]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Hyperion Elements Jacket, 09/12/22]"
    }
  },
  {
    "task_id": 10263,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Tell me the date of the most recent completed order for the product(s) with the {{number}}highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "intent": "Tell me the date of the most recent completed order for the product(s) with the fourth-highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "others",
    "description": "Go to Reports -> Reviews -> By Product, and sort by the Average (approved) column to retrieve the product(s) with the {{number}}highest average approved rating. Then, go to Reports -> Products -> Ordered, display the report from 1/8/22 to 5/31/23, and identify the most recent order date for those products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "number": "fourth-",
      "contents": "[Go-Get'r Pushup Grips, 06/14/22]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Go-Get'r Pushup Grips, 06/14/22]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Go-Get'r Pushup Grips, 06/14/22]"
    }
  },
  {
    "task_id": 10264,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "Tell me the date of the most recent completed order for the product(s) with the {{number}}highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "intent": "Tell me the date of the most recent completed order for the product(s) with the fifth-highest average approved rating. If multiple products have the same average rating, provide the date of the oldest order among their most recent completed orders. Exclude product(s) that have reviews but have never been ordered. Note that all orders were placed between January 8, 2022, and May 31, 2023. The date should be in the format month/day/year (e.g., 01/01/20). Final answer should be in the format '[product_name, date]' without reasoning.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "others",
    "description": "Go to Reports -> Reviews -> By Product, and sort by the Average (approved) column to retrieve the product(s) with the {{number}}highest average approved rating. Then, go to Reports -> Products -> Ordered, display the report from 1/8/22 to 5/31/23, and identify the most recent order date for those products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "number": "fifth-",
      "contents": "[Helios EverCool™ Tee, 01/15/22]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Helios EverCool™ Tee, 01/15/22]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Helios EverCool™ Tee, 01/15/22]"
    }
  },
  {
    "task_id": 10270,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the average approved rating of the products in the completed order(s) on {{date}}. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "intent": "List all the average approved rating of the products in the completed order(s) on June 26, 2022. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Sales -> Orders, set the Status to Complete, and identify the orders placed on {{date}}. Then, click the View button to see the details of each order and determine the products that were ordered. Finally, go to Reports -> Reviews -> By Products, search for each product, and retrieve their average approved rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "date": "June 26, 2022",
      "contents": "[N/A, 60, 67, 60]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[N/A, 60, 67, 60]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[N/A, 60, 67, 60]"
    }
  },
  {
    "task_id": 10271,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the average approved rating of the products in the completed order(s) on {{date}}. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "intent": "List all the average approved rating of the products in the completed order(s) on April 27, 2023. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Sales -> Orders, set the Status to Complete, and identify the orders placed on {{date}}. Then, click the View button to see the details of each order and determine the products that were ordered. Finally, go to Reports -> Reviews -> By Products, search for each product, and retrieve their average approved rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "date": "April 27, 2023",
      "contents": "[N/A, N/A, 60, 60, 87]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[N/A, N/A, 60, 60, 87]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[N/A, N/A, 60, 60, 87]"
    }
  },
  {
    "task_id": 10272,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the average approved rating of the products in the completed order(s) on {{date}}. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "intent": "List all the average approved rating of the products in the completed order(s) on April 5, 2023. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Sales -> Orders, set the Status to Complete, and identify the orders placed on {{date}}. Then, click the View button to see the details of each order and determine the products that were ordered. Finally, go to Reports -> Reviews -> By Products, search for each product, and retrieve their average approved rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "date": "April 5, 2023",
      "contents": "[N/A, 80, 80, 70, 87, 70, 70, 60, 67, N/A]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[N/A, 80, 80, 70, 87, 70, 70, 60, 67, N/A]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[N/A, 80, 80, 70, 87, 70, 70, 60, 67, N/A]"
    }
  },
  {
    "task_id": 10273,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the average approved rating of the products in the completed order(s) on {{date}}. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "intent": "List all the average approved rating of the products in the completed order(s) on December 11, 2022. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Sales -> Orders, set the Status to Complete, and identify the orders placed on {{date}}. Then, click the View button to see the details of each order and determine the products that were ordered. Finally, go to Reports -> Reviews -> By Products, search for each product, and retrieve their average approved rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "date": "December 11, 2022",
      "contents": "[60, N/A, 67, N/A, N/A, N/A, 50, 0]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[60, N/A, 67, N/A, N/A, N/A, 50, 0]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[60, N/A, 67, N/A, N/A, N/A, 50, 0]"
    }
  },
  {
    "task_id": 10274,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the average approved rating of the products in the completed order(s) on {{date}}. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "intent": "List all the average approved rating of the products in the completed order(s) on May 2, 2022. The rating is a value between 0 and 100 and final answer should be rounded to the nearest integer. Final answer should be in the format '[rating1, rating2, ...]' without reasoning, and sorted in ascending order of the products' original price. If multiple products have the same original price, their ratings should be sorted by product name in alphabetical order. If there are no reviews for the product, write N/A.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Sales -> Orders, set the Status to Complete, and identify the orders placed on {{date}}. Then, click the View button to see the details of each order and determine the products that were ordered. Finally, go to Reports -> Reviews -> By Products, search for each product, and retrieve their average approved rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/sales/order/",
      "date": "May 2, 2022",
      "contents": "[N/A, 60, 80, N/A, N/A, 87, N/A, N/A]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[N/A, 60, 80, N/A, N/A, 87, N/A, N/A]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[N/A, 60, 80, N/A, N/A, 87, N/A, N/A]"
    }
  },
  {
    "task_id": 10280,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the nicknames of reviewers who created an approved review for {{product_name1}} or {{product_name2}}, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "intent": "List all the nicknames of reviewers who created an approved review for Erica Evercool Sports Bra or Celeste Sports Bra, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Marketing -> User Content -> All Reviews, and filter the reviews by searching for the product in the Product field. Then, click the Edit button to open the details of each review and retrieve the rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_name1": "Erica Evercool Sports Bra",
      "product_name2": "Celeste Sports Bra",
      "contents": "[Ardelia, Eartha, Roxie, Cayla, Jammie, Tonya, Dorcas]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Ardelia, Eartha, Roxie, Cayla, Jammie, Tonya, Dorcas]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Ardelia, Eartha, Roxie, Cayla, Jammie, Tonya, Dorcas]"
    }
  },
  {
    "task_id": 10281,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the nicknames of reviewers who created an approved review for {{product_name1}} or {{product_name2}}, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "intent": "List all the nicknames of reviewers who created an approved review for Helios Endurance Tank or Erikssen CoolTech™ Fitness Tank, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Marketing -> User Content -> All Reviews, and filter the reviews by searching for the product in the Product field. Then, click the Edit button to open the details of each review and retrieve the rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_name1": "Helios Endurance Tank",
      "product_name2": "Erikssen CoolTech™ Fitness Tank",
      "contents": "[Dominic, Scotty, Alexander, Edmund, Trey, Graham, Mervin, Patrick]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Dominic, Scotty, Alexander, Edmund, Trey, Graham, Mervin, Patrick]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Dominic, Scotty, Alexander, Edmund, Trey, Graham, Mervin, Patrick]"
    }
  },
  {
    "task_id": 10282,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the nicknames of reviewers who created an approved review for {{product_name1}} or {{product_name2}}, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "intent": "List all the nicknames of reviewers who created an approved review for Strike Endurance Tee or Logan HeatTec® Tee, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Marketing -> User Content -> All Reviews, and filter the reviews by searching for the product in the Product field. Then, click the Edit button to open the details of each review and retrieve the rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_name1": "Strike Endurance Tee",
      "product_name2": "Logan HeatTec® Tee",
      "contents": "[Carlo, Hiram, Don, Gus, Maynard, Alfred, Hiram]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Carlo, Hiram, Don, Gus, Maynard, Alfred, Hiram]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Carlo, Hiram, Don, Gus, Maynard, Alfred, Hiram]"
    }
  },
  {
    "task_id": 10283,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the nicknames of reviewers who created an approved review for {{product_name1}} or {{product_name2}}, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "intent": "List all the nicknames of reviewers who created an approved review for Cruise Dual Analog Watch or Clamber Watch, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Marketing -> User Content -> All Reviews, and filter the reviews by searching for the product in the Product field. Then, click the Edit button to open the details of each review and retrieve the rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_name1": "Cruise Dual Analog Watch",
      "product_name2": "Clamber Watch",
      "contents": "[Bobby, Nadia, Tommie, Colleen, Laronda, Jamie, Frank]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Bobby, Nadia, Tommie, Colleen, Laronda, Jamie, Frank]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Bobby, Nadia, Tommie, Colleen, Laronda, Jamie, Frank]"
    }
  },
  {
    "task_id": 10284,
    "sites": [
      "shopping_admin"
    ],
    "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
    "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
    "storage_state": "./.auth/shopping_admin_state.json",
    "intent_template": "List all the nicknames of reviewers who created an approved review for {{product_name1}} or {{product_name2}}, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "intent": "List all the nicknames of reviewers who created an approved review for Josie Yoga Jacket or Lando Gym Jacket, sorted in ascending order of rating. If multiple reviews have the same rating, sort these nicknames in alphabetical order. Final answer should be in the format '[nickname1, nickname2, ...]' without reasoning",
    "required_obs": "image",
    "type_main": "long-term",
    "type_sub": "",
    "description": "Go to Marketing -> User Content -> All Reviews, and filter the reviews by searching for the product in the Product field. Then, click the Edit button to open the details of each review and retrieve the rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING_ADMIN__/admin/dashboard/",
      "start_url_lite": "__SHOPPING_ADMIN__/reports/report_review/product/",
      "product_name1": "Josie Yoga Jacket",
      "product_name2": "Lando Gym Jacket",
      "contents": "[Alesha, Emmett, Rudolf, Tennille, Burl, Lakeesha, Elvina]",
      "checkpoint1": "",
      "checkpoint2": "",
      "checkpoint_info": "",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "[Alesha, Emmett, Rudolf, Tennille, Burl, Lakeesha, Elvina]"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[Alesha, Emmett, Rudolf, Tennille, Burl, Lakeesha, Elvina]"
    }
  },
  {
    "task_id": 20000,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/snakebyte-twin-charge-x-xbox-one-controller-charger-dual-docking-charging-station-incl-2-rechargeable-battery-packs-for-xbox-one-controller-elite-s-controller-gamepad-black.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews for {{product}}. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "intent": "Please provide the distribution of reviews for Snakebyte Twin Charge X - Xbox One Controller Charger Dual Docking/Charging Station incl. 2 Rechargeable Battery Packs for XBOX One Controller / Elite / S Controller Gamepad, Black. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, go to the product page and navigate to the reviews page. Then, on the reviews page, count the distribution of review ratings.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/snakebyte-twin-charge-x-xbox-one-controller-charger-dual-docking-charging-station-incl-2-rechargeable-battery-packs-for-xbox-one-controller-elite-s-controller-gamepad-black.html",
      "product": "Snakebyte Twin Charge X - Xbox One Controller Charger Dual Docking/Charging Station incl. 2 Rechargeable Battery Packs for XBOX One Controller / Elite / S Controller Gamepad, Black",
      "contents": "5: 9, 4: 2, 3: 3, 2: 3, 1: 15",
      "checkpoint1": "5, 5, 5, 1, 5, 1, 1, 1, 1, 1",
      "checkpoint2": "1, 1, 1, 1, 1, 1, 2, 4, 4, 3",
      "checkpoint3": "3, 5, 1, 5, 3, 1, 5, 1, 5, 2",
      "checkpoint4": "5, 2",
      "checkpoint_info": "checkpoint1: review in page1, checkpoint2: review in page2, checkpoint3: review in page3",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5: 9, 4: 2, 3: 3, 2: 3, 1: 15"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 9, 4: 2, 3: 3, 2: 3, 1: 15"
    }
  },
  {
    "task_id": 20001,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/denture-case-denture-cups-bath-toothbrush-with-hard-denture-dentures-container-with-basket-denture-holder-for-travel-mouth-guard-night-gum-retainer-container-pink.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews for {{product}}. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "intent": "Please provide the distribution of reviews for Denture Case,Denture Cups Bath, Toothbrush with hard denture, Dentures Container with Basket Denture Holder for Travel,Mouth Guard Night Gum Retainer Container (Pink). Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, go to the product page and navigate to the reviews page. Then, on the reviews page, count the distribution of review ratings.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/denture-case-denture-cups-bath-toothbrush-with-hard-denture-dentures-container-with-basket-denture-holder-for-travel-mouth-guard-night-gum-retainer-container-pink.html",
      "product": "Denture Case,Denture Cups Bath, Toothbrush with hard denture, Dentures Container with Basket Denture Holder for Travel,Mouth Guard Night Gum Retainer Container (Pink)",
      "contents": "5: 42, 4: 6, 3: 8, 2: 7, 1: 7",
      "checkpoint1": "5*8, 3*1, 1*1",
      "checkpoint2": "5*4, 2*1, 1*5",
      "checkpoint3": "5*5, 3*1, 2*3, 1*1",
      "checlpoint4": "5*9, 3*1",
      "checkpoint5": "5*6, 4*1, 3*2, 2*1",
      "checkpoint6": "5*6, 4*3, 3*1",
      "checkpoint7": "5*4, 4*2, 3*2, 2*2",
      "checkpoint_info": "checkpoint1: review in page1, checkpoint2: review in page2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5: 42, 4: 6, 3: 8, 2: 7, 1: 7"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 42, 4: 6, 3: 8, 2: 7, 1: 7"
    }
  },
  {
    "task_id": 20002,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/manhattan-comfort-avesta-double-side-table-2-0-collection-free-standing-modern-side-table-tv-stand-with-storage-includes-2-doors-with-3-shelves-and-features-splayed-legs-white-stamp-grey-legs.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews for {{product}}. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "intent": "Please provide the distribution of reviews for Manhattan Comfort Avesta Double Side Table 2.0 Collection Free Standing Modern Side Table / TV Stand with Storage Includes 2 Doors with 3 Shelves and Features Splayed Legs, White/Stamp/Grey Legs. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, go to the product page and navigate to the reviews page. Then, on the reviews page, count the distribution of review ratings.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/manhattan-comfort-avesta-double-side-table-2-0-collection-free-standing-modern-side-table-tv-stand-with-storage-includes-2-doors-with-3-shelves-and-features-splayed-legs-white-stamp-grey-legs.html",
      "product": "Manhattan Comfort Avesta Double Side Table 2.0 Collection Free Standing Modern Side Table / TV Stand with Storage Includes 2 Doors with 3 Shelves and Features Splayed Legs, White/Stamp/Grey Legs",
      "contents": "5: 16, 4: 23, 3: 17, 2: 8, 1: 6",
      "checkpoint1": "2, 1, 1, 0, 1, 0, 1",
      "checkpoint2": "2, 3, 1, 1, 1, 0, 0",
      "checkpoint3": "2, 2, 1, 2, 3, 2, 5",
      "checkpoint4": "0, 1, 3, 4, 4, 7, 4",
      "checkpoint5": "4, 3, 4, 3, 1, 1, 0",
      "checkpoint_info": "checkpoint1: review in page1, checkpoint2: review in page2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5: 16, 4: 23, 3: 17, 2: 8, 1: 6"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 16, 4: 23, 3: 17, 2: 8, 1: 6"
    }
  },
  {
    "task_id": 20003,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/denture-do-it-yourself-full-set-of-top-and-bottom-fake-teeth-for-improve-smile.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews for {{product}}. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "intent": "Please provide the distribution of reviews for Denture Do it Yourself Full Set of Top and Bottom Fake Teeth for Improve Smile. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, go to the product page and navigate to the reviews page. Then, on the reviews page, count the distribution of review ratings.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/denture-do-it-yourself-full-set-of-top-and-bottom-fake-teeth-for-improve-smile.html",
      "product": "Denture Do it Yourself Full Set of Top and Bottom Fake Teeth for Improve Smile",
      "contents": "5: 6, 4: 6, 3: 10, 2: 5, 1: 45",
      "checkpoint1": "8, 10, 9, 10, 4, 1, 2, 1",
      "checkpoint2": "0, 0, 0, 0, 3, 0, 2, 0",
      "checkpoint3": "0, 0, 0, 0, 2, 5, 2, 1",
      "checkpoint4": "0, 0, 0, 0, 0, 3, 3, 0",
      "checkpoint5": "2, 0, 1, 0, 1, 1, 1, 0",
      "checkpoint_info": "checkpoint1: review in page1, checkpoint2: review in page2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5: 6, 4: 6, 3: 10, 2: 5, 1: 45"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 6, 4: 6, 3: 10, 2: 5, 1: 45"
    }
  },
  {
    "task_id": 20004,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/philadelphia-strawberry-cheesecake-snacks-2-ct-pack-3-25-oz-cups.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews for {{product}}. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "intent": "Please provide the distribution of reviews for Philadelphia Strawberry Cheesecake Snacks (2 ct Pack, 3.25 oz Cups). Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "First, go to the product page and navigate to the reviews page. Then, on the reviews page, count the distribution of review ratings.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/philadelphia-strawberry-cheesecake-snacks-2-ct-pack-3-25-oz-cups.html",
      "product": "Philadelphia Strawberry Cheesecake Snacks (2 ct Pack, 3.25 oz Cups)",
      "contents": "5: 41, 4: 10, 3: 7, 2: 4, 1: 12",
      "checkpoint1": "1, 6, 0, 0, 2, 0, 1, 2",
      "checkpoint2": "0, 1, 1, 0, 0, 2, 0, 0",
      "checkpoint3": "1, 2, 0, 1, 1, 0, 2, 0",
      "checkpoint4": "0, 0, 1, 1, 3, 2, 1, 2",
      "checkpoint5": "8, 1, 8, 8, 4, 6, 6, 0",
      "checkpoint_info": "checkpoint1: review in page1, checkpoint2: review in page2",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5: 41, 4: 10, 3: 7, 2: 4, 1: 12"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 41, 4: 10, 3: 7, 2: 4, 1: 12"
    }
  },
  {
    "task_id": 20010,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/video-games/pc/accessories.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews in the {{category}} category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "intent": "Please provide the distribution of reviews in the Accessories of PC of Video Games category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go to the category page and count the distribution of reviews for the displayed products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/video-games/pc/accessories.html",
      "category": "Accessories of PC of Video Games",
      "contents": "5: 1, 4: 17, 3: 33, 2: 5, 1: 1, 0: 69"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5: 1, 4: 17, 3: 33, 2: 5, 1: 1, 0: 69"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 1, 4: 17, 3: 33, 2: 5, 1: 1, 0: 69"
    }
  },
  {
    "task_id": 20011,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/women/uniforms-work-safety.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews in the {{category}} category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "intent": "Please provide the distribution of reviews in the Uniforms, Work & Safety of Women of Clothing, Shoes & Jewelry category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go to the category page and count the distribution of reviews for the displayed products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/women/uniforms-work-safety.html",
      "category": "Uniforms, Work & Safety of Women of Clothing, Shoes & Jewelry",
      "contents": "5: 6, 4: 21, 3: 11, 2: 2, 1: 1, 0: 67"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5: 6, 4: 21, 3: 11, 2: 2, 1: 1, 0: 67"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 6, 4: 21, 3: 11, 2: 2, 1: 1, 0: 67"
    }
  },
  {
    "task_id": 20012,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/frozen/ice-cream-novelties.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews in the {{category}} category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "intent": "Please provide the distribution of reviews in the Ice Cream & Novelties of Frozen of Grocery & Gourmet Food category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go to the category page and count the distribution of reviews for the displayed products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/frozen/ice-cream-novelties.html",
      "category": "Ice Cream & Novelties of Frozen of Grocery & Gourmet Food",
      "contents": "5: 2, 4: 16, 3: 11, 2: 10, 1: 1, 0: 60"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5: 2, 4: 16, 3: 11, 2: 10, 1: 1, 0: 60"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 2, 4: 16, 3: 11, 2: 10, 1: 1, 0: 60"
    }
  },
  {
    "task_id": 20013,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews in the {{category}} category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "intent": "Please provide the distribution of reviews in the Seafood of Meat & Seafood of Grocery & Gourmet Food category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go to the category page and count the distribution of reviews for the displayed products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html",
      "category": "Seafood of Meat & Seafood of Grocery & Gourmet Food",
      "contents": "5: 11, 4: 12, 3: 12, 2: 4, 1: 3, 0: 98"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5: 11, 4: 12, 3: 12, 2: 4, 1: 3, 0: 98"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 11, 4: 12, 3: 12, 2: 4, 1: 3, 0: 98"
    }
  },
  {
    "task_id": 20014,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/computers-accessories/tablet-accessories.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Please provide the distribution of reviews in the {{category}} category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "intent": "Please provide the distribution of reviews in the Tablet Accessories of Computers & Accessories of Electronics category. Here, the review stars (1~5) correspond to a Rating that is 20 times their value (1 = Rating 20, 2 = Rating 40, 3 = Rating 60, 4 = Rating 80, 5 = Rating 100). If the review star value is a decimal, round it down (e.g., 3.9 -> 3).\nFollow the format below, using numerical values:\n5: {number}, 4: {number}, 3: {number}, 2: {number}, 1: {number}, 0: {number}",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go to the category page and count the distribution of reviews for the displayed products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/computers-accessories/tablet-accessories.html",
      "category": "Tablet Accessories of Computers & Accessories of Electronics",
      "contents": "5: 3, 4: 29, 3: 36, 2: 10, 1: 2, 0: 74"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5: 3, 4: 29, 3: 36, 2: 10, 1: 2, 0: 74"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5: 3, 4: 29, 3: 36, 2: 10, 1: 2, 0: 74"
    }
  },
  {
    "task_id": 20020,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/patio-lawn-garden/gardening-lawn-care.html?cat=179",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the highest-rated product in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "intent": "Tell me the highest-rated product in Gardening & Lawn Care of Patio, Lawn & Garden within the price range of $30 to $69.99. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "Go to the specified category. Then, within the specified price range, select the product with the highest-rated review.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/patio-lawn-garden/gardening-lawn-care.html?cat=179",
      "category": "Gardening & Lawn Care of Patio, Lawn & Garden",
      "minimum_price": "$30",
      "maximum_price": "$69.99",
      "contents": "TOUCH MISS Ceramic Planter for Outdoor Indoor,Ceramic pots for Plants,Small Plant pots Set of 4 Flower Pot 3.35inch Blue, Fat Plants San Diego Miniature Flowering Cactus and Succulent Plant Collection (20)",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "TOUCH MISS Ceramic Planter for Outdoor Indoor,Ceramic pots for Plants,Small Plant pots Set of 4 Flower Pot 3.35inch Blue, Fat Plants San Diego Miniature Flowering Cactus and Succulent Plant Collection (20)"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "TOUCH MISS Ceramic Planter for Outdoor Indoor,Ceramic pots for Plants,Small Plant pots Set of 4 Flower Pot 3.35inch Blue, Fat Plants San Diego Miniature Flowering Cactus and Succulent Plant Collection (20)"
    }
  },
  {
    "task_id": 20021,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/home-audio.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the highest-rated product in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "intent": "Tell me the highest-rated product in Home Audio of Electronics within the price range of $1,000.00 to $4,999.99. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "Go to the specified category. Then, within the specified price range, select the product with the highest-rated review.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/home-audio.html",
      "category": "Home Audio of Electronics",
      "minimum_price": "$1,000.00",
      "maximum_price": "$4,999.99",
      "contents": "REL Acoustics T/7x Subwoofer, 8 inch Front-Firing Driver, Arrow Wireless Port, High Gloss Black",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "REL Acoustics T/7x Subwoofer, 8 inch Front-Firing Driver, Arrow Wireless Port, High Gloss Black"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "REL Acoustics T/7x Subwoofer, 8 inch Front-Firing Driver, Arrow Wireless Port, High Gloss Black"
    }
  },
  {
    "task_id": 20022,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html?cat=204",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the highest-rated product in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "intent": "Tell me the highest-rated product in Chargers & Power Adapters of Accessories of Cell Phones & Accessories within the price range of $30.00 to $69.99. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "Go to the specified category. Then, within the specified price range, select the product with the highest-rated review.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html?cat=204",
      "category": "Chargers & Power Adapters of Accessories of Cell Phones & Accessories",
      "minimum_price": "$30.00",
      "maximum_price": "$69.99",
      "contents": "AMMOD 65W GaN Charger, USB C Wall Charger with Foldable Plug, Type C Charger with 2 Ports Fast Charging for iPhone, MacBook Pro/Air, iPad Pro,Galaxy S20/S10 and More",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "AMMOD 65W GaN Charger, USB C Wall Charger with Foldable Plug, Type C Charger with 2 Ports Fast Charging for iPhone, MacBook Pro/Air, iPad Pro,Galaxy S20/S10 and More"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "AMMOD 65W GaN Charger, USB C Wall Charger with Foldable Plug, Type C Charger with 2 Ports Fast Charging for iPhone, MacBook Pro/Air, iPad Pro,Galaxy S20/S10 and More"
    }
  },
  {
    "task_id": 20023,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the highest-rated product in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "intent": "Tell me the highest-rated product in Accessories of Cell Phones & Accessories within the price range of $200.00 to $600.00. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "Go to the specified category. Then, within the specified price range, select the product with the highest-rated review.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html",
      "category": "Accessories of Cell Phones & Accessories",
      "minimum_price": "$200.00",
      "maximum_price": "$600.00",
      "contents": "Home 5G Cell Phone Signal Booster | Boost 2G/3G/4G LTE 5G Data and Calls | Compatible with All U.S. Carriers Verizon, AT&T, Straight Talk, U.S. Cellular | Cover up to 4,500 sq.ft | FCC Approved",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Home 5G Cell Phone Signal Booster | Boost 2G/3G/4G LTE 5G Data and Calls | Compatible with All U.S. Carriers Verizon, AT&T, Straight Talk, U.S. Cellular | Cover up to 4,500 sq.ft | FCC Approved"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home 5G Cell Phone Signal Booster | Boost 2G/3G/4G LTE 5G Data and Calls | Compatible with All U.S. Carriers Verizon, AT&T, Straight Talk, U.S. Cellular | Cover up to 4,500 sq.ft | FCC Approved"
    }
  },
  {
    "task_id": 20024,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the highest-rated product in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "intent": "Tell me the highest-rated product in Food & Beverage Gifts of Grocery & Gourmet Food within the price range of $100.00 to $399.00. If the average rating is the same, select the product with the highest number of reviews. Output only the full name of the product. If there is more than one matching product, separate them with commas in ascending order of price (e.g., product1, product2).",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "Go to the specified category. Then, within the specified price range, select the product with the highest-rated review.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts.html",
      "category": "Food & Beverage Gifts of Grocery & Gourmet Food",
      "minimum_price": "$100.00",
      "maximum_price": "$399.00",
      "contents": "Greenfire Custom Fortune Cookies, for Advertising and Promotions, Full Color Fortune Printing, Premium Vanilla, Bulk Quantity (120 count)",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Greenfire Custom Fortune Cookies, for Advertising and Promotions, Full Color Fortune Printing, Premium Vanilla, Bulk Quantity (120 count)"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Greenfire Custom Fortune Cookies, for Advertising and Promotions, Full Color Fortune Printing, Premium Vanilla, Bulk Quantity (120 count)"
    }
  },
  {
    "task_id": 20030,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/home-audio.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the top 3 products with the highest number of reviews in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "intent": "Tell me the top 3 products with the highest number of reviews in Home Audio of  Electronics within the price range of $1,000.00 to $9,999.99. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "First, go to the specified category. Then, within the specified price range, select the product with the highest number of reviews.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/home-audio.html",
      "category": "Home Audio of  Electronics",
      "minimum_price": "$1,000.00",
      "maximum_price": "$9,999.99",
      "contents": "Klipsch RP-6000F Floorstanding Speaker (Ebony Pair), Bose Bass Module 700 - Black- Wireless, Compact Subwoofer & Smart Soundbar 900 Dolby Atmos with Alexa Built-in, Bluetooth connectivity - Black, JBL Bar 9.1 - Channel Soundbar System with Surround Speakers and Dolby Atmos",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Klipsch RP-6000F Floorstanding Speaker (Ebony Pair), Bose Bass Module 700 - Black- Wireless, Compact Subwoofer & Smart Soundbar 900 Dolby Atmos with Alexa Built-in, Bluetooth connectivity - Black, JBL Bar 9.1 - Channel Soundbar System with Surround Speakers and Dolby Atmos"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Klipsch RP-6000F Floorstanding Speaker (Ebony Pair), Bose Bass Module 700 - Black- Wireless, Compact Subwoofer & Smart Soundbar 900 Dolby Atmos with Alexa Built-in, Bluetooth connectivity - Black, JBL Bar 9.1 - Channel Soundbar System with Surround Speakers and Dolby Atmos"
    }
  },
  {
    "task_id": 20031,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the top 3 products with the highest number of reviews in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "intent": "Tell me the top 3 products with the highest number of reviews in Accessories of Cell Phones & Accessories within the price range of $80.00 to $699.99. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "First, go to the specified category. Then, within the specified price range, select the product with the highest number of reviews.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories.html",
      "category": "Accessories of Cell Phones & Accessories",
      "minimum_price": "$80.00",
      "maximum_price": "$699.99",
      "contents": "Home Cell Phone Signal Booster Verizon Signal Booster 4G LTE 5G Band 13 Cell Phone Booster Verizon Cell Phone Signal Booster Amplifier Extender to Boost Voice and Data FCC Approved (White), Oculus Go Standalone Virtual Reality Headset - 32GB, weBoost Drive Reach (470154R) Factory Refurbished Vehicle Cell Phone Signal Booster | Car, Truck, Van, or SUV | U.S. Company | All U.S. Networks and Carriers | 1 Year Manufacturer Warranty",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Home Cell Phone Signal Booster Verizon Signal Booster 4G LTE 5G Band 13 Cell Phone Booster Verizon Cell Phone Signal Booster Amplifier Extender to Boost Voice and Data FCC Approved (White), Oculus Go Standalone Virtual Reality Headset - 32GB, weBoost Drive Reach (470154R) Factory Refurbished Vehicle Cell Phone Signal Booster | Car, Truck, Van, or SUV | U.S. Company | All U.S. Networks and Carriers | 1 Year Manufacturer Warranty"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home Cell Phone Signal Booster Verizon Signal Booster 4G LTE 5G Band 13 Cell Phone Booster Verizon Cell Phone Signal Booster Amplifier Extender to Boost Voice and Data FCC Approved (White), Oculus Go Standalone Virtual Reality Headset - 32GB, weBoost Drive Reach (470154R) Factory Refurbished Vehicle Cell Phone Signal Booster | Car, Truck, Van, or SUV | U.S. Company | All U.S. Networks and Carriers | 1 Year Manufacturer Warranty"
    }
  },
  {
    "task_id": 20032,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/video-projectors.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the top 3 products with the highest number of reviews in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "intent": "Tell me the top 3 products with the highest number of reviews in Video Projectors of Electronics within the price range of $900.00 to $3,999.99. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "First, go to the specified category. Then, within the specified price range, select the product with the highest number of reviews.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/video-projectors.html",
      "category": "Video Projectors of Electronics",
      "minimum_price": "$900.00",
      "maximum_price": "$3,999.99",
      "contents": "OMMC 4K UHD Laser TV Home Theatre Projector | Bright 2500 ANSI Lumens | Ultra Short Throw | Built-in Integrated SoundBar | Smart Android System| 3G RAM+64G Storage, Epson Home Cinema 3200 4K PRO-UHD 3-Chip Projector with HDR, Optoma UHD30 True 4K UHD Gaming Projector | 16ms Response Time with Enhanced Gaming Mode | Lowest Input Lag on 4K Projector | 240Hz Refresh Rate | HDR10 & HLG",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "OMMC 4K UHD Laser TV Home Theatre Projector | Bright 2500 ANSI Lumens | Ultra Short Throw | Built-in Integrated SoundBar | Smart Android System| 3G RAM+64G Storage, Epson Home Cinema 3200 4K PRO-UHD 3-Chip Projector with HDR, Optoma UHD30 True 4K UHD Gaming Projector | 16ms Response Time with Enhanced Gaming Mode | Lowest Input Lag on 4K Projector | 240Hz Refresh Rate | HDR10 & HLG"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "OMMC 4K UHD Laser TV Home Theatre Projector | Bright 2500 ANSI Lumens | Ultra Short Throw | Built-in Integrated SoundBar | Smart Android System| 3G RAM+64G Storage, Epson Home Cinema 3200 4K PRO-UHD 3-Chip Projector with HDR, Optoma UHD30 True 4K UHD Gaming Projector | 16ms Response Time with Enhanced Gaming Mode | Lowest Input Lag on 4K Projector | 240Hz Refresh Rate | HDR10 & HLG"
    }
  },
  {
    "task_id": 20033,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/alcoholic-beverages.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the top 3 products with the highest number of reviews in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "intent": "Tell me the top 3 products with the highest number of reviews in Alcoholic Beverages of Grocery & Gourmet Food within the price range of $20.00 to $79.99. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "First, go to the specified category. Then, within the specified price range, select the product with the highest number of reviews.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/alcoholic-beverages.html",
      "category": "Alcoholic Beverages of Grocery & Gourmet Food",
      "minimum_price": "$20.00",
      "maximum_price": "$79.99",
      "contents": "Sutter Home Fre Brut Non-alcoholic Champagne Wine Two Pack (Pack of 2), Heineken, Lager, 6pk, 12 Fl Oz, Underwood The Bubbles Can, 375 ml",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Sutter Home Fre Brut Non-alcoholic Champagne Wine Two Pack (Pack of 2), Heineken, Lager, 6pk, 12 Fl Oz, Underwood The Bubbles Can, 375 ml"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Sutter Home Fre Brut Non-alcoholic Champagne Wine Two Pack (Pack of 2), Heineken, Lager, 6pk, 12 Fl Oz, Underwood The Bubbles Can, 375 ml"
    }
  },
  {
    "task_id": 20034,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sports-outdoors/hunting-fishing.html?price=0-1000",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Tell me the top 3 products with the highest number of reviews in {{category}} within the price range of {{minimum_price}} to {{maximum_price}}. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "intent": "Tell me the top 3 products with the highest number of reviews in Hunting & Fishing of Sports & Outdoors within the price range of $100.00 to $899.99. If multiple products have the same number of reviews, prioritize those with the highest average rating. Output only the full name of the product, listed in descending order by number of reviews and then by rating, separated by commas.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "First, go to the specified category. Then, within the specified price range, select the product with the highest number of reviews.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sports-outdoors/hunting-fishing.html?price=0-1000",
      "category": "Hunting & Fishing of Sports & Outdoors",
      "minimum_price": "$100.00",
      "maximum_price": "$899.99",
      "contents": "Vortex Optics Diamondback Tactical First Focal Plane Riflescopes, ACPOTEL Night Vision Monocular, 5 x 35 Digital Night Vision HD Scopes with Rechargeable/Take Photo/Video Recording/Playback Function for Outdoor/Surveillance/Security/Hunting/Hiking, CREATIVE XP Cellular Trail Cameras - Outdoor Waterproof Security Camera w/ Night Vision for Hunting & Security - 4G Camo",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Vortex Optics Diamondback Tactical First Focal Plane Riflescopes, ACPOTEL Night Vision Monocular, 5 x 35 Digital Night Vision HD Scopes with Rechargeable/Take Photo/Video Recording/Playback Function for Outdoor/Surveillance/Security/Hunting/Hiking, CREATIVE XP Cellular Trail Cameras - Outdoor Waterproof Security Camera w/ Night Vision for Hunting & Security - 4G Camo"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Vortex Optics Diamondback Tactical First Focal Plane Riflescopes, ACPOTEL Night Vision Monocular, 5 x 35 Digital Night Vision HD Scopes with Rechargeable/Take Photo/Video Recording/Playback Function for Outdoor/Surveillance/Security/Hunting/Hiking, CREATIVE XP Cellular Trail Cameras - Outdoor Waterproof Security Camera w/ Night Vision for Hunting & Security - 4G Camo"
    }
  },
  {
    "task_id": 20040,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/office-products/office-electronics/printers-accessories.html",
    "start_url_lite": "__SHOPPING__/office-products/office-electronics/printers-accessories.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Show me the page with the {{status}} Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "intent": "Show me the page with the most recent Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "required_obs": "any",
    "type_main": "others",
    "description": "Record the Data First Available and select the oldest or the most recent one.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/office-products/office-electronics/printers-accessories.html",
      "start_url_lite": "__SHOPPING__/office-products/office-electronics/printers-accessories.html",
      "status": "most recent",
      "contents": "__SHOPPING__/canon-all-in-one-color-inkjet-wired-printer-print-scan-copy-for-home-office-up-to-60-sheets-600-x-1200-dpi-portability-lightweight-pixma-mg2522-w-usb-cable.html",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__SHOPPING__/canon-all-in-one-color-inkjet-wired-printer-print-scan-copy-for-home-office-up-to-60-sheets-600-x-1200-dpi-portability-lightweight-pixma-mg2522-w-usb-cable.html",
      "program_html": [],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 20041,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/office-products/office-electronics/printers-accessories.html?p=2",
    "start_url_lite": "__SHOPPING__/office-products/office-electronics/printers-accessories.html?p=2",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Show me the page with the {{status}} Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "intent": "Show me the page with the most recent Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "required_obs": "any",
    "type_main": "others",
    "description": "Record the Data First Available and select the oldest or the most recent one.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/office-products/office-electronics/printers-accessories.html?p=2",
      "start_url_lite": "__SHOPPING__/office-products/office-electronics/printers-accessories.html?p=2",
      "status": "most recent",
      "contents": "__SHOPPING__/ashata-replacement-printhead-black-printer-print-head-for-p100-xp202-xp102-xp212-tx430-tx430w-xp235-xp211-xp220-sx420-sx425-sx435-me500-me960-etc.html",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__SHOPPING__/ashata-replacement-printhead-black-printer-print-head-for-p100-xp202-xp102-xp212-tx430-tx430w-xp235-xp211-xp220-sx420-sx425-sx435-me500-me960-etc.html",
      "program_html": [],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 20042,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html",
    "start_url_lite": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Show me the page with the {{status}} Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "intent": "Show me the page with the most recent Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "required_obs": "any",
    "type_main": "others",
    "description": "Record the Data First Available and select the oldest or the most recent one.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html",
      "start_url_lite": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html",
      "status": "most recent",
      "contents": "__SHOPPING__/luckxuan-small-corner-bookcase-double-layer-desktop-bookshelf-office-storage-rack-small-printer-stand-save-space-multifunctional-office-desk-storage-rack-l57-d34-h38cm-bookshelf-bookshelves.html",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__SHOPPING__/luckxuan-small-corner-bookcase-double-layer-desktop-bookshelf-office-storage-rack-small-printer-stand-save-space-multifunctional-office-desk-storage-rack-l57-d34-h38cm-bookshelf-bookshelves.html",
      "program_html": [],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 20043,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html?p=2",
    "start_url_lite": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html?p=2",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Show me the page with the {{status}} Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "intent": "Show me the page with the most recent Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "required_obs": "any",
    "type_main": "others",
    "description": "Record the Data First Available and select the oldest or the most recent one.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html?p=2",
      "start_url_lite": "__SHOPPING__/office-products/office-school-supplies/desk-accessories-workspace-organizers.html?p=2",
      "status": "most recent",
      "contents": "__SHOPPING__/mdesign-plastic-divided-drawer-organizer-storage-bin-for-home-office-desk-drawer-shelf-cabinet-4-compartments-12-long-4-pack-32-adhesive-labels-clear.html",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__SHOPPING__/mdesign-plastic-divided-drawer-organizer-storage-bin-for-home-office-desk-drawer-shelf-cabinet-4-compartments-12-long-4-pack-32-adhesive-labels-clear.html",
      "program_html": [],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 20044,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/health-household/household-supplies/household-batteries.html",
    "start_url_lite": "__SHOPPING__/health-household/household-supplies/household-batteries.html",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Show me the page with the {{status}} Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "intent": "Show me the page with the oldest Date First Available among the products displayed on the given page. Please skip the products that do not have the Date First Available information.",
    "required_obs": "any",
    "type_main": "others",
    "description": "Record the Data First Available and select the oldest or the most recent one.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/health-household/household-supplies/household-batteries.html",
      "start_url_lite": "__SHOPPING__/health-household/household-supplies/household-batteries.html",
      "status": "oldest",
      "contents": "__SHOPPING__/duracell-ultra-lithium-battery-3v-cr2-2-batteries-pack-of-2.html",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": null,
      "reference_url": "__SHOPPING__/duracell-ultra-lithium-battery-3v-cr2-2-batteries-pack-of-2.html",
      "program_html": [],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 20050,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Count the total number of products sold in each category ({{category1}}, {{category2}}, {{category3}}, {{category4}}, {{category5}}) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "intent": "Count the total number of products sold in each category (Beauty & Personal Care, Sports & Outdoors, Home & Kitchen, Electronics, Cell Phones & Accessories) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to each category and retrieve the number of displayed products. Then, sort the categories in descending order based on the number of products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "contents": "Beauty & Personal Care, Home & Kitchen, Electronics, Cell Phones & Accessories, Sports & Outdoors",
      "category1": "Beauty & Personal Care",
      "category2": "Sports & Outdoors",
      "category3": "Home & Kitchen",
      "category4": "Electronics",
      "category5": "Cell Phones & Accessories",
      "checkpoint1": "21796",
      "checkpoint2": "884",
      "checkpoint3": "17241",
      "checkpoint4": "14539",
      "checkpoint5": "1924",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Beauty & Personal Care, Home & Kitchen, Electronics, Cell Phones & Accessories, Sports & Outdoors"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Beauty & Personal Care, Home & Kitchen, Electronics, Cell Phones & Accessories, Sports & Outdoors"
    }
  },
  {
    "task_id": 20051,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Count the total number of products sold in each category ({{category1}}, {{category2}}, {{category3}}, {{category4}}, {{category5}}) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "intent": "Count the total number of products sold in each category (Skin Care of Beauty & Personal Care, Men of Clothing, Shoes & Jewelry, Home Audio of Electronics, Office Electronics of Office Products, Xbox One of Video Games) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to each category and retrieve the number of displayed products. Then, sort the categories in descending order based on the number of products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "contents": "Men of Clothing, Shoes & Jewelry, Skin Care of Beauty & Personal Care, Home Audio of Electronics, Office Electronics of Office Products, Xbox One of Video Games",
      "category1": "Skin Care of Beauty & Personal Care",
      "category2": "Men of Clothing, Shoes & Jewelry",
      "category3": "Home Audio of Electronics",
      "category4": "Office Electronics of Office Products",
      "category5": "Xbox One of Video Games",
      "checkpoint1": "3074",
      "checkpoint2": "7648",
      "checkpoint3": "1280",
      "checkpoint4": "488",
      "checkpoint5": "158",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Men of Clothing, Shoes & Jewelry, Skin Care of Beauty & Personal Care, Home Audio of Electronics, Office Electronics of Office Products, Xbox One of Video Games"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Men of Clothing, Shoes & Jewelry, Skin Care of Beauty & Personal Care, Home Audio of Electronics, Office Electronics of Office Products, Xbox One of Video Games"
    }
  },
  {
    "task_id": 20052,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Count the total number of products sold in each category ({{category1}}, {{category2}}, {{category3}}, {{category4}}, {{category5}}) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "intent": "Count the total number of products sold in each category (Gardening & Lawn Care of Patio, Lawn & Garden, Headphones of Electronics, Cell Phones of Cell Phones & Accessories, PlayStation 4 of Video Games, Fan Shop of  Sports & Outdoors) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to each category and retrieve the number of displayed products. Then, sort the categories in descending order based on the number of products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "contents": "Headphones of Electronics, Fan Shop of  Sports & Outdoors, PlayStation 4 of Video Games, Gardening & Lawn Care of Patio, Lawn & Garden, Cell Phones of Cell Phones & Accessories",
      "category1": "Gardening & Lawn Care of Patio, Lawn & Garden",
      "category2": "Headphones of Electronics",
      "category3": "Cell Phones of Cell Phones & Accessories",
      "category4": "PlayStation 4 of Video Games",
      "category5": "Fan Shop of  Sports & Outdoors",
      "checkpoint1": "168",
      "checkpoint2": "631",
      "checkpoint3": "68",
      "checkpoint4": "233",
      "checkpoint5": "338",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Headphones of Electronics, Fan Shop of  Sports & Outdoors, PlayStation 4 of Video Games, Gardening & Lawn Care of Patio, Lawn & Garden, Cell Phones of Cell Phones & Accessories"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Headphones of Electronics, Fan Shop of  Sports & Outdoors, PlayStation 4 of Video Games, Gardening & Lawn Care of Patio, Lawn & Garden, Cell Phones of Cell Phones & Accessories"
    }
  },
  {
    "task_id": 20053,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Count the total number of products sold in each category ({{category1}}, {{category2}}, {{category3}}, {{category4}}, {{category5}}) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "intent": "Count the total number of products sold in each category (Fragrance of Beauty & Personal Care, Video Projectors of Electronics, Cases, Holsters & Sleeves of Cell Phones & Accessories, Deli & Prepared Foods of Grocery & Gourmet Food, PlayStation 4 of Video Games) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to each category and retrieve the number of displayed products. Then, sort the categories in descending order based on the number of products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "contents": "Fragrance of Beauty & Personal Care, Video Projectors of Electronics, Cases, Holsters & Sleeves of Cell Phones & Accessories, PlayStation 4 of Video Games, Deli & Prepared Foods of Grocery & Gourmet Food",
      "category1": "Fragrance of Beauty & Personal Care",
      "category2": "Video Projectors of Electronics",
      "category3": "Cases, Holsters & Sleeves of Cell Phones & Accessories",
      "category4": "Deli & Prepared Foods of Grocery & Gourmet Food",
      "category5": "PlayStation 4 of Video Games",
      "checkpoint1": "1311",
      "checkpoint2": "484",
      "checkpoint3": "457",
      "checkpoint4": "149",
      "checkpoint5": "233",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Fragrance of Beauty & Personal Care, Video Projectors of Electronics, Cases, Holsters & Sleeves of Cell Phones & Accessories, PlayStation 4 of Video Games, Deli & Prepared Foods of Grocery & Gourmet Food"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Fragrance of Beauty & Personal Care, Video Projectors of Electronics, Cases, Holsters & Sleeves of Cell Phones & Accessories, PlayStation 4 of Video Games, Deli & Prepared Foods of Grocery & Gourmet Food"
    }
  },
  {
    "task_id": 20054,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Count the total number of products sold in each category ({{category1}}, {{category2}}, {{category3}}, {{category4}}, {{category5}}) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "intent": "Count the total number of products sold in each category (Over-Ear Headphones of Headphones of Electronics, Chargers & Power Adapters of Accessories of Cell Phones & Accessories, Health Care of Health & Household, Sports of Sports & Outdoors, Bath of Home & Kitchen) and sort them in descending order. Answer in the following format: {category}, {category}, {category}, {category}, {category}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go to each category and retrieve the number of displayed products. Then, sort the categories in descending order based on the number of products.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "contents": "Chargers & Power Adapters of Accessories of Cell Phones & Accessories, Bath of Home & Kitchen, Over-Ear Headphones of Headphones of Electronics, Health Care of Health & Household, Sports of Sports & Outdoors",
      "category1": "Over-Ear Headphones of Headphones of Electronics",
      "category2": "Chargers & Power Adapters of Accessories of Cell Phones & Accessories",
      "category3": "Health Care of Health & Household",
      "category4": "Sports of Sports & Outdoors",
      "category5": "Bath of Home & Kitchen",
      "checkpoint1": "148",
      "checkpoint2": "273",
      "checkpoint3": "86",
      "checkpoint4": "75",
      "checkpoint5": "156",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Chargers & Power Adapters of Accessories of Cell Phones & Accessories, Bath of Home & Kitchen, Over-Ear Headphones of Headphones of Electronics, Health Care of Health & Household, Sports of Sports & Outdoors"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Chargers & Power Adapters of Accessories of Cell Phones & Accessories, Bath of Home & Kitchen, Over-Ear Headphones of Headphones of Electronics, Health Care of Health & Household, Sports of Sports & Outdoors"
    }
  },
  {
    "task_id": 20060,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sales/order/history",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Among my monthly purchase amounts from {{month2}}/{{year2}} to {{month1}}/{{year1}}, tell me the month with the {{order}} purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "intent": "Among my monthly purchase amounts from 11/2022 to 5/2023, tell me the month with the second highest purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "First, check the purchase history. Then, calculate the total purchase amount for each of the specified months.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sales/order/history",
      "contents": "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88",
      "year1": "2023",
      "month1": "5",
      "year2": "2022",
      "month2": "11",
      "order": "second highest",
      "checkpoint1": "2023-5: 0, 2023-3: 83.31, 2023-2: 947.5, 2023-1: 572.88, 2022-12: 203.4, 2022-11: 403.18",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88"
    }
  },
  {
    "task_id": 20061,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sales/order/history",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Among my monthly purchase amounts from {{month2}}/{{year2}} to {{month1}}/{{year1}}, tell me the month with the {{order}} purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "intent": "Among my monthly purchase amounts from 7/2022 to 11/2022, tell me the month with the third highest purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "First, check the purchase history. Then, calculate the total purchase amount for each of the specified months.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sales/order/history",
      "contents": "11/2022, 403.18 |OR| 11/2022, $403.18 |OR| November/2022, 403.18 |OR| November/2022, $403.18",
      "year1": "2022",
      "month1": "11",
      "year2": "2022",
      "month2": "7",
      "order": "third highest",
      "checkpoint1": "2022-11: 403.18, 2022-10: 3336.22, 2022-9: 3024.38, 2022-8: 153.64, 2022-7: 394.82",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "11/2022, 403.18 |OR| 11/2022, $403.18 |OR| November/2022, 403.18 |OR| November/2022, $403.18"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "11/2022, 403.18 |OR| 11/2022, $403.18 |OR| November/2022, 403.18 |OR| November/2022, $403.18"
    }
  },
  {
    "task_id": 20062,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sales/order/history",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Among my monthly purchase amounts from {{month2}}/{{year2}} to {{month1}}/{{year1}}, tell me the month with the {{order}} purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "intent": "Among my monthly purchase amounts from 3/2022 to 7/2022, tell me the month with the highest purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "First, check the purchase history. Then, calculate the total purchase amount for each of the specified months.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sales/order/history",
      "contents": "5/2022, 298.65 |OR| 5/2022, $298.65 |OR| 05/2022, 298.65 |OR| 05/2022, $298.65 |OR| May/2022, 298.65 |OR| May/2022, $298.65",
      "year1": "2022",
      "month1": "7",
      "year2": "2022",
      "month2": "3",
      "order": "highest",
      "checkpoint1": "2022-7: 40.16, 2022-6: 0, 2022-5: 298.65, 2022-4: 102.82, 2022-3: 52.35",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5/2022, 298.65 |OR| 5/2022, $298.65 |OR| 05/2022, 298.65 |OR| 05/2022, $298.65 |OR| May/2022, 298.65 |OR| May/2022, $298.65"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5/2022, 298.65 |OR| 5/2022, $298.65 |OR| 05/2022, 298.65 |OR| 05/2022, $298.65 |OR| May/2022, 298.65 |OR| May/2022, $298.65"
    }
  },
  {
    "task_id": 20063,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sales/order/history",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Among my monthly purchase amounts from {{month2}}/{{year2}} to {{month1}}/{{year1}}, tell me the month with the {{order}} purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "intent": "Among my monthly purchase amounts from 3/2022 to 3/2023, tell me the month with the fourth highest purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "First, check the purchase history. Then, calculate the total purchase amount for each of the specified months.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sales/order/history",
      "contents": "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88",
      "year1": "2023",
      "month1": "3",
      "year2": "2022",
      "month2": "3",
      "order": "fourth highest",
      "checkpoint1": "2023-3: 83.31, 2023-2: 947.5, 2023-1: 572.88, 2022-12: 203.4, 2022-11: 403.18, 2022-10: 3336.22, 2022-9: 3024.38, 2022-8: 153.64, 2022-7: 394.82, 2022-6: 173.56, 2022-5: 298.65, 2022-4: 102.82, 2022-3: 374.12",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1/2023, 572.88 |OR| 1/2023, $572.88 |OR| 01/2023, 572.88 |OR| 01/2023, $572.88 |OR| January/2023, 572.88 |OR| January/2023, $572.88"
    }
  },
  {
    "task_id": 20064,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/sales/order/history",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "Among my monthly purchase amounts from {{month2}}/{{year2}} to {{month1}}/{{year1}}, tell me the month with the {{order}} purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "intent": "Among my monthly purchase amounts from 6/2022 to 1/2023, tell me the month with the seventh highest purchase amount and its value. Only consider purchases that were successfully completed. Provide the answer in the following format: {month}/{year}, {purchase amount}",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "First, check the purchase history. Then, calculate the total purchase amount for each of the specified months.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/sales/order/history",
      "contents": "7/2022, 40.16 |OR| 7/2022, $40.16 |OR| 07/2022, 40.16 |OR| 07/2022, $40.16 |OR| July/2022, 40.16 |OR| July/2022, $40.16",
      "year1": "2023",
      "month1": "1",
      "year2": "2022",
      "month2": "6",
      "order": "seventh highest",
      "checkpoint1": "2022-6: 0, 2022-7: 40.16, 2022-8: 75.98, 2022-9: 3024.38, 2022-10: 1209.9, 2022-11: 403.18, 2022-12: 203.4, 2023-1: 572.88",
      "checkpoint_info": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "7/2022, 40.16 |OR| 7/2022, $40.16 |OR| 07/2022, 40.16 |OR| 07/2022, $40.16 |OR| July/2022, 40.16 |OR| July/2022, $40.16"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "7/2022, 40.16 |OR| 7/2022, $40.16 |OR| 07/2022, 40.16 |OR| 07/2022, $40.16 |OR| July/2022, 40.16 |OR| July/2022, $40.16"
    }
  },
  {
    "task_id": 20070,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please tell me the total price, including shipping fees, for buying {{first_item_count}} units of {{first_item_name}} and {{second_item_count}} units of {{second_item_name}}, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "intent": "Please tell me the total price, including shipping fees, for buying 3 units of Nivea Invisible Black & White Fresh Anti-Perspirant Deodorants - PACK OF 2 X 150 ml and 4 units of Eyebrow Trimmer, Sharpened Blade Facial Shaver Beautiful Delicate with Safety Cover for Eyebrow Shaving for Facial Shaving, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Note down the prices from the product pages and infer the shipping cost from the order history. Finally, calculate the total amount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "first_item_count": "3",
      "first_item_name": "Nivea Invisible Black & White Fresh Anti-Perspirant Deodorants - PACK OF 2 X 150 ml",
      "second_item_count": "4",
      "second_item_name": "Eyebrow Trimmer, Sharpened Blade Facial Shaver Beautiful Delicate with Safety Cover for Eyebrow Shaving for Facial Shaving",
      "ground_truth": "89.83",
      "//comments": "$16.89 x 3 + $7.29 x 4 = $79.83"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "89.83"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20071,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please tell me the total price, including shipping fees, for buying {{first_item_count}} units of {{first_item_name}} and {{second_item_count}} units of {{second_item_name}}, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "intent": "Please tell me the total price, including shipping fees, for buying 2 units of EMMA + OLIVER Stand-Alone Double Study Carrel with Height Adjustable Legs - Nebula Grey Finish and 5 units of File Holder Storage Box File Box Desktop Multi-Function Book Stand Simple Information Frame Office Supplies A+ (Color : Gray, Size : 3 Columns), but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Note down the prices from the product pages and infer the shipping cost from the order history. Finally, calculate the total amount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "first_item_count": "2",
      "first_item_name": "EMMA + OLIVER Stand-Alone Double Study Carrel with Height Adjustable Legs - Nebula Grey Finish",
      "second_item_count": "5",
      "second_item_name": "File Holder Storage Box File Box Desktop Multi-Function Book Stand Simple Information Frame Office Supplies A+ (Color : Gray, Size : 3 Columns)",
      "ground_truth": "1177.88",
      "//comments": "$492.99 x 2 + $36.38 x 5 = $1167.88"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1177.88"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20072,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please tell me the total price, including shipping fees, for buying {{first_item_count}} units of {{first_item_name}} and {{second_item_count}} units of {{second_item_name}}, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "intent": "Please tell me the total price, including shipping fees, for buying 11 units of [Samyang] Buldark Spicy Chicken Roasted Sauce 200g×2 / Korean food / Korean sauce / Asian dishes (overseas direct shipment) and 20 units of Barilla Ready Pasta, Rotini, 8.5 Ounce (Pack of 6), but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Note down the prices from the product pages and infer the shipping cost from the order history. Finally, calculate the total amount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "first_item_count": "11",
      "first_item_name": "[Samyang] Buldark Spicy Chicken Roasted Sauce 200g×2 / Korean food / Korean sauce / Asian dishes (overseas direct shipment)",
      "second_item_count": "20",
      "second_item_name": "Barilla Ready Pasta, Rotini, 8.5 Ounce (Pack of 6)",
      "ground_truth": "380.69",
      "//comments": "$11.99 x 11 + $11.94 x 20 = $370.69"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "380.69"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20073,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please tell me the total price, including shipping fees, for buying {{first_item_count}} units of {{first_item_name}} and {{second_item_count}} units of {{second_item_name}}, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "intent": "Please tell me the total price, including shipping fees, for buying 2 units of 100w 24(20A) Port USB Fast Charging Station,Travel Desktop USB Rapid Charger,Multi Ports Charging Station Organizer for iPhone,Ipad,Samsung and More Devices,fit School,mall,Hotel,Shop and 23 units of USB Type C Charger Cable Fast Charging 10ft,Extra Long 2Pack 10Foot USB A to USB-C Phone Charging Cord for Samsung Galaxy S20 S10 S10E S9 S8 Plus Note 10 9 8,Z Flip,LG V50 V40 V30 V20, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Note down the prices from the product pages and infer the shipping cost from the order history. Finally, calculate the total amount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "first_item_count": "2",
      "first_item_name": "100w 24(20A) Port USB Fast Charging Station,Travel Desktop USB Rapid Charger,Multi Ports Charging Station Organizer for iPhone,Ipad,Samsung and More Devices,fit School,mall,Hotel,Shop",
      "second_item_count": "23",
      "second_item_name": "USB Type C Charger Cable Fast Charging 10ft,Extra Long 2Pack 10Foot USB A to USB-C Phone Charging Cord for Samsung Galaxy S20 S10 S10E S9 S8 Plus Note 10 9 8,Z Flip,LG V50 V40 V30 V20",
      "ground_truth": "379.77",
      "//comments": "$35.50 x 2 + $12.99 x 23 = $369.77"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "379.77"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20074,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please tell me the total price, including shipping fees, for buying {{first_item_count}} units of {{first_item_name}} and {{second_item_count}} units of {{second_item_name}}, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "intent": "Please tell me the total price, including shipping fees, for buying 19 units of Made Terra 2 Tier Woven Hanging Plant Pot Seagrass Wicker Wall Hanging Planter Basket Cover for Flower Pot, Indoor Outdoor Garden Balcony Home Decoration (Natural Stripe) and 9 units of Tosnail 2 Pack Metal Wall Hanging Planter Basket with Coco Liner - Great for Indoor or Outdoor Plants, but do not add them to the cart. Please consider the shipping fee for multiple purchases of a single product to be the same as that for purchasing just one unit of the product.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Note down the prices from the product pages and infer the shipping cost from the order history. Finally, calculate the total amount.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "first_item_count": "19",
      "first_item_name": "Made Terra 2 Tier Woven Hanging Plant Pot Seagrass Wicker Wall Hanging Planter Basket Cover for Flower Pot, Indoor Outdoor Garden Balcony Home Decoration (Natural Stripe)",
      "second_item_count": "9",
      "second_item_name": "Tosnail 2 Pack Metal Wall Hanging Planter Basket with Coco Liner - Great for Indoor or Outdoor Plants",
      "ground_truth": "749.96",
      "//comments": "$29.95 x 19 + $18.99 x 9 = $739.96"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "749.96"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20080,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/snack-gifts.html?product_list_limit=5&product_list_mode=list",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "intent": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Calculate the price per unit weight for all products on the page based on their price and weight, then compare and sort them accordingly.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/snack-gifts.html?product_list_limit=5&product_list_mode=list",
      "start_url_lite": "__SHOPPING__",
      "ground_truth": "B004PR6HPQ, B09LLHRC3W, B07WZPC4WG, B098NRBL68, B005TG4C68",
      "//comments": "69.97$ 6lb (2721g) 0.0257$/g B004PR6HPQ, 44.98$ 2.69lb (1220g) 0.0369$/g B09LLHRC3W, 23.99$ 180g 0.1333$/g B098NRBL68, 28.09$ 90g 0.3121$/g B005TG4C68, 49.99$ 450g 0.1111$/g B07WZPC4WG"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B004PR6HPQ, B09LLHRC3W, B07WZPC4WG, B098NRBL68, B005TG4C68"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20081,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/fruit-nut-gifts.html?product_list_mode=list&product_list_limit=5",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "intent": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Calculate the price per unit weight for all products on the page based on their price and weight, then compare and sort them accordingly.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/fruit-nut-gifts.html?product_list_mode=list&product_list_limit=5",
      "start_url_lite": "__SHOPPING__",
      "ground_truth": "B09NQC6LBJ, B07F1WMJX2, B09MSMWHJJ, B08HRBXD2K, B00CPM4JSU",
      "//comments": "21.69$ 1.01lb 21.48$/lb B00CPM4JSU, 29.95$ 2.5lb 11.93$/lb B09NQC6LBJ, 22.99$ 1.51lb 15.23$/lb B09MSMWHJJ, 34.38$ 2lb 17.19$/lb B08HRBXD2K, 27.99$ 2.05lb 13.65$/lb B07F1WMJX2"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B09NQC6LBJ, B07F1WMJX2, B09MSMWHJJ, B08HRBXD2K, B00CPM4JSU"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20082,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/meat-seafood-gifts.html?p=2&product_list_limit=5&product_list_mode=list",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "intent": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Calculate the price per unit weight for all products on the page based on their price and weight, then compare and sort them accordingly.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/grocery-gourmet-food/food-beverage-gifts/meat-seafood-gifts.html?p=2&product_list_limit=5&product_list_mode=list",
      "start_url_lite": "__SHOPPING__",
      "ground_truth": "B08MX292VN, B00FAPR3LE, B071DVW1VK",
      "//comments": "重さなし, 49.95$ 3lb 16.65$/lb B00FAPR3LE, 399$ 10lb 39.9$/lb B071DVW1VK, 68.95$ 7.09lb 9.72$/lb B08MX292VN, 重さなし"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B08MX292VN, B00FAPR3LE, B071DVW1VK"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20083,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html?product_list_mode=list&product_list_limit=5",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "intent": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Calculate the price per unit weight for all products on the page based on their price and weight, then compare and sort them accordingly.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html?product_list_mode=list&product_list_limit=5",
      "start_url_lite": "__SHOPPING__",
      "ground_truth": "B00HP8UXHU, B00DJLL27W, B00QG2C5NQ, B00B04J6OQ, B085Q4Q7QV",
      "//comments": "14.43$ 2.02lb 7.14$/lb B00HP8UXHU, 6.59$ 0.45oz 0.028lb 235.36$/lb B085Q4Q7QV, 17.99$ 1lb 17.99$/lb B00DJLL27W, 167.5$ 1lb 167.5$/lb B00B04J6OQ, 99.50$ 5lb 19.9$/lb B00QG2C5NQ"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B00HP8UXHU, B00DJLL27W, B00QG2C5NQ, B00B04J6OQ, B085Q4Q7QV"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20084,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/grocery-gourmet-food/beverages/bottled-beverages-water-drink-mixes.html?product_list_mode=list&product_list_limit=5",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "intent": "Among products on this page that have weight information, which one has the lowest price per pound? Sort the SKU numbers in ascending order by price per pound and list them separated by commas followed by a space.",
    "required_obs": "any",
    "type_main": "calc",
    "description": "Calculate the price per unit weight for all products on the page based on their price and weight, then compare and sort them accordingly.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/grocery-gourmet-food/beverages/bottled-beverages-water-drink-mixes.html?product_list_mode=list&product_list_limit=5",
      "start_url_lite": "__SHOPPING__",
      "ground_truth": "B01MT3KBO7, B091B8SW3V, B09BNQM376, B095DK6HBF, B08Z2FR6GQ",
      "//comments": "29.13$ 1.62lb 17.98$/lb B09BNQM376, 15.95$ 7.83oz 0.49lb 32.55$/lb B095DK6HBF, 21.26$ 10.08oz 0.63lb 33.7$/lb B08Z2FR6GQ, 45.00$ 12oz*18 13.5lb 3.33$/lb B091B8SW3V, 24$ 9.45lb 2.54$/lb B01MT3KBO7"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B01MT3KBO7, B091B8SW3V, B09BNQM376, B095DK6HBF, B08Z2FR6GQ"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20090,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
    "intent_template": "Among the {{size}} products in the '{{category}}' category, please tell me which one is the cheapest. Answer SKU number.",
    "intent": "Among the 6.5inch products in the 'Mens' Shoes' category, please tell me which one is the cheapest. Answer SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
      "category": "Mens' Shoes",
      "size": "6.5inch",
      "ground_truth": "B09SB5YHCV"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B09SB5YHCV"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20091,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/television-video/televisions.html?product_list_order=price",
    "intent_template": "Among the {{size}} products in the '{{category}}' category, please tell me which one is the cheapest. Answer SKU number.",
    "intent": "Among the 43inch products in the 'TV' category, please tell me which one is the cheapest. Answer SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/television-video/televisions.html?product_list_order=price",
      "category": "TV",
      "size": "43inch",
      "ground_truth": "B09753NK6N"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B09753NK6N"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20100,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/accessories-supplies/power-strips-surge-protectors.html?product_list_order=price",
    "intent_template": "Among the products {{criteria}} in the '{{category}}' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "intent": "Among the products that have USB Ports in the 'Power Strips & Surge Protectors' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/accessories-supplies/power-strips-surge-protectors.html?product_list_order=price",
      "category": "Power Strips & Surge Protectors",
      "criteria": "that have USB Ports",
      "ground_truth": "B0872P75QM"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B0872P75QM"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20101,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/electronics/headphones/earbud-headphones.html?product_list_order=price",
    "intent_template": "Among the products {{criteria}} in the '{{category}}' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "intent": "Among the products made by JVC in the 'Earbud Headphones' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/electronics/headphones/earbud-headphones.html?product_list_order=price",
      "category": "Earbud Headphones",
      "criteria": "made by JVC",
      "ground_truth": "B08DK5178Y"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B08DK5178Y"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20102,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/dairy-cheese-eggs/cheese.html?product_list_order=price",
    "intent_template": "Among the products {{criteria}} in the '{{category}}' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "intent": "Among the products that contain cheddar cheese in the 'Cheese' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/dairy-cheese-eggs/cheese.html?product_list_order=price",
      "category": "Cheese",
      "criteria": "that contain cheddar cheese",
      "ground_truth": "B01N5WCAKK"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B01N5WCAKK"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20103,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
    "intent_template": "Among the products {{criteria}} in the '{{category}}' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "intent": "Among the products made by leather not sandals in the 'Men's Shoes' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
      "category": "Men's Shoes",
      "criteria": "made by leather not sandals",
      "ground_truth": "B07PP5BMDX"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B07PP5BMDX"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20104,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/cell-phones.html?product_list_order=price",
    "intent_template": "Among the products {{criteria}} in the '{{category}}' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "intent": "Among the products that have 128GB ROM in the 'Cell Phone' category, please tell me the cheapest one with at least 5 reviews and an average rating of 4 or higher out of 5 stars. Answer with SKU number.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through each product one by one until finding one that meets the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/cell-phones.html?product_list_order=price",
      "category": "Cell Phone",
      "criteria": "that have 128GB ROM",
      "ground_truth": "B09HN52ST3"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B09HN52ST3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20110,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please report to the administrator regarding {{category}} products purchased {{date}}. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "intent": "Please report to the administrator regarding cooked food products purchased on March, 2023. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through the order history to find an entry that satisfies the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "category": "cooked food",
      "date": "on March, 2023",
      "SKU": "B005IR33MM",
      "price": "12.99"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "last",
          "locator": "document.querySelector('[title=\"What’s on your mind?\"').value",
          "required_contents": {
            "must_include": [
              "SKU: B005IR33MM\nPrice: $12.99"
            ]
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20111,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please report to the administrator regarding {{category}} products purchased {{date}}. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "intent": "Please report to the administrator regarding furtniture products purchased on February, 2023. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through the order history to find an entry that satisfies the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "category": "furtniture",
      "date": "on February, 2023",
      "SKU": "B099TZT2XR",
      "price": "599.00"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "last",
          "locator": "document.querySelector('[title=\"What’s on your mind?\"').value",
          "required_contents": {
            "must_include": [
              "SKU: B099TZT2XR\nPrice: $599.00"
            ]
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20112,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please report to the administrator regarding {{category}} products purchased {{date}}. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "intent": "Please report to the administrator regarding photo products purchased in 2023. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through the order history to find an entry that satisfies the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "category": "photo",
      "date": "in 2023",
      "SKU": "B09F3JQN4W",
      "price": "33.28"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "last",
          "locator": "document.querySelector('[title=\"What’s on your mind?\"').value",
          "required_contents": {
            "must_include": [
              "SKU: B09F3JQN4W\nPrice: $33.28"
            ]
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20113,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please report to the administrator regarding {{category}} products purchased {{date}}. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "intent": "Please report to the administrator regarding skin care products purchased on November, 2022. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through the order history to find an entry that satisfies the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "category": "skin care",
      "date": "on November, 2022",
      "SKU": "B084WRP9B2",
      "price": "99.99"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "last",
          "locator": "document.querySelector('[title=\"What’s on your mind?\"').value",
          "required_contents": {
            "must_include": [
              "SKU: B084WRP9B2\nPrice: $99.99"
            ]
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20114,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Please report to the administrator regarding {{category}} products purchased {{date}}. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "intent": "Please report to the administrator regarding snack products purchased on April, 2022. Make sure to include the SKU number and price in the following format: ```SKU: {SKU}\nPrice: ${PRICE}```",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Go through the order history to find an entry that satisfies the condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "category": "snack",
      "date": "on April, 2022",
      "SKU": "B07VR1QS11",
      "price": "19.86"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "last",
          "locator": "document.querySelector('[title=\"What’s on your mind?\"').value",
          "required_contents": {
            "must_include": [
              "SKU: B07VR1QS11\nPrice: $19.86"
            ]
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20120,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/health-household/diet-sports-nutrition.html?cat=192&price=10-20",
    "intent_template": "Among the products in the '{{category}}' category within the price range of {{min_dollers}} to {{max_dollers}} dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "intent": "Among the products in the 'Diet & Sports Nutrition' category within the price range of 10.00 to 19.99 dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Record the ratings of all products that meet the condition, and finally output the one with the highest rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/health-household/diet-sports-nutrition.html?cat=192&price=10-20",
      "category": "Diet & Sports Nutrition",
      "min_dollers": "10.00",
      "max_dollers": "19.99",
      "ground_truth": "B07JG914JC"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B07JG914JC"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20121,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/video-games/playstation-4/accessories.html?price=20-30%2C0-100",
    "intent_template": "Among the products in the '{{category}}' category within the price range of {{min_dollers}} to {{max_dollers}} dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "intent": "Among the products in the 'PlayStation4 Accessories' category within the price range of 20.00 to 29.99 dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Record the ratings of all products that meet the condition, and finally output the one with the highest rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/video-games/playstation-4/accessories.html?price=20-30%2C0-100",
      "category": "PlayStation4 Accessories",
      "min_dollers": "20.00",
      "max_dollers": "29.99",
      "ground_truth": "B08JZ2MTMJ"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B08JZ2MTMJ"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20122,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/patio-lawn-garden/gardening-lawn-care/plants-seeds-bulbs.html?price=10-20",
    "intent_template": "Among the products in the '{{category}}' category within the price range of {{min_dollers}} to {{max_dollers}} dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "intent": "Among the products in the 'Plants, Seeds & Bulbs' category within the price range of 10.00 to 19.99 dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Record the ratings of all products that meet the condition, and finally output the one with the highest rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/patio-lawn-garden/gardening-lawn-care/plants-seeds-bulbs.html?price=10-20",
      "category": "Plants, Seeds & Bulbs",
      "min_dollers": "10.00",
      "max_dollers": "19.99",
      "ground_truth": "B07SSFGC5S"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B07SSFGC5S"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20123,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/home-kitchen/bath/bathroom-accessories.html?price=10-20%2C0-100",
    "intent_template": "Among the products in the '{{category}}' category within the price range of {{min_dollers}} to {{max_dollers}} dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "intent": "Among the products in the 'Bathroom Accessories' category within the price range of 10.00 to 19.99 dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Record the ratings of all products that meet the condition, and finally output the one with the highest rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/home-kitchen/bath/bathroom-accessories.html?price=10-20%2C0-100",
      "category": "Bathroom Accessories",
      "min_dollers": "10.00",
      "max_dollers": "19.99",
      "ground_truth": "B092HVZZG4"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B092HVZZG4"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20124,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/cases-holsters-sleeves/flip-cases.html?price=10-20",
    "intent_template": "Among the products in the '{{category}}' category within the price range of {{min_dollers}} to {{max_dollers}} dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "intent": "Among the products in the 'Cell Phone Flip Cases' category within the price range of 10.00 to 19.99 dollars, tell me which one has the highest percentage of reviews with 3 or more stars out of 5, with at least 5 reviews. Answer SKU number.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Record the ratings of all products that meet the condition, and finally output the one with the highest rating.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/cases-holsters-sleeves/flip-cases.html?price=10-20",
      "category": "Cell Phone Flip Cases",
      "min_dollers": "10.00",
      "max_dollers": "19.99",
      "ground_truth": "B097MYR4NQ"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "B097MYR4NQ"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20130,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Extract the title of reviews with a rating of 2 or below out of 5 stars from '{{item_name}}' and output them as a list in alphabetical order, separeted by line breaks.",
    "intent": "Extract the title of reviews with a rating of 2 or below out of 5 stars from 'Tea Gift Set for Tea Lovers - Includes Double Insulated Tea Cup 12 Uniquely Blended Teas and All Natural Honey Straws | Tea Gift Sets for Women Men | Tea Gifts Bag Presented in Beautiful Gift Bag' and output them as a list in alphabetical order, separeted by line breaks.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go through all the reviews and note the titles of those with low ratings. Finally, sort them in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "item_name": "Tea Gift Set for Tea Lovers - Includes Double Insulated Tea Cup 12 Uniquely Blended Teas and All Natural Honey Straws | Tea Gift Sets for Women Men | Tea Gifts Bag Presented in Beautiful Gift Bag",
      "ground_truth": "Absolutely ridiculous!\nCHEAP and non-returnable.\nGarbage.\nMissing all of the product !\nNot worth $30\nVERY DISAPPOINTED and you cannot return!"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Absolutely ridiculous!\nCHEAP and non-returnable.\nGarbage.\nMissing all of the product !\nNot worth $30\nVERY DISAPPOINTED and you cannot return!"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20131,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Extract the title of reviews with a rating of 2 or below out of 5 stars from '{{item_name}}' and output them as a list in alphabetical order, separeted by line breaks.",
    "intent": "Extract the title of reviews with a rating of 2 or below out of 5 stars from 'Pre-Seasoned Garlic and Herb Rub Prime Rib Roast, 1 count, 3.5-4 lb from Kansas City Steaks' and output them as a list in alphabetical order, separeted by line breaks.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go through all the reviews and note the titles of those with low ratings. Finally, sort them in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "item_name": "Pre-Seasoned Garlic and Herb Rub Prime Rib Roast, 1 count, 3.5-4 lb from Kansas City Steaks",
      "ground_truth": "Bad buy on that\nBuy from a reputable butcher for a Prime rib Roast\nDon't buy classic beef cuts online. Buy it in person.\nOver priced very small !\nso small\nTHINK\nVery expensive and disappointing. The dog will eat it, it's not fit for human consumption."
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Bad buy on that\nBuy from a reputable butcher for a Prime rib Roast\nDon't buy classic beef cuts online. Buy it in person.\nOver priced very small !\nso small\nTHINK\nVery expensive and disappointing. The dog will eat it, it's not fit for human consumption."
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20132,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Extract the title of reviews with a rating of 2 or below out of 5 stars from '{{item_name}}' and output them as a list in alphabetical order, separeted by line breaks.",
    "intent": "Extract the title of reviews with a rating of 2 or below out of 5 stars from 'SAMSUNG Galaxy Note 8 N950U 64GB Unlocked GSM 4G LTE Android Smartphone w/Dual 12 MegaPixel Camera (Renewed) (Orchid Grey)' and output them as a list in alphabetical order, separeted by line breaks.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go through all the reviews and note the titles of those with low ratings. Finally, sort them in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "item_name": "SAMSUNG Galaxy Note 8 N950U 64GB Unlocked GSM 4G LTE Android Smartphone w/Dual 12 MegaPixel Camera (Renewed) (Orchid Grey)",
      "ground_truth": "Barely works not worth the money\nCareful which Seller\nDefectuoso\nDO NOT WASTE YOUR MONEY AND AVOID an8 \"refurbished unlocked Verizon Branded Samsung Galaxy Note 8\nEl telÃ©fono saliÃ³ mal,lo regresÃ© y no me han devuelto mi dinero\nNot please\nOne of the two Note 8 phones I took to Africa was mess up, the other is pretty good though\nPhone dont work unless you put it on Speaker.\nPhone not unlocked\nPhone Sent was locked and they would not exchange for unlocked phone advertised\nRUN!!!\nWARNING might not come as described!"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Barely works not worth the money\nCareful which Seller\nDefectuoso\nDO NOT WASTE YOUR MONEY AND AVOID an8 \"refurbished unlocked Verizon Branded Samsung Galaxy Note 8\nEl telÃ©fono saliÃ³ mal,lo regresÃ© y no me han devuelto mi dinero\nNot please\nOne of the two Note 8 phones I took to Africa was mess up, the other is pretty good though\nPhone dont work unless you put it on Speaker.\nPhone not unlocked\nPhone Sent was locked and they would not exchange for unlocked phone advertised\nRUN!!!\nWARNING might not come as described!"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20133,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Extract the title of reviews with a rating of 2 or below out of 5 stars from '{{item_name}}' and output them as a list in alphabetical order, separeted by line breaks.",
    "intent": "Extract the title of reviews with a rating of 2 or below out of 5 stars from 'Bamboo Rolling 6 Tier Plant Stand Rack Multiple Flower Pot Holder Shelf Indoor Outdoor Planter Display Shelving Unit for Patio Garden Corner Balcony Living Room' and output them as a list in alphabetical order, separeted by line breaks.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go through all the reviews and note the titles of those with low ratings. Finally, sort them in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "item_name": "Bamboo Rolling 6 Tier Plant Stand Rack Multiple Flower Pot Holder Shelf Indoor Outdoor Planter Display Shelving Unit for Patio Garden Corner Balcony Living Room",
      "ground_truth": "Cute but No waterproof at all.\nCute but No waterproof at all.\nNot sturdy; do not recommend!! |OR| Cute but No waterproof at all.\nNot sturdy; do not recommend!!"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Cute but No waterproof at all.\nCute but No waterproof at all.\nNot sturdy; do not recommend!! |OR| Cute but No waterproof at all.\nNot sturdy; do not recommend!!"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20134,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__",
    "intent_template": "Extract the title of reviews with a rating of 2 or below out of 5 stars from '{{item_name}}' and output them as a list in alphabetical order, separeted by line breaks.",
    "intent": "Extract the title of reviews with a rating of 2 or below out of 5 stars from 'Waterproof Bone Conduction Headphones for Swimming, IPX8 Open-Ear MP3 Player Wireless Sport Earphones Headset Built-in 8GB Flash Memory for Running, Diving Water, Gym, Spa，Black' and output them as a list in alphabetical order, separeted by line breaks.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "Go through all the reviews and note the titles of those with low ratings. Finally, sort them in alphabetical order.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__",
      "item_name": "Waterproof Bone Conduction Headphones for Swimming, IPX8 Open-Ear MP3 Player Wireless Sport Earphones Headset Built-in 8GB Flash Memory for Running, Diving Water, Gym, Spa，Black",
      "ground_truth": "Disappointed\nFaulty\nNot what I was looking for\nUncomfortable to wear hard to hear\nUncomfortable to wear hard to hear\nVery hard material.\nWas great while it lasted |OR| Disappointed\nFaulty\nNot what I was looking for\nUncomfortable to wear hard to hear\nVery hard material.\nWas great while it lasted"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Disappointed\nFaulty\nNot what I was looking for\nUncomfortable to wear hard to hear\nUncomfortable to wear hard to hear\nVery hard material.\nWas great while it lasted |OR| Disappointed\nFaulty\nNot what I was looking for\nUncomfortable to wear hard to hear\nVery hard material.\nWas great while it lasted"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{{contents}}"
    }
  },
  {
    "task_id": 20140,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/gps-finders-accessories.html",
    "intent_template": "What is the average price of products in {{category}}? Please round to 2 decimal places. Please output only the number",
    "intent": "What is the average price of products in GPS, Finders & Accessories? Please round to 2 decimal places. Please output only the number",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Check the prices of all products in the category and calculate the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/gps-finders-accessories.html",
      "category": "GPS, Finders & Accessories",
      "category_level": "subcategory",
      "contents": "52.66"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "52.66"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "52.66"
    }
  },
  {
    "task_id": 20141,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/health-household/diet-sports-nutrition.html",
    "intent_template": "What is the average price of products in {{category}}? Please round to 2 decimal places. Please output only the number",
    "intent": "What is the average price of products in Diet & Sports Nutrition? Please round to 2 decimal places. Please output only the number",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Check the prices of all products in the category and calculate the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/health-household/diet-sports-nutrition.html",
      "category": "Diet & Sports Nutrition",
      "category_level": "subcategory",
      "contents": "30.46"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "30.46"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "30.46"
    }
  },
  {
    "task_id": 20142,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/security-surveillance/surveillance-video-equipment.html",
    "intent_template": "What is the average price of products in {{category}}? Please round to 2 decimal places. Please output only the number",
    "intent": "What is the average price of products in Surveillance Video Equipment? Please round to 2 decimal places. Please output only the number",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Check the prices of all products in the category and calculate the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/security-surveillance/surveillance-video-equipment.html",
      "category": "Surveillance Video Equipment",
      "category_level": "detailed category",
      "contents": "331.64"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "331.64"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "331.64"
    }
  },
  {
    "task_id": 20143,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/hair-care/hair-treatment-oils.html",
    "intent_template": "What is the average price of products in {{category}}? Please round to 2 decimal places. Please output only the number",
    "intent": "What is the average price of products in Hair Treatment Oils? Please round to 2 decimal places. Please output only the number",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Check the prices of all products in the category and calculate the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/hair-care/hair-treatment-oils.html",
      "category": "Hair Treatment Oils",
      "category_level": "detailed category",
      "contents": "21.87"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "21.87"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "21.87"
    }
  },
  {
    "task_id": 20144,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/pantry-staples/condiments-salad-dressings.html",
    "intent_template": "What is the average price of products in {{category}}? Please round to 2 decimal places. Please output only the number",
    "intent": "What is the average price of products in Condiments & Salad Dressings? Please round to 2 decimal places. Please output only the number",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Check the prices of all products in the category and calculate the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/pantry-staples/condiments-salad-dressings.html",
      "category": "Condiments & Salad Dressings",
      "category_level": "detailed category",
      "contents": "22.96"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "22.96"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "22.96"
    }
  },
  {
    "task_id": 20150,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/mouthwash.html",
    "intent_template": "Calculate the following statistics for the number of reviews in the {{category}} category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "intent": "Calculate the following statistics for the number of reviews in the Mouthwash category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "required_obs": "text",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Check the number of reviews for all products in the category and calculate the maximum, mean, median, and unbiased variance.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/mouthwash.html",
      "category": "Mouthwash",
      "review_stats": "Maximum: 12\nMean: 7.8\nMedian: 10.5\nVariance: 21.3",
      "max_product_name": "Sensodyne Pronamel Mouthwash, 8.4 Ounce (Pack of 2)",
      "review_max": 12,
      "review_mean": 7.8,
      "review_median": 10.5,
      "review_variance": 21.3,
      "num_products_with_reviews": 60
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Maximum: 12\nMean: 7.8\nMedian: 10.5\nVariance: 21.3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Maximum: 12\nMean: 7.8\nMedian: 10.5\nVariance: 21.3"
    }
  },
  {
    "task_id": 20151,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/video-games/playstation-4/accessories.html",
    "intent_template": "Calculate the following statistics for the number of reviews in the {{category}} category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "intent": "Calculate the following statistics for the number of reviews in the Play Station4 Accessories category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "required_obs": "text",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Check the number of reviews for all products in the category and calculate the maximum, mean, median, and unbiased variance.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/video-games/playstation-4/accessories.html",
      "category": "Play Station4 Accessories",
      "review_stats": "Maximum: 32\nMean: 7.6\nMedian: 9.0\nVariance: 28.1",
      "max_product_name": "MXRC Silicone Rubber Cover Skin Case x 1 Anti-Slip Studded Dots Customize for PS4/SLIM/PRO Controller x 1(Pink) + Cat Paw Thumb Grips x 2",
      "review_max": 32,
      "review_mean": 7.6,
      "review_median": 9.0,
      "review_variance": 28.1,
      "num_products_with_reviews": 91
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Maximum: 32\nMean: 7.6\nMedian: 9.0\nVariance: 28.1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Maximum: 32\nMean: 7.6\nMedian: 9.0\nVariance: 28.1"
    }
  },
  {
    "task_id": 20152,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/denture-care.html",
    "intent_template": "Calculate the following statistics for the number of reviews in the {{category}} category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "intent": "Calculate the following statistics for the number of reviews in the Denture Care category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "required_obs": "text",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Check the number of reviews for all products in the category and calculate the maximum, mean, median, and unbiased variance.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/denture-care.html",
      "category": "Denture Care",
      "review_stats": "Maximum: 72\nMean: 12.4\nMedian: 12.0\nVariance: 225.3",
      "max_product_name": "Denture Do it Yourself Full Set of Top and Bottom Fake Teeth for Improve Smile",
      "review_max": 72,
      "review_mean": 12.4,
      "review_median": 12.0,
      "review_variance": 225.3,
      "num_products_with_reviews": 36
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Maximum: 72\nMean: 12.4\nMedian: 12.0\nVariance: 225.3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Maximum: 72\nMean: 12.4\nMedian: 12.0\nVariance: 225.3"
    }
  },
  {
    "task_id": 20153,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/television-video/streaming-media-players.html",
    "intent_template": "Calculate the following statistics for the number of reviews in the {{category}} category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "intent": "Calculate the following statistics for the number of reviews in the Streaming Media Players category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "required_obs": "text",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Check the number of reviews for all products in the category and calculate the maximum, mean, median, and unbiased variance.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/television-video/streaming-media-players.html",
      "category": "Streaming Media Players",
      "review_stats": "Maximum: 12\nMean: 7.4\nMedian: 7.5\nVariance: 21.0",
      "max_product_name": "TiVo TCDA94000 Stream for TiVo Premiere and Roamio DVRs",
      "review_max": 12,
      "review_mean": 7.4,
      "review_median": 7.5,
      "review_variance": 21.0,
      "num_products_with_reviews": 22
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Maximum: 12\nMean: 7.4\nMedian: 7.5\nVariance: 21.0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Maximum: 12\nMean: 7.4\nMedian: 7.5\nVariance: 21.0"
    }
  },
  {
    "task_id": 20154,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/home-kitchen/storage-organization/clothing-closet-storage.html",
    "intent_template": "Calculate the following statistics for the number of reviews in the {{category}} category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "intent": "Calculate the following statistics for the number of reviews in the Clothing & Closet Storage category, considering only products that have at least one review: maximum, mean (rounded to 1 decimal place), median (rounded to 1 decimal place), and variance (unbiased variance, rounded to 1 decimal place). Format your answer exactly as follows on separate lines:\nMaximum: [value]\nMean: [value]\nMedian: [value]\nVariance: [value]",
    "required_obs": "text",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "Check the number of reviews for all products in the category and calculate the maximum, mean, median, and unbiased variance.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/home-kitchen/storage-organization/clothing-closet-storage.html",
      "category": "Clothing & Closet Storage",
      "review_stats": "Maximum: 122\nMean: 12.4\nMedian: 12.0\nVariance: 242.3",
      "max_product_name": "storageLAB Under Bed Shoe Storage Organizer, Adjustable Dividers - Fits Up to 12 Pairs - Underbed Storage Solution (Grey)",
      "review_max": 122,
      "review_mean": 12.4,
      "review_median": 12.0,
      "review_variance": 242.3,
      "num_products_with_reviews": 69
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Maximum: 122\nMean: 12.4\nMedian: 12.0\nVariance: 242.3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Maximum: 122\nMean: 12.4\nMedian: 12.0\nVariance: 242.3"
    }
  },
  {
    "task_id": 20160,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the combined price of the most affordable {{item1_description}} and the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the combined price of the most affordable item between highest-spec Galaxy cell phones (excluding the Note series) in Cell phone category products and the cheapest Flip Case with Card Holder that is compatible with highest-spec Galaxy (excluding the Note series)? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "item between highest-spec Galaxy cell phones (excluding the Note series) in Cell phone category products",
      "item2_description": "Flip Case with Card Holder that is compatible with highest-spec Galaxy (excluding the Note series)",
      "condition": "",
      "item1_price": 534.0,
      "item2_price": 13.99,
      "expected_answer": "547.99",
      "item1_product": "(Renewed) Samsung Galaxy S21 5G, US Version, 128GB, Phantom Gray - Unlocked",
      "item2_product": "Asuwish Compatible with Samsung Galaxy S21 Plus Glaxay S21+ 5G Wallet Case and Tempered Glass Screen Protector Flip Cover Card Holder Cell Phone Cases for Gaxaly S21+5G S21plus 21S + S 21 21+ G5 Blue"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "547.99"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "547.99",
      "price_calculation": "534.0 + 13.99"
    }
  },
  {
    "task_id": 20161,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the combined price of the most affordable {{item1_description}} and the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the combined price of the most affordable items between Latest iPhone in Cell phone category products and the cheapest Flip Case with Card Holder that is compatible with latest iPhone? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "items between Latest iPhone in Cell phone category products",
      "item2_description": "Flip Case with Card Holder that is compatible with latest iPhone",
      "condition": "",
      "item1_price": 448.2,
      "item2_price": 22.99,
      "expected_answer": "471.19",
      "item1_product": "Apple iPhone 12 Mini, 64GB, Black - Verizon (Renewed)",
      "item2_product": "ZVE Wallet Case Compatible with iPhone 12 Mini(2020), Zipper Purse Case with Card Holder Slot Crossbody Chain Wrist Strap Compatible with iPhone 12 Mini,5.4 inch-Rose Gold"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "471.19"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "471.19",
      "price_calculation": "448.2 + 22.99"
    }
  },
  {
    "task_id": 20162,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the combined price of the most affordable {{item1_description}} and the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the combined price of the most affordable smartphone at least 3.5 rating (rating>=70) and 5 review manufactured by Samsung or Apple and the cheapest privacy screen protector compatible with the phone each? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "smartphone at least 3.5 rating (rating>=70) and 5 review manufactured by Samsung or Apple",
      "item2_description": "privacy screen protector compatible with the phone each",
      "condition": "",
      "item1_price": 159.0,
      "item2_price": 5.98,
      "expected_answer": "164.98",
      "item1_product": "Samsung Galaxy A50 US Version Factory Unlocked Cell Phone with 64GB Memory, 6.4\" Screen, Black, [SM-A505UZKNXAA] (Renewed)",
      "item2_product": "[3-Pack] Pokolan Tempered Glass for Samsung Galaxy A50, A30, A30s, A50s, A40, M30, M30s, M31, M21 Screen Protector, Anti Scratch, HD Clear, 9H Hardness, Bubble Free, Easy to Install"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "164.98"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "164.98",
      "price_calculation": "159.0 + 5.98"
    }
  },
  {
    "task_id": 20170,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/home-kitchen/home-decor-products/rugs-pads-protectors.html",
    "intent_template": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of {{category}}. Answer with only the full product name, nothing else.",
    "intent": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of Rugs, Pads & Protectors. Answer with only the full product name, nothing else.",
    "required_obs": "text",
    "type_main": "massive_memory",
    "description": "Go to the specified category and calculate the highest 20% price of the products in that category. Sort the products in descending order by price, then find the product with the highest rating among those with the most reviews within that 20%.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/home-kitchen/home-decor-products/rugs-pads-protectors.html",
      "category": "Rugs, Pads & Protectors",
      "product_name": "Rugs America Area Rug, 8'0\"X10'0\", Carnation",
      "price": 188.84,
      "rating": 5.0,
      "review_count": 2
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Rugs America Area Rug, 8'0\"X10'0\", Carnation"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Rugs America Area Rug, 8'0\"X10'0\", Carnation"
    }
  },
  {
    "task_id": 20171,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/camera-photo/bags-cases.html",
    "intent_template": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of {{category}}. Answer with only the full product name, nothing else.",
    "intent": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of Camera & Photo/Bags & Cases. Answer with only the full product name, nothing else.",
    "required_obs": "text",
    "type_main": "massive_memory",
    "description": "Go to the specified category and calculate the highest 20% price of the products in that category. Sort the products in descending order by price, then find the product with the highest rating among those with the most reviews within that 20%.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/camera-photo/bags-cases.html",
      "category": "Camera & Photo/Bags & Cases",
      "product_name": "SKB iSeries 3i-1309 Military-Grade Waterproof Hard Case for BlackMagic Design Pocket Cinema Camera 4K & Accessories",
      "price": 139.99,
      "rating": 5.0,
      "review_count": 5
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "SKB iSeries 3i-1309 Military-Grade Waterproof Hard Case for BlackMagic Design Pocket Cinema Camera 4K & Accessories"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "SKB iSeries 3i-1309 Military-Grade Waterproof Hard Case for BlackMagic Design Pocket Cinema Camera 4K & Accessories"
    }
  },
  {
    "task_id": 20172,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/frozen/ice-cream-novelties.html",
    "intent_template": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of {{category}}. Answer with only the full product name, nothing else.",
    "intent": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of Ice Cream & Novelties. Answer with only the full product name, nothing else.",
    "required_obs": "text",
    "type_main": "massive_memory",
    "description": "Go to the specified category and calculate the highest 20% price of the products in that category. Sort the products in descending order by price, then find the product with the highest rating among those with the most reviews within that 20%.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/frozen/ice-cream-novelties.html",
      "category": "Ice Cream & Novelties",
      "product_name": "Juve Hydrating Electrolyte Pops (25-35 Calories, 5-7g Sugar, Vitamin B5, B6, B3) [Variety Pack: Triple Berry, Grape, and Orange] 6 Boxes of 12 x 1.79 FL Oz Pops, 72 Count | Buy Now-Freeze Later",
      "price": 60.0,
      "rating": 5.0,
      "review_count": 1
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Juve Hydrating Electrolyte Pops (25-35 Calories, 5-7g Sugar, Vitamin B5, B6, B3) [Variety Pack: Triple Berry, Grape, and Orange] 6 Boxes of 12 x 1.79 FL Oz Pops, 72 Count | Buy Now-Freeze Later"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Juve Hydrating Electrolyte Pops (25-35 Calories, 5-7g Sugar, Vitamin B5, B6, B3) [Variety Pack: Triple Berry, Grape, and Orange] 6 Boxes of 12 x 1.79 FL Oz Pops, 72 Count | Buy Now-Freeze Later"
    }
  },
  {
    "task_id": 20173,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/security-surveillance/surveillance-video-equipment.html",
    "intent_template": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of {{category}}. Answer with only the full product name, nothing else.",
    "intent": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of Surveillance Video Equipment. Answer with only the full product name, nothing else.",
    "required_obs": "text",
    "type_main": "massive_memory",
    "description": "Go to the specified category and calculate the highest 20% price of the products in that category. Sort the products in descending order by price, then find the product with the highest rating among those with the most reviews within that 20%.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/security-surveillance/surveillance-video-equipment.html",
      "category": "Surveillance Video Equipment",
      "product_name": "PANOOB 2-Way Audio 8 Channel 4K PoE Security Camera Systems, 4K/8MP NVR w/2TB HDD - 6Pcs 5MP 2.8mm HD Human Detection Wired Surveillance IP Cameras for 24/7 Business Video Audio Recording",
      "price": 569.99,
      "rating": 5.0,
      "review_count": 2
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "PANOOB 2-Way Audio 8 Channel 4K PoE Security Camera Systems, 4K/8MP NVR w/2TB HDD - 6Pcs 5MP 2.8mm HD Human Detection Wired Surveillance IP Cameras for 24/7 Business Video Audio Recording"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "PANOOB 2-Way Audio 8 Channel 4K PoE Security Camera Systems, 4K/8MP NVR w/2TB HDD - 6Pcs 5MP 2.8mm HD Human Detection Wired Surveillance IP Cameras for 24/7 Business Video Audio Recording"
    }
  },
  {
    "task_id": 20174,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/makeup/makeup-remover.html",
    "intent_template": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of {{category}}. Answer with only the full product name, nothing else.",
    "intent": "Please tell me the full name of the product with the most reviews among the highest-rated products in the highest 20% price range of Makeup Remover. Answer with only the full product name, nothing else.",
    "required_obs": "text",
    "type_main": "massive_memory",
    "description": "Go to the specified category and calculate the highest 20% price of the products in that category. Sort the products in descending order by price, then find the product with the highest rating among those with the most reviews within that 20%.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/makeup/makeup-remover.html",
      "category": "Makeup Remover",
      "product_name": "Diamond Wipes Gentle Makeup Remover Cleansing Face Wipes Case of 500ct Wipes Made with Vitamin E Perfect for Waterproof Makeup",
      "price": 57.95,
      "rating": 4.5,
      "review_count": 12
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Diamond Wipes Gentle Makeup Remover Cleansing Face Wipes Case of 500ct Wipes Made with Vitamin E Perfect for Waterproof Makeup"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Diamond Wipes Gentle Makeup Remover Cleansing Face Wipes Case of 500ct Wipes Made with Vitamin E Perfect for Waterproof Makeup"
    }
  },
  {
    "task_id": 20180,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What month had the highest spending for {{category}} products in my past orders during the period from {{start_date}} to {{end_date}}? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "intent": "What month had the highest spending for Home & Kitchen products in my past orders during the period from August 2022 to November 2022? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Aggregate the prices of items that fall under a specific category from my orders within the specified time period on a monthly basis → Identify the month with the highest total spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "category": "Home & Kitchen",
      "start_date": "August 2022",
      "end_date": "November 2022",
      "highest_month": "October 2022",
      "second_highest_month": "September 2022",
      "highest_amount": "370.87",
      "second_highest_amount": "338.99",
      "percentage_diff": "8.60%",
      "monthly_spending": "• October 2022: $370.87\n• September 2022: $338.99",
      "exact_answer": "October 2022"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "October 2022"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "October 2022"
    }
  },
  {
    "task_id": 20181,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What month had the highest spending for {{category}} products in my past orders during the period from {{start_date}} to {{end_date}}? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "intent": "What month had the highest spending for Electronics products in my past orders during the period from December 2022 to May 2023? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Aggregate the prices of items that fall under a specific category from my orders within the specified time period on a monthly basis → Identify the month with the highest total spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "category": "Electronics",
      "start_date": "December 2022",
      "end_date": "May 2023",
      "highest_month": "February 2023",
      "second_highest_month": "January 2023",
      "highest_amount": "229.63",
      "second_highest_amount": "169.95",
      "percentage_diff": "25.99%",
      "monthly_spending": "• February 2023: $229.63\n• January 2023: $169.95\n• December 2022: $15.49\n• March 2023: $6.28",
      "exact_answer": "February 2023"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "February 2023"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "February 2023"
    }
  },
  {
    "task_id": 20182,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What month had the highest spending for {{category}} products in my past orders during the period from {{start_date}} to {{end_date}}? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "intent": "What month had the highest spending for Home & Kitchen products in my past orders during the period from September 2022 to December 2022? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Aggregate the prices of items that fall under a specific category from my orders within the specified time period on a monthly basis → Identify the month with the highest total spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "category": "Home & Kitchen",
      "start_date": "September 2022",
      "end_date": "December 2022",
      "highest_month": "October 2022",
      "second_highest_month": "September 2022",
      "highest_amount": "370.87",
      "second_highest_amount": "338.99",
      "percentage_diff": "8.60%",
      "monthly_spending": "• October 2022: $370.87\n• September 2022: $338.99\n• December 2022: $59.17",
      "exact_answer": "October 2022"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "October 2022"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "October 2022"
    }
  },
  {
    "task_id": 20183,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What month had the highest spending for {{category}} products in my past orders during the period from {{start_date}} to {{end_date}}? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "intent": "What month had the highest spending for Grocery & Gourmet Food products in my past orders during the period from November 2022 to February 2023? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Aggregate the prices of items that fall under a specific category from my orders within the specified time period on a monthly basis → Identify the month with the highest total spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "category": "Grocery & Gourmet Food",
      "start_date": "November 2022",
      "end_date": "February 2023",
      "highest_month": "December 2022",
      "second_highest_month": "November 2022",
      "highest_amount": "66.27",
      "second_highest_amount": "41.94",
      "percentage_diff": "36.71%",
      "monthly_spending": "• December 2022: $66.27\n• November 2022: $41.94",
      "exact_answer": "December 2022"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "December 2022"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "December 2022"
    }
  },
  {
    "task_id": 20184,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What month had the highest spending for {{category}} products in my past orders during the period from {{start_date}} to {{end_date}}? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "intent": "What month had the highest spending for Electronics products in my past orders during the period from November 2022 to February 2023? Answer with only the month and year in this exact format: '[Month] [Year]' (for example: 'January 2023').",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Aggregate the prices of items that fall under a specific category from my orders within the specified time period on a monthly basis → Identify the month with the highest total spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "category": "Electronics",
      "start_date": "November 2022",
      "end_date": "February 2023",
      "highest_month": "February 2023",
      "second_highest_month": "January 2023",
      "highest_amount": "229.63",
      "second_highest_amount": "169.95",
      "percentage_diff": "25.99%",
      "monthly_spending": "• February 2023: $229.63\n• January 2023: $169.95\n• December 2022: $15.49",
      "exact_answer": "February 2023"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "February 2023"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "February 2023"
    }
  },
  {
    "task_id": 20190,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the full name of the {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "intent": "What is the full name of the lightest selfie stick product in the same subcategory Photo & Video Accessories as the product Tziarp Multifunction 3 in 1 Selfie Stick Wireless Bluetooth Control Extendable Tripod Foldable Rotatable Self-Timer Monopod for Phone from my order number 179?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "179",
      "product_name": "Tziarp Multifunction 3 in 1 Selfie Stick Wireless Bluetooth Control Extendable Tripod Foldable Rotatable Self-Timer Monopod for Phone",
      "category": "Photo & Video Accessories",
      "product_description": "lightest selfie stick product",
      "expected_answer": "2022 Newest Selfie Stick for iPhone with LED Light Wireless Bluetooth Tripod Selfie Stick with Detachable Remote Compatible with iPhone 13/13 Pro/12/11/XR/X/Pro Max/Mini, Android Smartphone -White"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "2022 Newest Selfie Stick for iPhone with LED Light Wireless Bluetooth Tripod Selfie Stick with Detachable Remote Compatible with iPhone 13/13 Pro/12/11/XR/X/Pro Max/Mini, Android Smartphone -White"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2022 Newest Selfie Stick for iPhone with LED Light Wireless Bluetooth Tripod Selfie Stick with Detachable Remote Compatible with iPhone 13/13 Pro/12/11/XR/X/Pro Max/Mini, Android Smartphone -White"
    }
  },
  {
    "task_id": 20191,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the full name of the {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "intent": "What is the full name of the the bread which country of Origin is USA in the same subcategory Breads as the product Whole Foods Market, Bread Batard Olive, 19 Ounce from my order number 162?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "162",
      "product_name": "Whole Foods Market, Bread Batard Olive, 19 Ounce",
      "category": "Breads",
      "product_description": "the bread which country of Origin is USA",
      "expected_answer": "B&M Brown Bread, Original Flavor, 16 Ounce (Pack of 12)"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "B&M Brown Bread, Original Flavor, 16 Ounce (Pack of 12)"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B&M Brown Bread, Original Flavor, 16 Ounce (Pack of 12)"
    }
  },
  {
    "task_id": 20192,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the full name of the {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "intent": "What is the full name of the A product that includes only the film, without a camera. in the same subcategory Film Photography as the product RDPIII 120 Provia 100F from my order number 179?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "179",
      "product_name": "RDPIII 120 Provia 100F",
      "category": "Film Photography",
      "product_description": "A product that includes only the film, without a camera.",
      "expected_answer": "Lomography Color Negative 400 ISO 35mm 3 Pack"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Lomography Color Negative 400 ISO 35mm 3 Pack"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Lomography Color Negative 400 ISO 35mm 3 Pack"
    }
  },
  {
    "task_id": 20193,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the full name of the {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "intent": "What is the full name of the The most cheapest Adapter. in the same subcategory AC Adapters as the product SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2 from my order number 160?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "160",
      "product_name": "SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2",
      "category": "AC Adapters",
      "product_description": "The most cheapest Adapter.",
      "expected_answer": "POWSEED 5V 3A Switching AC Adapter 15W Replacement Power Cord Charger for Android Tablets Webcam Digital Cameras Routers Toys Recorder Bluetooth Speaker TV Box GPS and More 5V Electronics"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "POWSEED 5V 3A Switching AC Adapter 15W Replacement Power Cord Charger for Android Tablets Webcam Digital Cameras Routers Toys Recorder Bluetooth Speaker TV Box GPS and More 5V Electronics"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "POWSEED 5V 3A Switching AC Adapter 15W Replacement Power Cord Charger for Android Tablets Webcam Digital Cameras Routers Toys Recorder Bluetooth Speaker TV Box GPS and More 5V Electronics"
    }
  },
  {
    "task_id": 20194,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the full name of the {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "intent": "What is the full name of the Adapter manufactured by FIT-POWER in the same subcategory AC Adapters as the product SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2 from my order number 160?  The product must have at least 5 reviews, a rating of 3.5 (rating>=70) or higher, and cost between 50%-90% of the original product's price. Answer with only the product's full name, nothing else.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "160",
      "product_name": "SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2",
      "category": "AC Adapters",
      "product_description": "Adapter manufactured by FIT-POWER",
      "expected_answer": "HY1C 24V 1A Power Supply Adapter, 100V-240V AC to DC 24 Volt 1Amp Charger for 24vdc 100mA 500mA 1000mA Christmas LED Strip Light, CCTV Camera, DC Pump, Humidifier, Massage Gun, Mini Printer, Cleaner"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "HY1C 24V 1A Power Supply Adapter, 100V-240V AC to DC 24 Volt 1Amp Charger for 24vdc 100mA 500mA 1000mA Christmas LED Strip Light, CCTV Camera, DC Pump, Humidifier, Massage Gun, Mini Printer, Cleaner"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "HY1C 24V 1A Power Supply Adapter, 100V-240V AC to DC 24 Volt 1Amp Charger for 24vdc 100mA 500mA 1000mA Christmas LED Strip Light, CCTV Camera, DC Pump, Humidifier, Massage Gun, Mini Printer, Cleaner"
    }
  },
  {
    "task_id": 20200,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html",
    "intent_template": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for {{category}}.",
    "intent": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for Automobile Accessories.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, go to the specified category. Then, check the prices of all products in the category and calculate the average price. Finally, find the product with the highest rating and most reviews within 90-120% of the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html",
      "category": "Automobile Accessories",
      "product_name": "andobil Original Magnetic Car Vent Mount Compatible with MagSafe [Case Friendly] Car Mount for iPhone 13 Pro Max 12 Mini [Powerful Magnet] Air Vent Car Phone Holder, Cell Phone Holder for Most of Car",
      "product_url": "__SHOPPING__/andobil-original-magnetic-car-vent-mount-compatible-with-magsafe-case-friendly-car-mount-for-iphone-13-pro-max-12-mini-powerful-magnet-air-vent-car-phone-holder-cell-phone-holder-for-most-of-car.html",
      "avg_price": 26.69,
      "price": 29.98,
      "price_ratio": 1.12,
      "rating": 4.9,
      "review_count": 10
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": "",
      "reference_url": "__SHOPPING__/andobil-original-magnetic-car-vent-mount-compatible-with-magsafe-case-friendly-car-mount-for-iphone-13-pro-max-12-mini-powerful-magnet-air-vent-car-phone-holder-cell-phone-holder-for-most-of-car.html",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/andobil-original-magnetic-car-vent-mount-compatible-with-magsafe-case-friendly-car-mount-for-iphone-13-pro-max-12-mini-powerful-magnet-air-vent-car-phone-holder-cell-phone-holder-for-most-of-car.html"
    }
  },
  {
    "task_id": 20201,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html",
    "intent_template": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for {{category}}.",
    "intent": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for Meat and Seafood, Seafood.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, go to the specified category. Then, check the prices of all products in the category and calculate the average price. Finally, find the product with the highest rating and most reviews within 90-120% of the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/meat-seafood/seafood.html",
      "category": "Meat and Seafood, Seafood",
      "product_name": "Ahi Tuna Loin 4 lbs, Tristan ULT Fresh, #1 Grade, Skinless, Boneless, and Bloodline Removed",
      "product_url": "__SHOPPING__/ahi-tuna-loin-4-lbs-tristan-ult-fresh-1-grade-skinless-boneless-and-bloodline-removed.html",
      "avg_price": 105.34,
      "price": 124.99,
      "price_ratio": 1.19,
      "rating": 5.0,
      "review_count": 1
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": "",
      "reference_url": "__SHOPPING__/ahi-tuna-loin-4-lbs-tristan-ult-fresh-1-grade-skinless-boneless-and-bloodline-removed.html",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/ahi-tuna-loin-4-lbs-tristan-ult-fresh-1-grade-skinless-boneless-and-bloodline-removed.html"
    }
  },
  {
    "task_id": 20202,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/grocery-gourmet-food/deli-prepared-foods.html",
    "intent_template": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for {{category}}.",
    "intent": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for Deli & Prepared Foods.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, go to the specified category. Then, check the prices of all products in the category and calculate the average price. Finally, find the product with the highest rating and most reviews within 90-120% of the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/grocery-gourmet-food/deli-prepared-foods.html",
      "category": "Deli & Prepared Foods",
      "product_name": "Amazon Kitchen, Beef & Broccoli Stir-Fry, No-Prep Kit for 2, 27 oz",
      "product_url": "__SHOPPING__/amazon-kitchen-beef-broccoli-stir-fry-no-prep-kit-for-2-27-oz.html",
      "avg_price": 42.19,
      "price": 44.81,
      "price_ratio": 1.06,
      "rating": 5.0,
      "review_count": 1
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": "",
      "reference_url": "__SHOPPING__/amazon-kitchen-beef-broccoli-stir-fry-no-prep-kit-for-2-27-oz.html",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/amazon-kitchen-beef-broccoli-stir-fry-no-prep-kit-for-2-27-oz.html"
    }
  },
  {
    "task_id": 20203,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/video-games/legacy-systems/playstation-systems.html",
    "intent_template": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for {{category}}.",
    "intent": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for PlayStation Systems.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, go to the specified category. Then, check the prices of all products in the category and calculate the average price. Finally, find the product with the highest rating and most reviews within 90-120% of the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/video-games/legacy-systems/playstation-systems.html",
      "category": "PlayStation Systems",
      "product_name": "KontrolFreek Spaceland Zombies Edition for Playstation 4 (PS4)",
      "product_url": "__SHOPPING__/kontrolfreek-spaceland-zombies-edition-for-playstation-4-ps4.html",
      "avg_price": 30.52,
      "price": 36.6,
      "price_ratio": 1.2,
      "rating": 4.9,
      "review_count": 9
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": "",
      "reference_url": "__SHOPPING__/kontrolfreek-spaceland-zombies-edition-for-playstation-4-ps4.html",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/kontrolfreek-spaceland-zombies-edition-for-playstation-4-ps4.html"
    }
  },
  {
    "task_id": 20204,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/electronics/computers-accessories/tablet-accessories.html",
    "intent_template": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for {{category}}.",
    "intent": "Take me to the page of the product with the most reviews among the highest-rated products priced within 90-120% of the average price for Tablet Accessories.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "First, go to the specified category. Then, check the prices of all products in the category and calculate the average price. Finally, find the product with the highest rating and most reviews within 90-120% of the average price.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/electronics/computers-accessories/tablet-accessories.html",
      "category": "Tablet Accessories",
      "product_name": "Screen Protector for Humminbird Helix 7 G3N (Screen Protector by BoxWave) - ClearTouch Anti-Glare (2-Pack), Anti-Fingerprint Matte Film Skin",
      "product_url": "__SHOPPING__/screen-protector-for-humminbird-helix-7-g3n-screen-protector-by-boxwave-cleartouch-anti-glare-2-pack-anti-fingerprint-matte-film-skin.html",
      "avg_price": 18.21,
      "price": 16.95,
      "price_ratio": 0.93,
      "rating": 5.0,
      "review_count": 4
    },
    "eval": {
      "eval_types": [
        "url_match"
      ],
      "reference_answers": "",
      "reference_url": "__SHOPPING__/screen-protector-for-humminbird-helix-7-g3n-screen-protector-by-boxwave-cleartouch-anti-glare-2-pack-anti-fingerprint-matte-film-skin.html",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/screen-protector-for-humminbird-helix-7-g3n-screen-protector-by-boxwave-cleartouch-anti-glare-2-pack-anti-fingerprint-matte-film-skin.html"
    }
  },
  {
    "task_id": 20210,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}. The products must have at least 5 reviews, a rating of 3.5 (rating >= 70) or higher, and cost between 50%-90% of the original product's price. Answer with only the full product names, nothing else. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of The breads manufactured by Gourmet Market in the same subcategory Breads as the product Whole Foods Market, Bread Batard Olive, 19 Ounce from my order number 162. The products must have at least 5 reviews, a rating of 3.5 (rating >= 70) or higher, and cost between 50%-90% of the original product's price. Answer with only the full product names, nothing else. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "162",
      "product_name": "Whole Foods Market, Bread Batard Olive, 19 Ounce",
      "category": "Breads",
      "product_description": "The breads manufactured by Gourmet Market",
      "expected_products": "Authentic German Klosterbrot Bread Pack of 2, Jewish Rye Bread Pack of 4",
      "expected_answer": "B088DLW8V1\nB08922FBD7"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B088DLW8V1\nB08922FBD7"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B088DLW8V1\nB08922FBD7"
    }
  },
  {
    "task_id": 20211,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of {{product_description}} in the same subcategory {{category}} as the product {{product_name}} from my order number {{order_number}}. The products must have at least 5 reviews, a rating of 3.5 (rating >= 70) or higher, and cost between 50%-90% of the original product's price. Answer with only the full product names, nothing else. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of Adapters with exchange periods longer than one year in the same subcategory AC Adapters as the product SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2 from my order number 160. The products must have at least 5 reviews, a rating of 3.5 (rating >= 70) or higher, and cost between 50%-90% of the original product's price. Answer with only the full product names, nothing else. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the specified item from the order → Navigate to its category and identify the items that meet the latter condition within that category, making a note of each item and its location → Review all the noted items and search for the one that satisfies the {{product_description}} condition.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "160",
      "product_name": "SupplySource AC-DC Adapter for Sony Playstation VR Virtual Reality Headset PSVR PSVR2",
      "category": "AC Adapters",
      "product_description": "Adapters with exchange periods longer than one year",
      "expected_products": "Pwr+ Charger for Booster PAC ES5000 ES2500 J900 ESA218: ES6000 ES1224 ESA217 ESA214 ESA22 Power Supply AC Adapter Extra Long 6.7 Ft Cord UL Listed Replacement with Small Jack\n9V AC Power Cord for Schwinn A10 A20 430 420 460 101 130 150 170 202 220 230 240 270 Bike Exercise Elliptical Recumbent Upright Trainer Power Supply",
      "expected_answer": "B076CTVS7L\nB08Z71243H"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B076CTVS7L\nB08Z71243H"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B076CTVS7L\nB08Z71243H"
    }
  },
  {
    "task_id": 20220,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List the top 3 categories with the highest spending from my past orders during the period from {{start_date}} to {{end_date}}. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "intent": "List the top 3 categories with the highest spending from my past orders during the period from March 2022 to August 2022. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Classify the items from my orders within a specified time period into major categories and calculate the total spending for each. Then, compute the percentage share of each category and list the top 3 categories by spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "period": "First half 2022",
      "start_date": "March 2022",
      "end_date": "August 2022",
      "total_spending": "494.96",
      "top_spending_categories": "Home & Kitchen: 55%\nGrocery & Gourmet Food: 30%\nBeauty & Personal Care: 10%"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Home & Kitchen: 55%\nGrocery & Gourmet Food: 30%\nBeauty & Personal Care: 10%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home & Kitchen: 55%\nGrocery & Gourmet Food: 30%\nBeauty & Personal Care: 10%"
    }
  },
  {
    "task_id": 20221,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List the top 3 categories with the highest spending from my past orders during the period from {{start_date}} to {{end_date}}. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "intent": "List the top 3 categories with the highest spending from my past orders during the period from July 2022 to September 2022. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Classify the items from my orders within a specified time period into major categories and calculate the total spending for each. Then, compute the percentage share of each category and list the top 3 categories by spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "period": "Summer 2022",
      "start_date": "July 2022",
      "end_date": "September 2022",
      "total_spending": "3060.52",
      "top_spending_categories": "Office Products: 80%\nHome & Kitchen: 10%\nElectronics: 5%"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Office Products: 80%\nHome & Kitchen: 10%\nElectronics: 5%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Office Products: 80%\nHome & Kitchen: 10%\nElectronics: 5%"
    }
  },
  {
    "task_id": 20222,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List the top 3 categories with the highest spending from my past orders during the period from {{start_date}} to {{end_date}}. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "intent": "List the top 3 categories with the highest spending from my past orders during the period from March 2022 to June 2022. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Classify the items from my orders within a specified time period into major categories and calculate the total spending for each. Then, compute the percentage share of each category and list the top 3 categories by spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "period": "Spring 2022",
      "start_date": "March 2022",
      "end_date": "June 2022",
      "total_spending": "413.82",
      "top_spending_categories": "Home & Kitchen: 65%\nGrocery & Gourmet Food: 30%\nClothing, Shoes & Jewelry: 5%"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Home & Kitchen: 65%\nGrocery & Gourmet Food: 30%\nClothing, Shoes & Jewelry: 5%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home & Kitchen: 65%\nGrocery & Gourmet Food: 30%\nClothing, Shoes & Jewelry: 5%"
    }
  },
  {
    "task_id": 20223,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List the top 3 categories with the highest spending from my past orders during the period from {{start_date}} to {{end_date}}. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "intent": "List the top 3 categories with the highest spending from my past orders during the period from January 2023 to March 2023. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Classify the items from my orders within a specified time period into major categories and calculate the total spending for each. Then, compute the percentage share of each category and list the top 3 categories by spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "period": "Winter 2023",
      "start_date": "January 2023",
      "end_date": "March 2023",
      "total_spending": "1508.69",
      "top_spending_categories": "Home & Kitchen: 60%\nElectronics: 25%\nBeauty & Personal Care: 5%"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Home & Kitchen: 60%\nElectronics: 25%\nBeauty & Personal Care: 5%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home & Kitchen: 60%\nElectronics: 25%\nBeauty & Personal Care: 5%"
    }
  },
  {
    "task_id": 20224,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List the top 3 categories with the highest spending from my past orders during the period from {{start_date}} to {{end_date}}. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "intent": "List the top 3 categories with the highest spending from my past orders during the period from October 2022 to December 2022. For each category, show the name and the percentage of the total amount spent (excluding shipping costs) during this period, rounded to the nearest 5% (e.g., 30%, 35%, 40%). Format each line as 'Category: X%'. Categories should be from (Beauty & Personal Care, Cell Phones & Accessories, Clothing, Shoes & Jewelry, Electronics, Grocery & Gourmet Food, Health & Household, Home & Kitchen, Office Products, Patio, Lawn & Garden, Sports & Outdoors, Tools & Home Improvement, Video Games).",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Classify the items from my orders within a specified time period into major categories and calculate the total spending for each. Then, compute the percentage share of each category and list the top 3 categories by spending.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "period": "Fall 2022",
      "start_date": "October 2022",
      "end_date": "December 2022",
      "total_spending": "1662.49",
      "top_spending_categories": "Home & Kitchen: 25%\nBeauty & Personal Care: 20%\nElectronics: 20%"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Home & Kitchen: 25%\nBeauty & Personal Care: 20%\nElectronics: 20%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Home & Kitchen: 25%\nBeauty & Personal Care: 20%\nElectronics: 20%"
    }
  },
  {
    "task_id": 20230,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of products in the {{category}} category that are priced within 60-80% of the original product {{product}} from my Order {{order_number}} and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of products in the Home Storage Hooks category that are priced within 60-80% of the original product NOZE Rustic Coat Rack Wall Mounted Shelf with 4 Hooks, Hanging Entryway Organizer for Mug Coffee Cup, Holding Solid Wooden Shelf with 2 Baskets for Kitchen Living Room, Bathroom and Bedroom from my Order 170 and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the corresponding product from the Order. Next, navigate to the Category, and save the SKUs of all products within the category that meet the price constraint.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "170",
      "product": "NOZE Rustic Coat Rack Wall Mounted Shelf with 4 Hooks, Hanging Entryway Organizer for Mug Coffee Cup, Holding Solid Wooden Shelf with 2 Baskets for Kitchen Living Room, Bathroom and Bedroom",
      "category": "Home Storage Hooks",
      "original_price": "40.99",
      "original_rating": "3.9",
      "cheaper_better_products": "LIANTRAL Wall Mounted Coat Rack, 15-Inch, Set of 2 Wood Rustic Coat Hooks with 4 Hooks for Entryway, Mudroom, Bathroom, Kitchen(Brown), Coat Rack Wall Mounted, 5 Tri Hooks, 2 Pack Wall Hook Rack, Wooden Base, Metal Coat Hook Rail for Coat Hat Key, Rustic Coat Rack for Entryway Bathroom Bedroom Kitchen, Coat Hooks for Wall, Walnut Wood Wall Hooks with 5 Swivel Foldable Arms, 12'' Length Wall Coat Rack Hat Hooks for Bathroom Entryway Bedroom Office Kitchen, Heavy Duty, MaxGear Coat Rack Wall Mount, 2 Pack Coat Hanger Hat Rack for Wall, Coat Hooks Wall Hook Rack Heavy Duty Hook Rail Wooden Wall Rack with Hooks Peg Rack Purse Rack Backpack Hanger (Bamboo), Halcent Entryway Mail Organizer Coat Rack Key Holder Hooks, Newspaper Magazine Holder with Memo Board Wall Decor, EXCELLO GLOBAL PRODUCTS Rustic Barn Wood Wall Mounted 38 by 10 in Hanging Entryway Coat Rack with 7 Hooks, BirdRock Home Dual Hook Coat and Hat Rack - 4 Dual Hooks - 17 Inches - Wall Mount - Decorative Home Storage - Entryway Foyer Hallway Bathroom Bedroom Rail - Satin Nickel Hooks - White Pine Bathroom Ra, Cast Iron Deer Head Double Hook Wall Key Rack Holder Hooks Coat Hook Home Decor, EMERIT Mail Holder Organzier Wall Mount Key Holder Rack Hanging Entryway Decorative Shelf (White 1)",
      "cheaper_better_skus": "B004WSVYP6\nB01K5YOTOI\nB07FD1YMZH\nB07HQB5L3Z\nB07ZKGFT2V\nB088QYFHCP\nB08H4XQLV5\nB08YRG3L3T\nB09NVS2G2J"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B004WSVYP6\nB01K5YOTOI\nB07FD1YMZH\nB07HQB5L3Z\nB07ZKGFT2V\nB088QYFHCP\nB08H4XQLV5\nB08YRG3L3T\nB09NVS2G2J"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B004WSVYP6\nB01K5YOTOI\nB07FD1YMZH\nB07HQB5L3Z\nB07ZKGFT2V\nB088QYFHCP\nB08H4XQLV5\nB08YRG3L3T\nB09NVS2G2J"
    }
  },
  {
    "task_id": 20231,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of products in the {{category}} category that are priced within 60-80% of the original product {{product}} from my Order {{order_number}} and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of products in the PlayStation Systems category that are priced within 60-80% of the original product Designer Skin for Sony PlayStation PS3 SLIM System & Remote Controllers -Big Ballin from my Order 180 and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the corresponding product from the Order. Next, navigate to the Category, and save the SKUs of all products within the category that meet the price constraint.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "180",
      "product": "Designer Skin for Sony PlayStation PS3 SLIM System & Remote Controllers -Big Ballin",
      "category": "PlayStation Systems",
      "original_price": "1.63",
      "original_rating": "4.2",
      "cheaper_better_products": "Vivi Audio For Slim PS3 Playstation 3 Power Eject Ribbon Cable CECH-3001A 3001B, Sony Playstaton Portable System - Ceramic White PSP (Japan)",
      "cheaper_better_skus": "B000U696NG\nB014HDAUAA"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B000U696NG\nB014HDAUAA"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B000U696NG\nB014HDAUAA"
    }
  },
  {
    "task_id": 20232,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of products in the {{category}} category that are priced within 60-80% of the original product {{product}} from my Order {{order_number}} and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of products in the Sets & Kits category that are priced within 60-80% of the original product Your Selfie-Ready Skincare 5-Piece Hydrating, Radiance-Boosting Super Set - Your Skin But Better Primer, Je Ne Sais Quoi Lip Treatment, Bye Bye Under Eye, Secret Sauce, and Miracle Water from my Order 164 and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the corresponding product from the Order. Next, navigate to the Category, and save the SKUs of all products within the category that meet the price constraint.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "164",
      "product": "Your Selfie-Ready Skincare 5-Piece Hydrating, Radiance-Boosting Super Set - Your Skin But Better Primer, Je Ne Sais Quoi Lip Treatment, Bye Bye Under Eye, Secret Sauce, and Miracle Water",
      "category": "Sets & Kits",
      "original_price": "99.99",
      "original_rating": "5.0",
      "cheaper_better_products": "Clinique 3-Step Skin Care System For Skin Type 2 Dry to Dry Combination Skin",
      "cheaper_better_skus": "B00FBBJOW8"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B00FBBJOW8"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B00FBBJOW8"
    }
  },
  {
    "task_id": 20233,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "List only the SKUs (without any additional text) of products in the {{category}} category that are priced within 60-80% of the original product {{product}} from my Order {{order_number}} and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "intent": "List only the SKUs (without any additional text) of products in the Condiments & Salad Dressings category that are priced within 60-80% of the original product Pure Horseradish - 8oz Jar - Homestyle from my Order 165 and have a higher rating than the original product. Format your answer with one SKU per line, sorted alphabetically.",
    "required_obs": "text",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Retrieve the price of the corresponding product from the Order. Next, navigate to the Category, and save the SKUs of all products within the category that meet the price constraint.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "order_number": "165",
      "product": "Pure Horseradish - 8oz Jar - Homestyle",
      "category": "Condiments & Salad Dressings",
      "original_price": "8.00",
      "original_rating": "3.9",
      "cheaper_better_products": "Kraft Classic Catalina Fat Free Salad Dressing (16 fl oz Bottle), Grey Poupon Dijon Mustard (6 ct Casepack, 48 oz Jars)",
      "cheaper_better_skus": "B00I8GJLOO\nB00OKFXVAC"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "B00I8GJLOO\nB00OKFXVAC"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "B00I8GJLOO\nB00OKFXVAC"
    }
  },
  {
    "task_id": 20240,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest item among Nintendo Switch controller combined with the cheapest Switch kaset, each with 10 or more reviews? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "item among Nintendo Switch controller",
      "item2_description": "Switch kaset",
      "condition": ", each with 10 or more reviews",
      "item1_price": 3.66,
      "item2_price": 16.74,
      "expected_answer": "20.40 |OR| 20.4",
      "item1_product": "",
      "item2_product": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "20.40 |OR| 20.4"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "20.40 |OR| 20.4",
      "price_calculation": "3.66 + 16.74"
    }
  },
  {
    "task_id": 20241,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest item among Nintendo Switch controller combined with the cheapest Switch kaset, each with a review rating of 3 (rating=60) or higher? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "item among Nintendo Switch controller",
      "item2_description": "Switch kaset",
      "condition": ", each with a review rating of 3 (rating=60) or higher",
      "item1_price": 86.0,
      "item2_price": 16.74,
      "expected_answer": "102.74",
      "item1_product": "",
      "item2_product": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "102.74"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "102.74",
      "price_calculation": "86.0 + 16.74"
    }
  },
  {
    "task_id": 20242,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest plant seeds combined with the cheapest product from the \"Planter, Pots\" category, each with 10 or more reviews? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "plant seeds",
      "item2_description": "product from the \"Planter, Pots\" category",
      "condition": ", each with 10 or more reviews",
      "item1_price": 6.49,
      "item2_price": 13.99,
      "expected_answer": "20.48",
      "item1_product": "",
      "item2_product": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "20.48"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "20.48",
      "price_calculation": "6.49 + 13.99"
    }
  },
  {
    "task_id": 20243,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest plant seeds combined with the cheapest product from the \"Planter, Pots\" category, each with a review rating of 4 (rating=80) or higher? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "plant seeds",
      "item2_description": "product from the \"Planter, Pots\" category",
      "condition": ", each with a review rating of 4 (rating=80) or higher",
      "item1_price": 14.95,
      "item2_price": 13.99,
      "expected_answer": "28.94",
      "item1_product": "",
      "item2_product": ""
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "28.94"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "28.94",
      "price_calculation": "14.95 + 13.99"
    }
  },
  {
    "task_id": 20244,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest spa bed or table product in the Spa Beds & Tables category that costs at least costs 50$ combined with the cheapest spa trolley or cart product in the Spa Storage Systems category that costs at least costs 20$? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "spa bed or table product in the Spa Beds & Tables category that costs at least costs 50$",
      "item2_description": "spa trolley or cart product in the Spa Storage Systems category that costs at least costs 20$",
      "condition": "",
      "item1_price": 64.99,
      "item2_price": 28.07,
      "expected_answer": "93.06",
      "item1_product": "Sentiment 73 Inches Long 28 Inches Wide Folding Portable Massage Table with Carrying case, Black",
      "item2_product": "50kg Load Rolling Beauty Salon Trolley Bracket, Beauty Salon Storage Equipment, SPA Tool Trolley, ABS Salon Trolley, Beauty Equipment Machine,Mobile Mental Stand Trolley Rolling Cart Shelf"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "93.06"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "93.06",
      "price_calculation": "64.99 + 28.07"
    }
  },
  {
    "task_id": 20245,
    "sites": [
      "shopping"
    ],
    "start_url": "__SHOPPING__/",
    "start_url_lite": "__SHOPPING__/",
    "storage_state": "./.auth/shopping_state.json",
    "intent_template": "What is the total price of the cheapest {{item1_description}} combined with the cheapest {{item2_description}}{{condition}}? Please only output the number.",
    "intent": "What is the total price of the cheapest spa bed or table product in the Spa Beds & Tables category combined with the cheapest spa trolley or cart product in the Spa Storage Systems category, each with 5 or more reviews and rating greater than 3.5 (rating>=70)? Please only output the number.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Extract all items from the lists of {product1} and {product2} that meet the {condition} → Among them, find the cheapest item from each list and add their prices together.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__/",
      "start_url_lite": "__SHOPPING__/",
      "item1_description": "spa bed or table product in the Spa Beds & Tables category",
      "item2_description": "spa trolley or cart product in the Spa Storage Systems category",
      "condition": ", each with 5 or more reviews and rating greater than 3.5 (rating>=70)",
      "item1_price": 78.99,
      "item2_price": 89.88,
      "expected_answer": "168.87",
      "item1_product": "Yaheetech Portable Massage Table 84inch Massage Bed Aluminium Height Adjustable Facial Salon Tattoo Bed Black",
      "item2_product": "Beauty Salon Black Hair Color Tray Portable Utility Cart"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "168.87"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "168.87",
      "price_calculation": "78.99 + 89.88"
    }
  },
  {
    "task_id": 30000,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze {{number}} submissions from my account. Please count how many times I’ve posted in each forum, and return the result in the following dictionary format, sorted by the number of posts in descending order. If multiple forums have the same number of posts, sort them alphabetically by forum name: forum3: 51, forum1: 25, forum2: 4, forum6: 4,...",
    "intent": "I want to analyze the top 600 most recent submissions from my account. Please count how many times I’ve posted in each forum, and return the result in the following dictionary format, sorted by the number of posts in descending order. If multiple forums have the same number of posts, sort them alphabetically by forum name: forum3: 51, forum1: 25, forum2: 4, forum6: 4,...",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and count how many of them have been posted to each forum. Finally, report that count.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "the top 600 most recent",
      "contents": "television: 395, movies: 204, technology: 1",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "television: 395, movies: 204, technology: 1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "television: 395, movies: 204, technology: 1"
    }
  },
  {
    "task_id": 30001,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze {{number}} submissions from my account. Please count how many times I’ve posted in each forum, and return the result in the following dictionary format, sorted by the number of posts in descending order. If multiple forums have the same number of posts, sort them alphabetically by forum name: forum3: 51, forum1: 25, forum2: 4, forum6: 4,...",
    "intent": "I want to analyze all the submissions from my account. Please count how many times I’ve posted in each forum, and return the result in the following dictionary format, sorted by the number of posts in descending order. If multiple forums have the same number of posts, sort them alphabetically by forum name: forum3: 51, forum1: 25, forum2: 4, forum6: 4,...",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and count how many of them have been posted to each forum. Finally, report that count.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "all the",
      "contents": "television: 405, movies: 259, MachineLearning: 1, Music: 1, technology: 1",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "television: 405, movies: 259, MachineLearning: 1, Music: 1, technology: 1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "television: 405, movies: 259, MachineLearning: 1, Music: 1, technology: 1"
    }
  },
  {
    "task_id": 30010,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "In my submissions, how many places from the most recent is the one I submitted to the forum {{forum}}?",
    "intent": "In my submissions, how many places from the most recent is the one I submitted to the forum movies?",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and count how many of them have been posted to each forum. Finally, report that count.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "forum": "movies",
      "contents": "60",
      "checkpoint1": "10",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "60"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "60"
    }
  },
  {
    "task_id": 30020,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/cutie_chipmunk/comments",
    "start_url_lite": "__REDDIT__/user/cutie_chipmunk/comments",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the total number of upvotes that {{user}}'s comments have received? (If an upvote is negative, exclude it from the count.)",
    "intent": "What is the total number of upvotes that cutie_chipmunk's comments have received? (If an upvote is negative, exclude it from the count.)",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum up the number of upvotes on the user's comments. Do not count any upvotes that are negative.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/cutie_chipmunk/comments",
      "start_url_lite": "__REDDIT__/user/cutie_chipmunk/comments",
      "user": "cutie_chipmunk",
      "contents": "61",
      "checkpoint1": "44",
      "checkpoint2": "17"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "61"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "61"
    }
  },
  {
    "task_id": 30021,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/Reselects420/comments",
    "start_url_lite": "__REDDIT__/user/Reselects420/comments",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the total number of upvotes that {{user}}'s comments have received? (If an upvote is negative, exclude it from the count.)",
    "intent": "What is the total number of upvotes that Reselects420's comments have received? (If an upvote is negative, exclude it from the count.)",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum up the number of upvotes on the user's comments. Do not count any upvotes that are negative.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/Reselects420/comments",
      "start_url_lite": "__REDDIT__/user/Reselects420/comments",
      "user": "Reselects420",
      "contents": "860",
      "checkpoint1": "584",
      "checkpoint2": "248",
      "checkpoint3": "28"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "860"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "860"
    }
  },
  {
    "task_id": 30022,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/Justtryme90/comments",
    "start_url_lite": "__REDDIT__/user/Justtryme90/comments",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the total number of upvotes that {{user}}'s comments have received? (If an upvote is negative, exclude it from the count.)",
    "intent": "What is the total number of upvotes that Justtryme90's comments have received? (If an upvote is negative, exclude it from the count.)",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum up the number of upvotes on the user's comments. Do not count any upvotes that are negative.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/Justtryme90/comments",
      "start_url_lite": "__REDDIT__/user/Justtryme90/comments",
      "user": "Justtryme90",
      "contents": "562",
      "checkpoint1": "451",
      "checkpoint2": "111"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "562"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "562"
    }
  },
  {
    "task_id": 30023,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/Gonzostewie/comments",
    "start_url_lite": "__REDDIT__/user/Gonzostewie/comments",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the total number of upvotes that {{user}}'s comments have received? (If an upvote is negative, exclude it from the count.)",
    "intent": "What is the total number of upvotes that Gonzostewie's comments have received? (If an upvote is negative, exclude it from the count.)",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum up the number of upvotes on the user's comments. Do not count any upvotes that are negative.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/Gonzostewie/comments",
      "start_url_lite": "__REDDIT__/user/Gonzostewie/comments",
      "user": "Gonzostewie",
      "contents": "834",
      "checkpoint1": "167",
      "checkpoint2": "564",
      "checkpoint3": "103"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "834"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "834"
    }
  },
  {
    "task_id": 30024,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/pmk0286/comments",
    "start_url_lite": "__REDDIT__/user/pmk0286/comments",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the total number of upvotes that {{user}}'s comments have received? (If an upvote is negative, exclude it from the count.)",
    "intent": "What is the total number of upvotes that pmk0286's comments have received? (If an upvote is negative, exclude it from the count.)",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum up the number of upvotes on the user's comments. Do not count any upvotes that are negative.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/pmk0286/comments",
      "start_url_lite": "__REDDIT__/user/pmk0286/comments",
      "user": "pmk0286",
      "contents": "85",
      "checkpoint1": "69",
      "checkpoint2": "16"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "85"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "85"
    }
  },
  {
    "task_id": 30030,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/news",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "intent": "Among the top 150 hottest submissions in the forum news, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the specified forum. Then, check the number of hottest submissions and count the number of comments on each post. Finally, display the results grouped by every 20 posts. Treat any post with 200 or more comments as a single group.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/news",
      "forum": "news",
      "number": "150",
      "contents": "0-19: 0, 20-39: 4, 40-59: 3, 60-79: 11, 80-99: 16, 100-119: 18, 120-139: 18, 140-159: 25, 160-179: 16, 180-199: 22, 200-: 17"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0-19: 0, 20-39: 4, 40-59: 3, 60-79: 11, 80-99: 16, 100-119: 18, 120-139: 18, 140-159: 25, 160-179: 16, 180-199: 22, 200-: 17"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0-19: 0, 20-39: 4, 40-59: 3, 60-79: 11, 80-99: 16, 100-119: 18, 120-139: 18, 140-159: 25, 160-179: 16, 180-199: 22, 200-: 17"
    }
  },
  {
    "task_id": 30031,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/news",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "intent": "Among the top 100 hottest submissions in the forum news, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the specified forum. Then, check the number of hottest submissions and count the number of comments on each post. Finally, display the results grouped by every 20 posts. Treat any post with 200 or more comments as a single group.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/news",
      "forum": "news",
      "number": "100",
      "contents": "0-19: 0, 20-39: 2, 40-59: 2, 60-79: 8, 80-99: 13, 100-119: 9, 120-139: 13, 140-159: 14, 160-179: 11, 180-199: 15, 200-: 13"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0-19: 0, 20-39: 2, 40-59: 2, 60-79: 8, 80-99: 13, 100-119: 9, 120-139: 13, 140-159: 14, 160-179: 11, 180-199: 15, 200-: 13"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0-19: 0, 20-39: 2, 40-59: 2, 60-79: 8, 80-99: 13, 100-119: 9, 120-139: 13, 140-159: 14, 160-179: 11, 180-199: 15, 200-: 13"
    }
  },
  {
    "task_id": 30032,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/nyc",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "intent": "Among the top 150 hottest submissions in the forum nyc, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the specified forum. Then, check the number of hottest submissions and count the number of comments on each post. Finally, display the results grouped by every 20 posts. Treat any post with 200 or more comments as a single group.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/nyc",
      "forum": "nyc",
      "number": "150",
      "contents": "0-19: 9, 20-39: 19, 40-59: 11, 60-79: 14, 80-99: 14, 100-119: 22, 120-139: 12, 140-159: 16, 160-179: 19, 180-199: 12, 200-: 2",
      "checkpoint1": "194"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0-19: 9, 20-39: 19, 40-59: 11, 60-79: 14, 80-99: 14, 100-119: 22, 120-139: 12, 140-159: 16, 160-179: 19, 180-199: 12, 200-: 2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0-19: 9, 20-39: 19, 40-59: 11, 60-79: 14, 80-99: 14, 100-119: 22, 120-139: 12, 140-159: 16, 160-179: 19, 180-199: 12, 200-: 2"
    }
  },
  {
    "task_id": 30033,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/nyc",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "intent": "Among the top 100 hottest submissions in the forum nyc, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the specified forum. Then, check the number of hottest submissions and count the number of comments on each post. Finally, display the results grouped by every 20 posts. Treat any post with 200 or more comments as a single group.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/nyc",
      "forum": "nyc",
      "number": "100",
      "contents": "0-19: 3, 20-39: 10, 40-59: 8, 60-79: 8, 80-99: 12, 100-119: 14, 120-139: 12, 140-159: 14, 160-179: 10, 180-199: 8, 200-: 1",
      "checkpoint1": "174"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0-19: 3, 20-39: 10, 40-59: 8, 60-79: 8, 80-99: 12, 100-119: 14, 120-139: 12, 140-159: 14, 160-179: 10, 180-199: 8, 200-: 1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0-19: 3, 20-39: 10, 40-59: 8, 60-79: 8, 80-99: 12, 100-119: 14, 120-139: 12, 140-159: 14, 160-179: 10, 180-199: 8, 200-: 1"
    }
  },
  {
    "task_id": 30034,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Futurology",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "intent": "Among the top 150 hottest submissions in the forum Futurology, please show how many posts fall into each 20-comment range. Treat all posts with 200 or more comments as a single range. Format the output as follows: '0-19: 5, 20-39: 3, 40-59: 2, 60-79: 0, 80-99: 0, 100-119: 7, 120-139: 2, 140-159: 1, 160-179: 0, 180-199: 0, 200-: 0'.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, navigate to the specified forum. Then, check the number of hottest submissions and count the number of comments on each post. Finally, display the results grouped by every 20 posts. Treat any post with 200 or more comments as a single group.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Futurology",
      "forum": "Futurology",
      "number": "150",
      "contents": "0-19: 6, 20-39: 13, 40-59: 18, 60-79: 16, 80-99: 19, 100-119: 29, 120-139: 11, 140-159: 10, 160-179: 13, 180-199: 13, 200-: 2",
      "checkpoint1": "191"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0-19: 6, 20-39: 13, 40-59: 18, 60-79: 16, 80-99: 19, 100-119: 29, 120-139: 11, 140-159: 10, 160-179: 13, 180-199: 13, 200-: 2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0-19: 6, 20-39: 13, 40-59: 18, 60-79: 16, 80-99: 19, 100-119: 29, 120-139: 11, 140-159: 10, 160-179: 13, 180-199: 13, 200-: 2"
    }
  },
  {
    "task_id": 30040,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=chatgpt",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze the popularity of \"{{keyword1}}\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"{{keyword1}}\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "intent": "I want to analyze the popularity of \"chatgpt\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"chatgpt\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, search for keyword1 and check the submissions that come up. Then, sum the upvote counts for each forum and finally answer the total number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=chatgpt",
      "keyword1": "chatgpt",
      "contents": "'MachineLearning': 2001, 'singularity': 853, 'technology': 471, 'Futurology': 104, 'coolgithubprojects': 29, 'Music': 0",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "'MachineLearning': 2001, 'singularity': 853, 'technology': 471, 'Futurology': 104, 'coolgithubprojects': 29, 'Music': 0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "'MachineLearning': 2001, 'singularity': 853, 'technology': 471, 'Futurology': 104, 'coolgithubprojects': 29, 'Music': 0"
    }
  },
  {
    "task_id": 30041,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=CMU",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze the popularity of \"{{keyword1}}\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"{{keyword1}}\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "intent": "I want to analyze the popularity of \"CMU\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"CMU\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, search for keyword1 and check the submissions that come up. Then, sum the upvote counts for each forum and finally answer the total number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=CMU",
      "keyword1": "CMU",
      "contents": "'pittsburgh': 295, 'MachineLearning': 26, 'DIY': 6, 'dataisbeautiful': 6, 'Pennsylvania': 3, 'Futurology': 1",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "'pittsburgh': 295, 'MachineLearning': 26, 'DIY': 6, 'dataisbeautiful': 6, 'Pennsylvania': 3, 'Futurology': 1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "'pittsburgh': 295, 'MachineLearning': 26, 'DIY': 6, 'dataisbeautiful': 6, 'Pennsylvania': 3, 'Futurology': 1"
    }
  },
  {
    "task_id": 30042,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=twitter",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze the popularity of \"{{keyword1}}\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"{{keyword1}}\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "intent": "I want to analyze the popularity of \"twitter\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"twitter\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, search for keyword1 and check the submissions that come up. Then, sum the upvote counts for each forum and finally answer the total number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=twitter",
      "keyword1": "twitter",
      "contents": "'technology': 1783, 'news': 1297, 'MachineLearning': 889, 'wallstreetbets': 682, 'memes': 225, 'nottheonion': 74, 'newhampshire': 22, 'dataisbeautiful': 20, 'LifeProTips': 5, 'science': 4, 'explainlikeimfive': 2, 'AskReddit': 2, 'Jokes': 1, 'Futurology': 0, 'relationship_advice': 0, 'Music': 0, 'gifs': 0",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "'technology': 1783, 'news': 1297, 'MachineLearning': 889, 'wallstreetbets': 682, 'memes': 225, 'nottheonion': 74, 'newhampshire': 22, 'dataisbeautiful': 20, 'LifeProTips': 5, 'science': 4, 'explainlikeimfive': 2, 'AskReddit': 2, 'Jokes': 1, 'Futurology': 0, 'relationship_advice': 0, 'Music': 0, 'gifs': 0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "'technology': 1783, 'news': 1297, 'MachineLearning': 889, 'wallstreetbets': 682, 'memes': 225, 'nottheonion': 74, 'newhampshire': 22, 'dataisbeautiful': 20, 'LifeProTips': 5, 'science': 4, 'explainlikeimfive': 2, 'AskReddit': 2, 'Jokes': 1, 'Futurology': 0, 'relationship_advice': 0, 'Music': 0, 'gifs': 0"
    }
  },
  {
    "task_id": 30043,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=instagram",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "I want to analyze the popularity of \"{{keyword1}}\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"{{keyword1}}\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "intent": "I want to analyze the popularity of \"instagram\". Popularity is determined by the relationship between the forums and the number of upvotes that appear when searching for \"instagram\". Please provide the total number of upvotes for each forum. When the upvote score is negative, use the absolute value of that score. The format should be as follows, sorted in descending order of total count: 'forum1': 54, 'forum2': 26, ...",
    "required_obs": "text",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, search for keyword1 and check the submissions that come up. Then, sum the upvote counts for each forum and finally answer the total number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=instagram",
      "keyword1": "instagram",
      "contents": "'GetMotivated': 20059, 'Showerthoughts': 3473, 'sports': 2865, 'technology': 1031, 'science': 812, 'dataisbeautiful': 628, 'rva': 436, 'philadelphia': 348, 'newjersey': 175, 'nottheonion': 135, 'baltimore': 100, 'relationship_advice': 36, 'wallstreetbets': 27, 'newhampshire': 22, 'tifu': 19, 'news': 11, 'gifs': 3, 'iphone': 2, 'worldnews': 2, 'UpliftingNews': 2, 'Music': 1, 'massachusetts': 0, 'Connecticut': 0",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "'GetMotivated': 20059, 'Showerthoughts': 3473, 'sports': 2865, 'technology': 1031, 'science': 812, 'dataisbeautiful': 628, 'rva': 436, 'philadelphia': 348, 'newjersey': 175, 'nottheonion': 135, 'baltimore': 100, 'relationship_advice': 36, 'wallstreetbets': 27, 'newhampshire': 22, 'tifu': 19, 'news': 11, 'gifs': 3, 'iphone': 2, 'worldnews': 2, 'UpliftingNews': 2, 'Music': 1, 'massachusetts': 0, 'Connecticut': 0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "'GetMotivated': 20059, 'Showerthoughts': 3473, 'sports': 2865, 'technology': 1031, 'science': 812, 'dataisbeautiful': 628, 'rva': 436, 'philadelphia': 348, 'newjersey': 175, 'nottheonion': 135, 'baltimore': 100, 'relationship_advice': 36, 'wallstreetbets': 27, 'newhampshire': 22, 'tifu': 19, 'news': 11, 'gifs': 3, 'iphone': 2, 'worldnews': 2, 'UpliftingNews': 2, 'Music': 1, 'massachusetts': 0, 'Connecticut': 0"
    }
  },
  {
    "task_id": 30050,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/news",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "intent": "Among the top 600 hottest submissions in the forum news, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "First, go to the specified forum page. Then, check the most recent number of submissions and count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/news",
      "forum": "news",
      "number": "600",
      "contents": "439",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "439"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "439"
    }
  },
  {
    "task_id": 30051,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/AskReddit",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "intent": "Among the top 600 hottest submissions in the forum AskReddit, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "First, go to the specified forum page. Then, check the most recent number of submissions and count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/AskReddit",
      "forum": "AskReddit",
      "number": "600",
      "contents": "526",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "526"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "526"
    }
  },
  {
    "task_id": 30052,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/nyc",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "intent": "Among the top 600 hottest submissions in the forum nyc, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "First, go to the specified forum page. Then, check the most recent number of submissions and count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/nyc",
      "forum": "nyc",
      "number": "600",
      "contents": "354",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "354"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "354"
    }
  },
  {
    "task_id": 30053,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/worldnews",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "intent": "Among the top 600 hottest submissions in the forum worldnews, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "First, go to the specified forum page. Then, check the most recent number of submissions and count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/worldnews",
      "forum": "worldnews",
      "number": "600",
      "contents": "362",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "362"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "362"
    }
  },
  {
    "task_id": 30054,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Futurology",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Among the top {{number}} hottest submissions in the forum {{forum}}, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "intent": "Among the top 600 hottest submissions in the forum Futurology, count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "First, go to the specified forum page. Then, check the most recent number of submissions and count how many unique users have posted a submission. Treat all deleted users as one unique user.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Futurology",
      "forum": "Futurology",
      "number": "600",
      "contents": "248",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "248"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "248"
    }
  },
  {
    "task_id": 30060,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the {{order}} upvoted post among my last {{number}} submissions? Please answer the title of the post and do not include any other information.",
    "intent": "What is the most upvoted post among my last 75 submissions? Please answer the title of the post and do not include any other information.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and find the {{order}} upvoted post. Finally, report the title of that post.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "75",
      "order": "most",
      "contents": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record",
      "checkpoint1": "656",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record"
    }
  },
  {
    "task_id": 30061,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the {{order}} upvoted post among my last {{number}} submissions? Please answer the title of the post and do not include any other information.",
    "intent": "What is the most upvoted post among my last 125 submissions? Please answer the title of the post and do not include any other information.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and find the {{order}} upvoted post. Finally, report the title of that post.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "125",
      "order": "most",
      "contents": "Martin Scorsese’s ‘Killers of the Flower Moon’ Will Have World Premiere at Cannes Film Festival",
      "checkpoint1": "2792",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "Martin Scorsese’s ‘Killers of the Flower Moon’ Will Have World Premiere at Cannes Film Festival"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Martin Scorsese’s ‘Killers of the Flower Moon’ Will Have World Premiere at Cannes Film Festival"
    }
  },
  {
    "task_id": 30062,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the {{order}} upvoted post among my last {{number}} submissions? Please answer the title of the post and do not include any other information.",
    "intent": "What is the most upvoted post among my last 55 submissions? Please answer the title of the post and do not include any other information.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and find the {{order}} upvoted post. Finally, report the title of that post.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "55",
      "order": "most",
      "contents": "'Jujutsu Kaisen' Season 2 Premieres July 6",
      "checkpoint1": "357",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "'Jujutsu Kaisen' Season 2 Premieres July 6"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "'Jujutsu Kaisen' Season 2 Premieres July 6"
    }
  },
  {
    "task_id": 30063,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the {{order}} upvoted post among my last {{number}} submissions? Please answer the title of the post and do not include any other information.",
    "intent": "What is the most upvoted post among my last 100 submissions? Please answer the title of the post and do not include any other information.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to my submission page. Then, check the most recent number of submissions and find the {{order}} upvoted post. Finally, report the title of that post.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "number": "100",
      "order": "most",
      "contents": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record |OR| 'Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers",
      "checkpoint1": "656",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "fuzzy_match": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record |OR| 'Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "‘Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers, Breaks Showtime Streaming Record |OR| 'Yellowjackets’ Season 2 Premiere Draws Nearly 2M Viewers"
    }
  },
  {
    "task_id": 30070,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/OldSchoolCool/35802/twins-photographed-in-1937-and-2012",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Who is the user with the most prominent comment in submission {{submission}} in the forum {{forum}}? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "intent": "Who is the user with the most prominent comment in submission Twins photographed in 1937 and 2012 in the forum OldSchoolCool? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the specified submission page. Then, find the most prominent comment.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/OldSchoolCool/35802/twins-photographed-in-1937-and-2012",
      "forum": "OldSchoolCool",
      "submission": "Twins photographed in 1937 and 2012",
      "contents": "Amerikai, 847.35",
      "checkpoint1": "450 * 0.8^0 + 242 * 0.8^1 + 161 * 0.8^2 + 61 * 0.8^3 + 39 * 0.8^4 + 4 * 0.8^5 + 1 * 0.8^5 + 0 * 0.8^5 + 12 * 0.8^6 + 8 * 0.8^7 + 1 * 0.8^8 + 3 * 0.8^6 + 18 * 0.8^4 + 12 * 0.8^5 + 10 * 0.8^5 + 4 * 0.8^5 + 3 * 0.8^6 + 1 * 0.8^7 + 1 * 0.8^6 + 2 * 0.8^7 + 3 * 0.8^4 + 1 * 0.8^4 + 30 * 0.8^3 + 5 * 0.8^2 + 2 * 0.8^2 + 1 * 0.8^2 + 8 * 0.8^1",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Amerikai, 847.35"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Amerikai, 847.35"
    }
  },
  {
    "task_id": 30071,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Music/56626/brian-may-gets-a-knighthood-in-new-year-honours-list",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Who is the user with the most prominent comment in submission {{submission}} in the forum {{forum}}? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "intent": "Who is the user with the most prominent comment in submission Brian May gets a knighthood in New Year Honours list in the forum Music? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the specified submission page. Then, find the most prominent comment.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Music/56626/brian-may-gets-a-knighthood-in-new-year-honours-list",
      "forum": "Music",
      "submission": "Brian May gets a knighthood in New Year Honours list",
      "contents": "VioletInADream, 826.68",
      "checkpoint1": "507 * 0.8^0 + 187 * 0.8^1 + 106 * 0.8^2 + 47 * 0.8^3 + 25 * 0.8^4 + 9 * 0.8^5 + 6 * 0.8^6 + 4 * 0.8^5 + 0 * 0.8^6 + 1 * 0.8^5 + 1 * 0.8^5 + 1 * 0.8^4 + 12 * 0.8^3 + 4 * 0.8^3 + 2 * 0.8^4 + 15 * 0.8^2 + 4 * 0.8^3 + 1 * 0.8^4 + 9 * 0.8^2 + 16 * 0.8^1 + 8 * 0.8^2 + 7 * 0.8^3 + 12 * 0.8^4 + 10 * 0.8^5 + 10 * 0.8^6 + 5 * 0.8^7 + 4 * 0.8^7",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "VioletInADream, 826.68"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "VioletInADream, 826.68"
    }
  },
  {
    "task_id": 30072,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/technology/27999/fires-from-exploding-e-bike-batteries-multiply-in-nyc",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Who is the user with the most prominent comment in submission {{submission}} in the forum {{forum}}? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "intent": "Who is the user with the most prominent comment in submission Fires from exploding e-bike batteries multiply in NYC — sometimes fatally in the forum technology? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the specified submission page. Then, find the most prominent comment.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/technology/27999/fires-from-exploding-e-bike-batteries-multiply-in-nyc",
      "forum": "technology",
      "submission": "Fires from exploding e-bike batteries multiply in NYC — sometimes fatally",
      "contents": "reggie_rocket, 552.65",
      "checkpoint1": "294 * 0.8^0 + 70 * 0.8^1 + 141 * 0.8^2 + 42 * 0.8^3 + 27 * 0.8^4 + 9 * 0.8^5 + 1 * 0.8^5 + 7 * 0.8^6 + 2 * 0.8^6 + 14 * 0.8^4 + 16 * 0.8^5 + 8 * 0.8^6 + 4 * 0.8^7 + 11 * 0.8^4 + 1 * 0.8^5 + 1 * 0.8^6 + 1 * 0.8^4 + 26 * 0.8^3 + 7 * 0.8^4 + 2 * 0.8^3 + 1 * 0.8^3 + 1 * 0.8^3 + 1 * 0.8^4 + 9 * 0.8^2 + 6 * 0.8^2 + 9 * 0.8^3 + 10 * 0.8^4 + 8 * 0.8^4 + 2 * 0.8^4 + 1 * 0.8^2 + 1 * 0.8^2 + 0 * 0.8^2 + 4 * 0.8^1 + 7 * 0.8^2 + 2 * 0.8^1",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "reggie_rocket, 552.65"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "reggie_rocket, 552.65"
    }
  },
  {
    "task_id": 30073,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/wallstreetbets/50383/the-only-indicator-i-need-my-mom",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Who is the user with the most prominent comment in submission {{submission}} in the forum {{forum}}? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "intent": "Who is the user with the most prominent comment in submission The only indicator I need…my mom in the forum wallstreetbets? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the specified submission page. Then, find the most prominent comment.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/wallstreetbets/50383/the-only-indicator-i-need-my-mom",
      "forum": "wallstreetbets",
      "submission": "The only indicator I need…my mom",
      "contents": "dekrob, 650.65",
      "checkpoint1": "311 * 0.8^0 + 176 * 0.8^1 + 221 * 0.8^2 + 55 * 0.8^3 + 45 * 0.8^4 + 18 * 0.8^5 + 15 * 0.8^5",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "dekrob, 650.65"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "dekrob, 650.65"
    }
  },
  {
    "task_id": 30074,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/television/49068/wilko-johnson-legendary-guitarist-and-actor-who-played-ser",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Who is the user with the most prominent comment in submission {{submission}} in the forum {{forum}}? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "intent": "Who is the user with the most prominent comment in submission Wilko Johnson, Legendary Guitarist and Actor Who Played Ser Ilyn Payne in ‘Game of Thrones’, Dies at 75 in the forum television? The prominence should be determined by the weighted sum of the upvotes, which includes both the upvotes on the comment itself and the upvotes on all its nested replies. When the upvote score is negative, use the absolute value of that score. The influence of upvotes decreases by a factor of 0.8 for each level of nesting. Round to the nearest hundredth and display the result with two decimal places. Provide the user name and its total weighted count, using the following format: {user name}, {total count}.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "First, go to the specified submission page. Then, find the most prominent comment.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/television/49068/wilko-johnson-legendary-guitarist-and-actor-who-played-ser",
      "forum": "television",
      "submission": "Wilko Johnson, Legendary Guitarist and Actor Who Played Ser Ilyn Payne in ‘Game of Thrones’, Dies at 75",
      "contents": "Malcolm_Ten, 2198.54",
      "checkpoint1": "894 * 0.8^0 + 522 * 0.8^1 + 396 * 0.8^2 + 381 * 0.8^3 + 112 * 0.8^4 + 23 * 0.8^5 + 56 * 0.8^4 + 81 * 0.8^3 + 164 * 0.8^4 + 69 * 0.8^5 + 56 * 0.8^6 + 75 * 0.8^7 + 31 * 0.8^8 + 22 * 0.8^8 + 14 * 0.8^9 + 1 * 0.8^10 + 12 * 0.8^8 + 38 * 0.8^7 + 14 * 0.8^8 + 21 * 0.8^9 + 5 * 0.8^10 + 7 * 0.8^11 + 1 * 0.8^12 + 3 * 0.8^13 + 2 * 0.8^14 + 3 * 0.8^9 + 2 * 0.8^9 + 9 * 0.8^8 + 7 * 0.8^9 + 0 * 0.8^10 + 1 * 0.8^9 + 7 * 0.8^6 + 1 * 0.8^7 + 3 * 0.8^8 + 7 * 0.8^4 + 1 * 0.8^5 + 6 * 0.8^3 + 3 * 0.8^2 + 17 * 0.8^3 + 8 * 0.8^4 + 1 * 0.8^2 + 65 * 0.8^1 + 45 * 0.8^2 + 13 * 0.8^3 + 12 * 0.8^4 + 3 * 0.8^5 + 4 * 0.8^3 + 34 * 0.8^2 + 13 * 0.8^3 + 14 * 0.8^4 + 10 * 0.8^5 + 2 * 0.8^4 + 3 * 0.8^3 + 1 * 0.8^4 + 3 * 0.8^2 + 10 * 0.8^1 + 1 * 0.8^1",
      "checkpoint_info": "",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Malcolm_Ten, 2198.54"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Malcolm_Ten, 2198.54"
    }
  },
  {
    "task_id": 30080,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top {{number}} most commented posts of all time on forum {{forum}}.",
    "intent": "Calculate the total number of comments on the top 40 most commented posts of all time on forum worldnews.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum the number of comments from the top posts in a forum up to a specified number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
      "number": "40",
      "forum": "worldnews",
      "answer": "7280 |OR| 7,280",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "7280 |OR| 7,280"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30081,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/deeplearning/most_commented?t=all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top {{number}} most commented posts of all time on forum {{forum}}.",
    "intent": "Calculate the total number of comments on the top 40 most commented posts of all time on forum deeplearning.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum the number of comments from the top posts in a forum up to a specified number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/deeplearning/most_commented?t=all",
      "number": "40",
      "forum": "deeplearning",
      "answer": "941",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "941"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30082,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/space/most_commented?t=all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top {{number}} most commented posts of all time on forum {{forum}}.",
    "intent": "Calculate the total number of comments on the top 30 most commented posts of all time on forum space.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum the number of comments from the top posts in a forum up to a specified number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/space/most_commented?t=all",
      "number": "30",
      "forum": "space",
      "answer": "5491 |OR| 5,491",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5491 |OR| 5,491"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30083,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/OldSchoolCool/most_commented?t=all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top {{number}} most commented posts of all time on forum {{forum}}.",
    "intent": "Calculate the total number of comments on the top 30 most commented posts of all time on forum OldSchoolCool.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum the number of comments from the top posts in a forum up to a specified number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/OldSchoolCool/most_commented?t=all",
      "number": "30",
      "forum": "OldSchoolCool",
      "answer": "5361 |OR| 5,361",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5361 |OR| 5,361"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30084,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/askscience/most_commented?t=all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top {{number}} most commented posts of all time on forum {{forum}}.",
    "intent": "Calculate the total number of comments on the top 50 most commented posts of all time on forum askscience.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Sum the number of comments from the top posts in a forum up to a specified number.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/askscience/most_commented?t=all",
      "number": "50",
      "forum": "askscience",
      "answer": "8719 |OR| 8,719",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "8719 |OR| 8,719"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30090,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=I+Photographed+Something+No+One+Can+Explain",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Search for {{title1}} and {{title2}} and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "intent": "Search for I Photographed Something No One Can Explain and What Happened at Hotel Carlton and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "calc",
    "description": "complain of the customer service",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=I+Photographed+Something+No+One+Can+Explain",
      "title1": "I Photographed Something No One Can Explain",
      "title2": "What Happened at Hotel Carlton",
      "ans": "I Photographed Something No One Can Explain",
      "ratio": "19",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: I Photographed Something No One Can Explain, Ratio: 19"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "I Photographed Something No One Can Explain, 19"
    }
  },
  {
    "task_id": 30091,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=How+long+is+to+long+of+a+commute.",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Search for {{title1}} and {{title2}} and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "intent": "Search for How long is to long of a commute. and Those of you on Fidium Fiber, how do you like it? and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "calc",
    "description": "complain of the customer service",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=How+long+is+to+long+of+a+commute.",
      "title1": "How long is to long of a commute.",
      "title2": "Those of you on Fidium Fiber, how do you like it?",
      "ans": "Those of you on Fidium Fiber, how do you like it?",
      "ratio": "0",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: Those of you on Fidium Fiber, how do you like it?, Ratio: 0"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Those of you on Fidium Fiber, how do you like it?, 0"
    }
  },
  {
    "task_id": 30092,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=The+global+income+distribution.",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Search for {{title1}} and {{title2}} and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "intent": "Search for The global income distribution and Bank Failures 2005 - 2023 - Should we be worried? [OC] and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "calc",
    "description": "complain of the customer service",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=The+global+income+distribution.",
      "title1": "The global income distribution",
      "title2": "Bank Failures 2005 - 2023 - Should we be worried? [OC]",
      "ans": "The global income distribution",
      "ratio": "36",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: The global income distribution, Ratio: 36"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "The global income distribution, 36"
    }
  },
  {
    "task_id": 30093,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=I+like+to+tell+dad+jokes.",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Search for {{title1}} and {{title2}} and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "intent": "Search for I like to tell dad jokes and I’m currently writing this from the hospital. and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "calc",
    "description": "complain of the customer service",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=I+like+to+tell+dad+jokes.",
      "title1": "I like to tell dad jokes",
      "title2": "I’m currently writing this from the hospital.",
      "ans": "I’m currently writing this from the hospital.",
      "ratio": "25",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: I’m currently writing this from the hospital., Ratio: 25"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "I’m currently writing this from the hospital., 25"
    }
  },
  {
    "task_id": 30094,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Rooster+Run.",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Search for {{title1}} and {{title2}} and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "intent": "Search for Rooster Run and I'll raise you one Dollar more... and determine which post has a higher votes-to-comments ratio (rounded to the nearest integer). Output the result in the following format: Ans: [title], Ratio: [votes/comments]",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "calc",
    "description": "complain of the customer service",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Rooster+Run.",
      "title1": "Rooster Run",
      "title2": "I'll raise you one Dollar more...",
      "ans": "Rooster Run",
      "ratio": "30",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: Rooster Run, Ratio: 30"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Rooster Run, 30"
    }
  },
  {
    "task_id": 30100,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/Sariel007",
    "start_url_lite": "__REDDIT__/user/Sariel007",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the number of submissions made by {{user}} in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "intent": "List the number of submissions made by Sariel007 in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Count the total number of submissions made by a user in each forum by going through all of their submission history.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/Sariel007",
      "start_url_lite": "__REDDIT__/user/Sariel007",
      "user": "Sariel007",
      "forum": "Sariel007",
      "ans": "UpliftingNews: 82, Futurology: 18, space: 6, books: 5, technology: 3, nottheonion: 1",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "UpliftingNews: 82, Futurology: 18, space: 6, books: 5, technology: 3, nottheonion: 1"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "UpliftingNews: 82, Futurology: 18, space: 6, books: 5, technology: 3, nottheonion: 1"
    }
  },
  {
    "task_id": 30101,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/mossadnik",
    "start_url_lite": "__REDDIT__/user/mossadnik",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the number of submissions made by {{user}} in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "intent": "List the number of submissions made by mossadnik in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Count the total number of submissions made by a user in each forum by going through all of their submission history.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/mossadnik",
      "start_url_lite": "__REDDIT__/user/mossadnik",
      "user": "mossadnik",
      "forum": "mossadnik",
      "ans": "Futurology: 43, science: 24, technology: 9, sports: 1",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Futurology: 43, science: 24, technology: 9, sports: 1"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Futurology: 43, science: 24, technology: 9, sports: 1"
    }
  },
  {
    "task_id": 30102,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/thebelsnickle1991",
    "start_url_lite": "__REDDIT__/user/thebelsnickle1991",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the number of submissions made by {{user}} in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "intent": "List the number of submissions made by thebelsnickle1991 in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Count the total number of submissions made by a user in each forum by going through all of their submission history.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/thebelsnickle1991",
      "start_url_lite": "__REDDIT__/user/thebelsnickle1991",
      "user": "thebelsnickle1991",
      "forum": "thebelsnickle1991",
      "ans": "gadgets: 73, science: 45, technology: 12, Futurology: 7, Music: 1, space: 1",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "gadgets: 73, science: 45, technology: 12, Futurology: 7, Music: 1, space: 1"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "gadgets: 73, science: 45, technology: 12, Futurology: 7, Music: 1, space: 1"
    }
  },
  {
    "task_id": 30103,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/nastratin",
    "start_url_lite": "__REDDIT__/user/nastratin",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the number of submissions made by {{user}} in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "intent": "List the number of submissions made by nastratin in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Count the total number of submissions made by a user in each forum by going through all of their submission history.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/nastratin",
      "start_url_lite": "__REDDIT__/user/nastratin",
      "user": "nastratin",
      "forum": "nastratin",
      "ans": "Futurology: 25, technology: 6, books: 1, worldnews: 1",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Futurology: 25, technology: 6, books: 1, worldnews: 1"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Futurology: 25, technology: 6, books: 1, worldnews: 1"
    }
  },
  {
    "task_id": 30104,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/chrisdh79",
    "start_url_lite": "__REDDIT__/user/chrisdh79",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the number of submissions made by {{user}} in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "intent": "List the number of submissions made by chrisdh79 in each forum, sorted in descending order. If the counts are the same, sort them alphabetically. Display the results in the following format: [forum]: [count], [forum]: [count], ...",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Count the total number of submissions made by a user in each forum by going through all of their submission history.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/chrisdh79",
      "start_url_lite": "__REDDIT__/user/chrisdh79",
      "user": "chrisdh79",
      "forum": "chrisdh79",
      "ans": "technology: 124, science: 120, gadgets: 118, Futurology: 39, space: 15, UpliftingNews: 5, movie: 3",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "technology: 124, science: 120, gadgets: 118, Futurology: 39, space: 15, UpliftingNews: 5, movie: 3"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "technology: 124, science: 120, gadgets: 118, Futurology: 39, space: 15, UpliftingNews: 5, movie: 3"
    }
  },
  {
    "task_id": 30110,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the oldest post among the top {{number}} posts in forum {{forum}}? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "intent": "What is the oldest post among the top 20 posts in forum /f/gaming? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "required_obs": "text",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Find the oldest post among the top N posts in a forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
      "forum": "/f/gaming",
      "number": "20",
      "ans": "[OC] visited a video game museum today this is the original master copy of DOOM 2",
      "date": "10/30",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: [OC] visited a video game museum today this is the original master copy of DOOM 2, Date: 10/30"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "[OC] visited a video game museum today this is the original master copy of DOOM 2"
    }
  },
  {
    "task_id": 30111,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the oldest post among the top {{number}} posts in forum {{forum}}? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "intent": "What is the oldest post among the top 30 posts in forum /f/wallstreetbets? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "required_obs": "text",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Find the oldest post among the top N posts in a forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
      "forum": "/f/wallstreetbets",
      "number": "30",
      "ans": "Confirmed. Sky Bear sighting signals bull trap and pawwing for your calls...",
      "date": "10/29",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: Confirmed. Sky Bear sighting signals bull trap and pawwing for your calls..., Date: 10/29"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Confirmed. Sky Bear sighting signals bull trap and pawwing for your calls..."
    }
  },
  {
    "task_id": 30112,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the oldest post among the top {{number}} posts in forum {{forum}}? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "intent": "What is the oldest post among the top 30 posts in forum /f/movies? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "required_obs": "text",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Find the oldest post among the top N posts in a forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
      "forum": "/f/movies",
      "number": "30",
      "ans": "Bullet Train is a fun movie!",
      "date": "10/24",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: Bullet Train is a fun movie!, Date: 10/24"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Bullet Train is a fun movie!"
    }
  },
  {
    "task_id": 30113,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the oldest post among the top {{number}} posts in forum {{forum}}? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "intent": "What is the oldest post among the top 15 posts in forum /f/books? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "required_obs": "text",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Find the oldest post among the top N posts in a forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
      "forum": "/f/books",
      "number": "15",
      "ans": "I just finished reading The Hobbit to my 6 year old daughter, and she loved it!",
      "date": "10/25",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: I just finished reading The Hobbit to my 6 year old daughter, and she loved it!, Date: 10/25"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "I just finished reading The Hobbit to my 6 year old daughter, and she loved it!"
    }
  },
  {
    "task_id": 30114,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What is the oldest post among the top {{number}} posts in forum {{forum}}? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "intent": "What is the oldest post among the top 30 posts in forum /f/science? Please provide the result in the following format with UTC time: Ans: [title], Date: [MM/DD]",
    "required_obs": "text",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Find the oldest post among the top N posts in a forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/search?q=Large+study+provides+evidence+that+goal+incongruence+can+harm+romantic+relationship+satisfaction",
      "forum": "/f/science",
      "number": "30",
      "ans": "Scientists have proved goldfish do have good memories and are able to navigate their surroundings. A team from Oxford University trained nine fish to travel 70cm (2.3ft) and back, receiving a food reward at the end. The study disproves the long-held belief goldfish have little or no memory.",
      "date": "10/13",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ans: Scientists have proved goldfish do have good memories and are able to navigate their surroundings. A team from Oxford University trained nine fish to travel 70cm (2.3ft) and back, receiving a food reward at the end. The study disproves the long-held belief goldfish have little or no memory., Date: 10/13"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Scientists have proved goldfish do have good memories and are able to navigate their surroundings. A team from Oxford University trained nine fish to travel 70cm (2.3ft) and back, receiving a food reward at the end. The study disproves the long-held belief goldfish have little or no memory."
    }
  },
  {
    "task_id": 30120,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find all users who have a post in the top {{number}} by votes in both forum {{forum1}} and forum {{forum2}}. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "intent": "Find all users who have a post in the top 50 by votes in both forum iphone and forum explainlikeimfive. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Identify the unique users from the top N posts in a forum, and find the intersection with another set of unique users.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/science",
      "forum1": "iphone",
      "forum2": "explainlikeimfive",
      "number": "50",
      "user": "ExternalUserError"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "ExternalUserError"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "ExternalUserError"
    }
  },
  {
    "task_id": 30121,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/funny",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find all users who have a post in the top {{number}} by votes in both forum {{forum1}} and forum {{forum2}}. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "intent": "Find all users who have a post in the top 100 by votes in both forum books and forum technology. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Identify the unique users from the top N posts in a forum, and find the intersection with another set of unique users.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/funny",
      "forum1": "books",
      "forum2": "technology",
      "number": "100",
      "user": "zsreport"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "zsreport"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "zsreport"
    }
  },
  {
    "task_id": 30122,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/todayilearned",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find all users who have a post in the top {{number}} by votes in both forum {{forum1}} and forum {{forum2}}. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "intent": "Find all users who have a post in the top 75 by votes in both forum Washington and forum vermont. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Identify the unique users from the top N posts in a forum, and find the intersection with another set of unique users.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/todayilearned",
      "forum1": "Washington",
      "forum2": "vermont",
      "number": "75",
      "user": "bunkerbash, gammapsi05"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "bunkerbash, gammapsi05"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "bunkerbash, gammapsi05"
    }
  },
  {
    "task_id": 30123,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/memes",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find all users who have a post in the top {{number}} by votes in both forum {{forum1}} and forum {{forum2}}. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "intent": "Find all users who have a post in the top 100 by votes in both forum memes and forum Showerthoughts. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Identify the unique users from the top N posts in a forum, and find the intersection with another set of unique users.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/memes",
      "forum1": "memes",
      "forum2": "Showerthoughts",
      "number": "100",
      "user": "Looney_forner"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Looney_forner"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Looney_forner"
    }
  },
  {
    "task_id": 30124,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/television",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find all users who have a post in the top {{number}} by votes in both forum {{forum1}} and forum {{forum2}}. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "intent": "Find all users who have a post in the top 100 by votes in both forum worldnews and forum news. Do not include deleted users. If there are multiple users, separate them with commas like user1, user2. Output the usernames in alphabetical order.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": false,
    "type_main": "massive_memory",
    "description": "Identify the unique users from the top N posts in a forum, and find the intersection with another set of unique users.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/television",
      "forum1": "worldnews",
      "forum2": "news",
      "number": "100",
      "user": "Picture-unrelated, WhoIsJolyonWest"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Picture-unrelated, WhoIsJolyonWest"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Picture-unrelated, WhoIsJolyonWest"
    }
  },
  {
    "task_id": 30130,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/arlingtonva",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{x}}\" forum have more comments than {{y}}? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"lakewood\" forum have more comments than Date Night in Arlington? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Counting the submission while comparing the number of comments",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/arlingtonva",
      "x": "lakewood",
      "y": "Date Night in Arlington",
      "contents": "40.9",
      "checkpoint1": "11",
      "checkpoint2": "9",
      "checkpoint_info": "checkpoint1: The number of comments in {{y}}. checkpoint2: The number of comments in {{x}} that have more comments than {{y}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "40.9"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "40.9"
    }
  },
  {
    "task_id": 30131,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/television",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{x}}\" forum have more comments than {{y}}? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"listentothis\" forum have more comments than Supernatural Alum Nicki Aycox Passed Away? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Counting the submission while comparing the number of comments",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/television",
      "x": "listentothis",
      "y": "Supernatural Alum Nicki Aycox Passed Away",
      "contents": "33.9",
      "checkpoint1": "104",
      "checkpoint2": "21",
      "checkpoint_info": "checkpoint1: The number of comments in {{y}}. checkpoint2: The number of comments in {{x}} that have more comments than {{y}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "33.9"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "33.9"
    }
  },
  {
    "task_id": 30132,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/funny",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{x}}\" forum have more comments than {{y}}? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"InternetIsBeautiful\" forum have more comments than Accurate holiday season? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Counting the submission while comparing the number of comments",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/funny",
      "x": "InternetIsBeautiful",
      "y": "Accurate holiday season",
      "contents": "4.5",
      "checkpoint1": "149",
      "checkpoint2": "8",
      "checkpoint_info": "checkpoint1: The number of comments in {{y}}. checkpoint2: The number of comments in {{x}} that have more comments than {{y}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "4.5"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "4.5"
    }
  },
  {
    "task_id": 30133,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/search?q=Best+bowling+alley+in+the+area%3F",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{x}}\" forum have more comments than {{y}}? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"ColumbiaMD\" forum have more comments than Best bowling alley in the area?? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Counting the submission while comparing the number of comments",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/search?q=Best+bowling+alley+in+the+area%3F",
      "x": "ColumbiaMD",
      "y": "Best bowling alley in the area?",
      "contents": "16.3",
      "checkpoint1": "25",
      "checkpoint2": "49",
      "checkpoint_info": "checkpoint1: The number of comments in {{y}}. checkpoint2: The number of comments in {{x}} that have more comments than {{y}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "16.3"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "16.3"
    }
  },
  {
    "task_id": 30134,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/search?q=Japan+defeats+USA+3-2+in+WBC+Final.",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{x}}\" forum have more comments than {{y}}? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"sports\" forum have more comments than Japan defeats USA 3-2 in WBC Final.? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Counting the submission while comparing the number of comments",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/search?q=Japan+defeats+USA+3-2+in+WBC+Final.",
      "x": "sports",
      "y": "Japan defeats USA 3-2 in WBC Final.",
      "contents": "10.1",
      "checkpoint1": "131",
      "checkpoint2": "74",
      "checkpoint_info": "checkpoint1: The number of comments in {{y}}. checkpoint2: The number of comments in {{x}} that have more comments than {{y}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "10.1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "10.1"
    }
  },
  {
    "task_id": 30140,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/monitor",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{submission}}\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"monitor\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Computing the ratio of upvotes among multiple pages",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/monitor",
      "submission": "monitor",
      "contents": "66.7",
      "checkpoint1": "6",
      "checkpoint2": "4",
      "checkpoint_info": "checkpoint1: The total number of submissions in {{submission}}. checkpoint2: The number of submissions that have more upvotes in {{submission}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "66.7"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "66.7"
    }
  },
  {
    "task_id": 30141,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/listentothis",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{submission}}\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"listentothis\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Computing the ratio of upvotes among multiple pages",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/listentothis",
      "submission": "listentothis",
      "contents": "95.2",
      "checkpoint1": "62",
      "checkpoint2": "59",
      "checkpoint_info": "checkpoint1: The total number of submissions in {{submission}}. checkpoint2: The number of submissions that have more upvotes in {{submission}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "95.2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "95.2"
    }
  },
  {
    "task_id": 30142,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/Documentaries",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{submission}}\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"Documentaries\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Computing the ratio of upvotes among multiple pages",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/Documentaries",
      "submission": "Documentaries",
      "contents": "94.9",
      "checkpoint1": "59",
      "checkpoint2": "56",
      "checkpoint_info": "checkpoint1: The total number of submissions in {{submission}}. checkpoint2: The number of submissions that have more upvotes in {{submission}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "94.9"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "94.9"
    }
  },
  {
    "task_id": 30143,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/LowellMA",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{submission}}\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"LowellMA\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Computing the ratio of upvotes among multiple pages",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/LowellMA",
      "submission": "LowellMA",
      "contents": "96.0 |OR| 96.1",
      "checkpoint1": "76",
      "checkpoint2": "73",
      "checkpoint_info": "checkpoint1: The total number of submissions in {{submission}}. checkpoint2: The number of submissions that have more upvotes in {{submission}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "96.0 |OR| 96.1"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "96.0 |OR| 96.1"
    }
  },
  {
    "task_id": 30144,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/deeplearning",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "What percentage of submissions in \"{{submission}}\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "intent": "What percentage of submissions in \"deeplearning\" forum have more upvotes than downvotes? Round to the first decimal place.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Computing the ratio of upvotes among multiple pages",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/deeplearning",
      "submission": "deeplearning",
      "contents": "83.0",
      "checkpoint1": "235",
      "checkpoint2": "195",
      "checkpoint_info": "checkpoint1: The total number of submissions in {{submission}}. checkpoint2: The number of submissions that have more upvotes in {{submission}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "83.0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "83.0"
    }
  },
  {
    "task_id": 30150,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"{{w}}\", \"{{x}}\", \"{{y}}\" and \"{{z}}\", for a total of 160 submissions.",
    "intent": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"food\", \"science\", \"gadgets\" and \"books\", for a total of 160 submissions.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing the number of comments among multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "w": "food",
      "x": "science",
      "y": "gadgets",
      "z": "books",
      "contents": "28880 |OR| 28,880",
      "checkpoint1": "6772 |OR| 6,772",
      "checkpoint2": "7744 |OR| 7,744",
      "checkpoint_info": "checkpoint1: The total number of comments in the top 40 most-commented submission in forum \"{{w}}\". checkpoint2: The total number of comments in the top 40 most-commented submission in forum \"{{x}}\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "28880 |OR| 28,880"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "28880 |OR| 28,880"
    }
  },
  {
    "task_id": 30151,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"{{w}}\", \"{{x}}\", \"{{y}}\" and \"{{z}}\", for a total of 160 submissions.",
    "intent": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"Jokes\", \"memes\", \"gaming\" and \"videos\", for a total of 160 submissions.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing the number of comments among multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "w": "Jokes",
      "x": "memes",
      "y": "gaming",
      "z": "videos",
      "contents": "19857 |OR| 19,857",
      "checkpoint1": "6067 |OR| 6,067",
      "checkpoint2": "5117 |OR| 5,117",
      "checkpoint_info": "checkpoint1: The total number of comments in the top 40 most-commented submission in forum \"{{w}}\". checkpoint2: The total number of comments in the top 40 most-commented submission in forum \"{{x}}\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "19857 |OR| 19,857"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "19857 |OR| 19,857"
    }
  },
  {
    "task_id": 30152,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"{{w}}\", \"{{x}}\", \"{{y}}\" and \"{{z}}\", for a total of 160 submissions.",
    "intent": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"Art\", \"Maine\", \"AskReddit\" and \"worldnews\", for a total of 160 submissions.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing the number of comments among multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "w": "Art",
      "x": "Maine",
      "y": "AskReddit",
      "z": "worldnews",
      "contents": "22284 |OR| 22,284",
      "checkpoint1": "6086 |OR| 6,086",
      "checkpoint2": "6502 |OR| 6,502",
      "checkpoint_info": "checkpoint1: The total number of comments in the top 40 most-commented submission in forum \"{{w}}\". checkpoint2: The total number of comments in the top 40 most-commented submission in forum \"{{x}}\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "22284 |OR| 22,284"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "22284 |OR| 22,284"
    }
  },
  {
    "task_id": 30153,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"{{w}}\", \"{{x}}\", \"{{y}}\" and \"{{z}}\", for a total of 160 submissions.",
    "intent": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"funny\", \"vermont\", \"history\" and \"creepy\", for a total of 160 submissions.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing the number of comments among multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "w": "funny",
      "x": "vermont",
      "y": "history",
      "z": "creepy",
      "contents": "25409 |OR| 25,409",
      "checkpoint1": "6115 |OR| 6,115",
      "checkpoint2": "6703 |OR| 6,703",
      "checkpoint_info": "checkpoint1: The total number of comments in the top 40 most-commented submission in forum \"{{w}}\". checkpoint2: The total number of comments in the top 40 most-commented submission in forum \"{{x}}\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "25409 |OR| 25,409"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "25409 |OR| 25,409"
    }
  },
  {
    "task_id": 30154,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"{{w}}\", \"{{x}}\", \"{{y}}\" and \"{{z}}\", for a total of 160 submissions.",
    "intent": "Calculate the total number of comments on the top 40 most-commented submissions in forum \"science\", \"Jokes\", \"Art\" and \"funny\", for a total of 160 submissions.",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing the number of comments among multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "w": "science",
      "x": "Jokes",
      "y": "Art",
      "z": "funny",
      "contents": "26012 |OR| 26,012",
      "checkpoint1": "7744 |OR| 7,744",
      "checkpoint2": "6067 |OR| 6,067",
      "checkpoint_info": "checkpoint1: The total number of comments in the top 40 most-commented submission in forum \"{{x}}\". checkpoint2: The total number of comments in the top 40 most-commented submission in forum \"{{y}}\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "26012 |OR| 26,012"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "26012 |OR| 26,012"
    }
  },
  {
    "task_id": 30160,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/Upper_Initial7918",
    "start_url_lite": "__REDDIT__/user/Upper_Initial7918",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "How many comments has user \"{{x}}\" made in the forum where they have commented the most?",
    "intent": "How many comments has user \"Upper_Initial7918\" made in the forum where they have commented the most?",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing how many comments a user have made to multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/Upper_Initial7918",
      "start_url_lite": "__REDDIT__/user/Upper_Initial7918",
      "x": "Upper_Initial7918",
      "contents": "5",
      "checkpoint1": "Showerthoughts",
      "checkpoint_info": "checkpoint1: The forum user \"{{x}}\" makes most comments.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "5"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5"
    }
  },
  {
    "task_id": 30161,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/DotTraditional3096",
    "start_url_lite": "__REDDIT__/user/DotTraditional3096",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "How many comments has user \"{{x}}\" made in the forum where they have commented the most?",
    "intent": "How many comments has user \"DotTraditional3096\" made in the forum where they have commented the most?",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing how many comments a user have made to multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/DotTraditional3096",
      "start_url_lite": "__REDDIT__/user/DotTraditional3096",
      "x": "DotTraditional3096",
      "contents": "7",
      "checkpoint1": "OldSchoolCool",
      "checkpoint_info": "checkpoint1: The forum user \"{{x}}\" makes most comments.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "7"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "7"
    }
  },
  {
    "task_id": 30162,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/sector3011",
    "start_url_lite": "__REDDIT__/user/sector3011",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "How many comments has user \"{{x}}\" made in the forum where they have commented the most?",
    "intent": "How many comments has user \"sector3011\" made in the forum where they have commented the most?",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing how many comments a user have made to multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/sector3011",
      "start_url_lite": "__REDDIT__/user/sector3011",
      "x": "sector3011",
      "contents": "4",
      "checkpoint1": "news",
      "checkpoint_info": "checkpoint1: The forum user \"{{x}}\" makes most comments.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "4"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "4"
    }
  },
  {
    "task_id": 30163,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/yttikat",
    "start_url_lite": "__REDDIT__/user/yttikat",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "How many comments has user \"{{x}}\" made in the forum where they have commented the most?",
    "intent": "How many comments has user \"yttikat\" made in the forum where they have commented the most?",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing how many comments a user have made to multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/yttikat",
      "start_url_lite": "__REDDIT__/user/yttikat",
      "x": "yttikat",
      "contents": "28",
      "checkpoint1": "pics",
      "checkpoint_info": "checkpoint1: The forum user \"{{x}}\" makes most comments.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "28"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "28"
    }
  },
  {
    "task_id": 30164,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/user/bigwolf29",
    "start_url_lite": "__REDDIT__/user/bigwolf29",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "How many comments has user \"{{x}}\" made in the forum where they have commented the most?",
    "intent": "How many comments has user \"bigwolf29\" made in the forum where they have commented the most?",
    "required_obs": "any",
    "affects_environment": false,
    "type_main": "calc",
    "description": "Computing how many comments a user have made to multiple forums",
    "instantiation_dict": {
      "start_url": "__REDDIT__/user/bigwolf29",
      "start_url_lite": "__REDDIT__/user/bigwolf29",
      "x": "bigwolf29",
      "contents": "9",
      "checkpoint1": "Jokes",
      "checkpoint_info": "checkpoint1: The forum user \"{{x}}\" makes most comments.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "9"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "9"
    }
  },
  {
    "task_id": 30170,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"{{forum}}\" forum, and post them in the forum with the second highest number of submissions after \"{{forum}}\" (i.e., the one ranked just below \"{{forum}}\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "intent": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"news\" forum, and post them in the forum with the second highest number of submissions after \"news\" (i.e., the one ranked just below \"news\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Making a post with the list of three titles",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "forum": "news",
      "contents": "Naval Academy Renames Building After Jimmy Carter, DOJ sues pharma giant AmerisourceBergen Corp. for allegedly helping to fuel the opioid epidemic, Voters can erase racist wording in Alabama Constitution",
      "checkpoint1": "Naval Academy Renames Building After Jimmy Carter",
      "checkpoint2": "movies",
      "checkpoint_info": "checkpoint1: The title of the most liked submission in {{forum}}. checkpoint2: The name of the forum to submit.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/movies",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "Naval Academy Renames Building After Jimmy Carter, DOJ sues pharma giant AmerisourceBergen Corp. for allegedly helping to fuel the opioid epidemic, Voters can erase racist wording in Alabama Constitution"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 30171,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"{{forum}}\" forum, and post them in the forum with the second highest number of submissions after \"{{forum}}\" (i.e., the one ranked just below \"{{forum}}\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "intent": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"tifu\" forum, and post them in the forum with the second highest number of submissions after \"tifu\" (i.e., the one ranked just below \"tifu\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Making a post with the list of three titles",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "forum": "tifu",
      "contents": "TIFUpdate by drunk texting my crush, THREE YEARS LATER!, TIFU by submitting furry porn instead of my lab report, TIFU by teaching survival skills to a church group",
      "checkpoint1": "TIFUpdate by drunk texting my crush, THREE YEARS LATER!",
      "checkpoint2": "space",
      "checkpoint_info": "checkpoint1: The title of the most liked submission in {{forum}}. checkpoint2: The name of the forum to submit.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/space",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "TIFUpdate by drunk texting my crush, THREE YEARS LATER!, TIFU by submitting furry porn instead of my lab report, TIFU by teaching survival skills to a church group"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 30172,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"{{forum}}\" forum, and post them in the forum with the second highest number of submissions after \"{{forum}}\" (i.e., the one ranked just below \"{{forum}}\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "intent": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"askscience\" forum, and post them in the forum with the second highest number of submissions after \"askscience\" (i.e., the one ranked just below \"askscience\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Making a post with the list of three titles",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "forum": "askscience",
      "contents": "Why are coastlines crinkly near the poles but smooth in the tropics?, Is dark matter orbiting galaxies with the same speed as normal matter?, What lifeform has the shortest genetic sequence?",
      "checkpoint1": "Why are coastlines crinkly near the poles but smooth in the tropics?",
      "checkpoint2": "pittsburgh",
      "checkpoint_info": "checkpoint1: The title of the most liked submission in {{forum}}. checkpoint2: The name of the forum to submit.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/pittsburgh",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "Why are coastlines crinkly near the poles but smooth in the tropics?, Is dark matter orbiting galaxies with the same speed as normal matter?, What lifeform has the shortest genetic sequence?"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 30173,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"{{forum}}\" forum, and post them in the forum with the second highest number of submissions after \"{{forum}}\" (i.e., the one ranked just below \"{{forum}}\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "intent": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"pittsburgh\" forum, and post them in the forum with the second highest number of submissions after \"pittsburgh\" (i.e., the one ranked just below \"pittsburgh\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Making a post with the list of three titles",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "forum": "pittsburgh",
      "contents": "Driving in Pittsburgh summed up by one traffic sign, Happy birthday Pittsburgh! On this day in 1758 General Forbes founded Fort Pitt, Shoutout to the two young guys who helped get my fat ass up off the sidewalk after I fell yesterday in the Strip.",
      "checkpoint1": "Driving in Pittsburgh summed up by one traffic sign.",
      "checkpoint2": "newjersey",
      "checkpoint_info": "checkpoint1: The title of the most liked submission in {{forum}}. checkpoint2: The name of the forum to submit.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/newjersey",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "Driving in Pittsburgh summed up by one traffic sign, Happy birthday Pittsburgh! On this day in 1758 General Forbes founded Fort Pitt, Shoutout to the two young guys who helped get my fat ass up off the sidewalk after I fell yesterday in the Strip."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 30174,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/forums/all",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"{{forum}}\" forum, and post them in the forum with the second highest number of submissions after \"{{forum}}\" (i.e., the one ranked just below \"{{forum}}\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "intent": "Find the titles of the most upvoted, the 50th most upvoted, and the 100th most upvoted submissions in the \"headphones\" forum, and post them in the forum with the second highest number of submissions after \"headphones\" (i.e., the one ranked just below \"headphones\" in submission count). When posting, use the following format: {title of the most upvoted submission}, {title of the 50th most upvoted submission}, {title of the 100th most upvoted submission}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Making a post with the list of three titles",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/forums/all",
      "forum": "headphones",
      "contents": "I do use Spotify more nowadays, It arrived!!, Loss-less",
      "checkpoint1": "I do use Spotify more nowadays",
      "checkpoint2": "rva",
      "checkpoint_info": "checkpoint1: The title of the most liked submission in {{forum}}. checkpoint2: The name of the forum to submit.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/rva",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "I do use Spotify more nowadays, It arrived!!, Loss-less"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 30180,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/relationship_advice/46378/i-m-tired-of-being-my-sister-s-nanny-update",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Reply to the user \"{{user}}\" in the submission \"{{current_page}}\" with the most upvoted comment in the submission \"{{submission}}\".",
    "intent": "Reply to the user \"eggiecat\" in the submission \"I'm tired of being my sister's nanny UPDATE\" with the most upvoted comment in the submission \"Boyfriend's dad wants me to call and text him regularly\".",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Reply to a user with the most liked comment in another submission",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/relationship_advice/46378/i-m-tired-of-being-my-sister-s-nanny-update",
      "user": "eggiecat",
      "current_page": "I'm tired of being my sister's nanny UPDATE",
      "submission": "Boyfriend's dad wants me to call and text him regularly",
      "checkpoint1": "It's creepy, boundary crossing and invasive.",
      "checkpoint_info": "checkpoint1: The most upvoted comment in the submission \"{{submission}}\".",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/relationship_advice/46378/i-m-tired-of-being-my-sister-s-nanny-update",
      "program_html": [
        {
          "url": "__REDDIT__/f/relationship_advice/46378/i-m-tired-of-being-my-sister-s-nanny-update",
          "locator": "document.querySelector('.comment__header a[href*=\"MarvelsGrantMan136\"]')?.closest('.comment')?.querySelector('.comment__body')?.outerText",
          "required_contents": {
            "must_include": [
              "It's creepy, boundary crossing and invasive."
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 30181,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/personalfinance/44843/quest-diagnostics-refusing-to-refund-overpayment-due-to",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Reply to the user \"{{user}}\" in the submission \"{{current_page}}\" with the most upvoted comment in the submission \"{{submission}}\".",
    "intent": "Reply to the user \"7dayweekendgirl\" in the submission \"Quest Diagnostics Refusing to Refund Overpayment Due to Insurance Reassessment\" with the most upvoted comment in the submission \"Filing for Unemployment with Company that serially fires employees\".",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Reply to a user with the most liked comment in another submission",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/personalfinance/44843/quest-diagnostics-refusing-to-refund-overpayment-due-to",
      "user": "7dayweekendgirl",
      "current_page": "Quest Diagnostics Refusing to Refund Overpayment Due to Insurance Reassessment",
      "submission": "Filing for Unemployment with Company that serially fires employees",
      "checkpoint1": "I would file and argue for benefits if denied. It will cost you nothing.",
      "checkpoint_info": "checkpoint1: The most upvoted comment in the submission \"{{submission}}\".",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/personalfinance/44843/quest-diagnostics-refusing-to-refund-overpayment-due-to",
      "program_html": [
        {
          "url": "__REDDIT__/f/personalfinance/44843/quest-diagnostics-refusing-to-refund-overpayment-due-to",
          "locator": "document.querySelector('.comment__header a[href*=\"MarvelsGrantMan136\"]')?.closest('.comment')?.querySelector('.comment__body')?.outerText",
          "required_contents": {
            "must_include": [
              "I would file and argue for benefits if denied. It will cost you nothing."
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 30182,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/personalfinance/109821/my-employer-is-causing-my-credit-score-to-drop",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Reply to the user \"{{user}}\" in the submission \"{{current_page}}\" with the most upvoted comment in the submission \"{{submission}}\".",
    "intent": "Reply to the user \"imakenosensetopeople\" in the submission \"My employer is causing my credit score to drop..\" with the most upvoted comment in the submission \"Obtaining a Perfect Credit Score\".",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Reply to a user with the most liked comment in another submission",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/personalfinance/109821/my-employer-is-causing-my-credit-score-to-drop",
      "user": "imakenosensetopeople",
      "current_page": "My employer is causing my credit score to drop..",
      "submission": "Obtaining a Perfect Credit Score",
      "checkpoint1": "780 and 850 get the exact same best rates.",
      "checkpoint_info": "checkpoint1: The most upvoted comment in the submission \"{{submission}}\".",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/personalfinance/109821/my-employer-is-causing-my-credit-score-to-drop",
      "program_html": [
        {
          "url": "__REDDIT__/f/personalfinance/109821/my-employer-is-causing-my-credit-score-to-drop",
          "locator": "document.querySelector('.comment__header a[href*=\"MarvelsGrantMan136\"]')?.closest('.comment')?.querySelector('.comment__body')?.outerText",
          "required_contents": {
            "must_include": [
              "780 and 850 get the exact same best rates."
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 30183,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/philadelphia/88884/better-time-to-be-a-philly-sports-fan",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Reply to the user \"{{user}}\" in the submission \"{{current_page}}\" with the most upvoted comment in the submission \"{{submission}}\".",
    "intent": "Reply to the user \"TreeMac12\" in the submission \"Better time to be a Philly sports fan?\" with the most upvoted comment in the submission \"Philadelphia has now lost 3 major finals in one athletic year (MLS, MLB, NFL)\".",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Reply to a user with the most liked comment in another submission",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/philadelphia/88884/better-time-to-be-a-philly-sports-fan",
      "user": "TreeMac12",
      "current_page": "Better time to be a Philly sports fan?",
      "submission": "Philadelphia has now lost 3 major finals in one athletic year (MLS, MLB, NFL)",
      "checkpoint1": "We're number one at being number two",
      "checkpoint_info": "checkpoint1: The most upvoted comment in the submission \"{{submission}}\".",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/philadelphia/88884/better-time-to-be-a-philly-sports-fan",
      "program_html": [
        {
          "url": "__REDDIT__/f/philadelphia/88884/better-time-to-be-a-philly-sports-fan",
          "locator": "document.querySelector('.comment__header a[href*=\"MarvelsGrantMan136\"]')?.closest('.comment')?.querySelector('.comment__body')?.outerText",
          "required_contents": {
            "must_include": [
              "We're number one at being number two"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 30184,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/f/DIY/97953/do-i-need-to-replace-my-deck-joists",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Reply to the user \"{{user}}\" in the submission \"{{current_page}}\" with the most upvoted comment in the submission \"{{submission}}\".",
    "intent": "Reply to the user \"wowsuchtroll\" in the submission \"Do I need to replace my deck joists?\" with the most upvoted comment in the submission \"Replaced a rotten threshold.\".",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Reply to a user with the most liked comment in another submission",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/f/DIY/97953/do-i-need-to-replace-my-deck-joists",
      "user": "wowsuchtroll",
      "current_page": "Do I need to replace my deck joists?",
      "submission": "Replaced a rotten threshold.",
      "checkpoint1": "Yeah. That PVC looks like a heck of a trip hazard?!?",
      "checkpoint_info": "checkpoint1: The most upvoted comment in the submission \"{{submission}}\".",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/DIY/97953/do-i-need-to-replace-my-deck-joists",
      "program_html": [
        {
          "url": "__REDDIT__/f/DIY/97953/do-i-need-to-replace-my-deck-joists",
          "locator": "document.querySelector('.comment__header a[href*=\"MarvelsGrantMan136\"]')?.closest('.comment')?.querySelector('.comment__body')?.outerText",
          "required_contents": {
            "must_include": [
              "Yeah. That PVC looks like a heck of a trip hazard?!?"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 30190,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/books",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Upvote all posts among the top {{number}} most voted that have a number of comments above the average in forum {{forum}}.",
    "intent": "Upvote all posts among the top 20 most voted that have a number of comments above the average in forum books.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": true,
    "type_main": "calc",
    "description": "From the forum posts, calculate the average number of comments among the top N posts. Then, upvote all posts that have a number of comments equal to or above that average.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/books",
      "number": "20",
      "average": "105.1",
      "forum": "books",
      "urls": [
        "__REDDIT__/f/books/81371/the-letters-of-t-s-eliot-to-emily-hale-that-were-kept-sealed",
        "__REDDIT__/f/books/59421/friendly-reminder-bookshop-org-exists",
        "__REDDIT__/f/books/59478/the-simple-greatness-of-agatha-christie",
        "__REDDIT__/f/books/17445/i-just-finished-reading-the-hobbit-to-my-6-year-old-daughter",
        "__REDDIT__/f/books/103061/what-is-it-that-makes-used-bookstores-so-wonderful",
        "__REDDIT__/f/books/59401/just-finished-things-fall-apart-chinua-achebe-and-i-loved-it",
        "__REDDIT__/f/books/124150/post-book-depression",
        "__REDDIT__/f/books/59471/i-fell-in-love-and-my-interests-in-books-changed-drastically",
        "__REDDIT__/f/books/59477/i-just-can-t-with-the-forced-romances-in-mysteries-and",
        "__REDDIT__/f/books/17589/all-spaniards-we-discovered-knew-two-english-expressions-one",
        "__REDDIT__/f/books/124024/5-n-y-schools-evacuated-after-bomb-threats-over-lgbtq-book"
      ],
      "test": [
        "__REDDIT__/f/books/124043/banning-words-won-t-make-the-world-more-just-the-atlantic",
        "__REDDIT__/f/books/38271/all-systems-red-by-martha-wells",
        "__REDDIT__/f/books/38309/the-haunting-of-hill-house-was-so-good"
      ]
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__REDDIT__/f/books/81371/the-letters-of-t-s-eliot-to-emily-hale-that-were-kept-sealed",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/59421/friendly-reminder-bookshop-org-exists",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/59478/the-simple-greatness-of-agatha-christie",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/17445/i-just-finished-reading-the-hobbit-to-my-6-year-old-daughter",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/103061/what-is-it-that-makes-used-bookstores-so-wonderful",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/59401/just-finished-things-fall-apart-chinua-achebe-and-i-loved-it",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/124150/post-book-depression",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/59471/i-fell-in-love-and-my-interests-in-books-changed-drastically",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/59477/i-just-can-t-with-the-forced-romances-in-mysteries-and",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/17589/all-spaniards-we-discovered-knew-two-english-expressions-one",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/124024/5-n-y-schools-evacuated-after-bomb-threats-over-lgbtq-book",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/books/124043/banning-words-won-t-make-the-world-more-just-the-atlantic",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/books/38271/all-systems-red-by-martha-wells",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/books/38309/the-haunting-of-hill-house-was-so-good",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30191,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/MechanicalKeyboards",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Upvote all posts among the top {{number}} most voted that have a number of comments above the average in forum {{forum}}.",
    "intent": "Upvote all posts among the top 20 most voted that have a number of comments above the average in forum MechanicalKeyboards.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": true,
    "type_main": "calc",
    "description": "From the forum posts, calculate the average number of comments among the top N posts. Then, upvote all posts that have a number of comments equal to or above that average.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/MechanicalKeyboards",
      "number": "20",
      "average": "84.45",
      "forum": "MechanicalKeyboards",
      "urls": [
        "__REDDIT__/f/MechanicalKeyboards/78288/i-don-t-know-why-i-m-like-this",
        "__REDDIT__/f/MechanicalKeyboards/56381/nobody-asked",
        "__REDDIT__/f/MechanicalKeyboards/35145/you-guys-have-some-really-nice-builds",
        "__REDDIT__/f/MechanicalKeyboards/100026/i-ve-fallen-down-the-rabbit-hole-a-bit-browsing-this-sub",
        "__REDDIT__/f/MechanicalKeyboards/120987/can-someone-help-me-find-this-switch",
        "__REDDIT__/f/MechanicalKeyboards/120870/just-spotted-one-of-you-for-the-first-time-in-austria",
        "__REDDIT__/f/MechanicalKeyboards/14329/big-w",
        "__REDDIT__/f/MechanicalKeyboards/121006/not-for-everyone-but-i-like-it",
        "__REDDIT__/f/MechanicalKeyboards/78374/first-40",
        "__REDDIT__/f/MechanicalKeyboards/56302/decided-to-kill-some-time-on-the-plane"
      ],
      "test": [
        "__REDDIT__/f/MechanicalKeyboards/100156/encountered-a-fellow-enthusiast-today",
        "__REDDIT__/f/MechanicalKeyboards/35141/sa-espresso-on-keychron-k12",
        "__REDDIT__/f/MechanicalKeyboards/100201/not-much-but-i-made-this-from-scratch",
        "__REDDIT__/f/MechanicalKeyboards/35118/it-is-so-true"
      ]
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/78288/i-don-t-know-why-i-m-like-this",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/56381/nobody-asked",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/35145/you-guys-have-some-really-nice-builds",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/100026/i-ve-fallen-down-the-rabbit-hole-a-bit-browsing-this-sub",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/120987/can-someone-help-me-find-this-switch",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/120870/just-spotted-one-of-you-for-the-first-time-in-austria",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/14329/big-w",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/121006/not-for-everyone-but-i-like-it",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/78374/first-40",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/56302/decided-to-kill-some-time-on-the-plane",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/100156/encountered-a-fellow-enthusiast-today",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/35141/sa-espresso-on-keychron-k12",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/100201/not-much-but-i-made-this-from-scratch",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/MechanicalKeyboards/35118/it-is-so-true",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30192,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Music",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Upvote all posts among the top {{number}} most voted that have a number of comments above the average in forum {{forum}}.",
    "intent": "Upvote all posts among the top 20 most voted that have a number of comments above the average in forum Music.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": true,
    "type_main": "calc",
    "description": "From the forum posts, calculate the average number of comments among the top N posts. Then, upvote all posts that have a number of comments equal to or above that average.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Music",
      "number": "20",
      "average": "117.4",
      "forum": "Music",
      "urls": [
        "__REDDIT__/f/Music/35510/fame-and-flashdance-singer-irene-cara-has-died-aged-63",
        "__REDDIT__/f/Music/56626/brian-may-gets-a-knighthood-in-new-year-honours-list",
        "__REDDIT__/f/Music/35453/michael-jackson-s-thriller-returns-to-billboard-top-10-after",
        "__REDDIT__/f/Music/78525/in-february-i-will-walk-a-km-for-every-upvote-i-get-on-this",
        "__REDDIT__/f/Music/56575/rapper-tory-lanez-guilty-in-shooting-of-megan-thee-stallion",
        "__REDDIT__/f/Music/56719/holy-shit-is-tom-s-diner-by-suzanne-vega-amp-dna-so-godamn",
        "__REDDIT__/f/Music/14731/spotify-has-some-bizarre-auto-generated-playlists-that-you",
        "__REDDIT__/f/Music/14701/this-weekend-is-the-20th-anniversary-of-warren-zevon-s-final",
        "__REDDIT__/f/Music/78662/pink-floyd-fans-are-amused-that-the-anti-woke-mob-are"
      ],
      "test": [
        "__REDDIT__/f/Music/100424/does-anyone-else-listen-to-music-this-way",
        "__REDDIT__/f/Music/121233/metallica-ac-dc-ozzy-osbourne-iron-maiden-guns-n-roses-tool",
        "__REDDIT__/f/Music/35373/groovifi-the-ultimate-playlist-generator-for-spotify",
        "__REDDIT__/f/Music/100326/an-album-a-day"
      ]
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__REDDIT__/f/Music/35510/fame-and-flashdance-singer-irene-cara-has-died-aged-63",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/56626/brian-may-gets-a-knighthood-in-new-year-honours-list",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/35453/michael-jackson-s-thriller-returns-to-billboard-top-10-after",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/78525/in-february-i-will-walk-a-km-for-every-upvote-i-get-on-this",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/56575/rapper-tory-lanez-guilty-in-shooting-of-megan-thee-stallion",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/56719/holy-shit-is-tom-s-diner-by-suzanne-vega-amp-dna-so-godamn",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/14731/spotify-has-some-bizarre-auto-generated-playlists-that-you",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/14701/this-weekend-is-the-20th-anniversary-of-warren-zevon-s-final",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/78662/pink-floyd-fans-are-amused-that-the-anti-woke-mob-are",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Music/100424/does-anyone-else-listen-to-music-this-way",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Music/121233/metallica-ac-dc-ozzy-osbourne-iron-maiden-guns-n-roses-tool",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Music/35373/groovifi-the-ultimate-playlist-generator-for-spotify",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Music/100326/an-album-a-day",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30193,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Art",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Upvote all posts among the top {{number}} most voted that have a number of comments above the average in forum {{forum}}.",
    "intent": "Upvote all posts among the top 20 most voted that have a number of comments above the average in forum Art.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": true,
    "type_main": "calc",
    "description": "From the forum posts, calculate the average number of comments among the top N posts. Then, upvote all posts that have a number of comments equal to or above that average.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Art",
      "number": "20",
      "average": "132.7",
      "forum": "Art",
      "urls": [
        "__REDDIT__/f/Art/10038/random-pencils-me-markers-and-pencils-2022",
        "__REDDIT__/f/Art/116617/chester-bennington-me-string-art-2023",
        "__REDDIT__/f/Art/30768/wayamba-me-digital-2022",
        "__REDDIT__/f/Art/30859/the-general-zapped-an-angel-karel-thole-oils-1970",
        "__REDDIT__/f/Art/30832/black-is-a-happy-color-me-watercolor-2022",
        "__REDDIT__/f/Art/95719/the-simpler-days-dovgrub-digital-2023",
        "__REDDIT__/f/Art/51628/skely-jelly-me-digital-2022",
        "__REDDIT__/f/Art/10121/la-bagnante-adornata-me-3d-2022",
        "__REDDIT__/f/Art/51774/we6574-interior-me-digital-2022",
        "__REDDIT__/f/Art/30772/origami-titan-beetle-designed-by-shuki-kato-and-folded-by-me",
        "__REDDIT__/f/Art/10050/king-me-coloured-pencils-2022",
        "__REDDIT__/f/Art/10081/painting-pumpkins-me-gouache-2022"
      ],
      "test": [
        "__REDDIT__/f/Art/30905/house-exterior-3-me-digital-2022",
        "__REDDIT__/f/Art/30872/daytime-me-acrylic-on-canvas-2022",
        "__REDDIT__/f/Art/10146/lost-me-oil-paint-2022",
        "__REDDIT__/f/Art/30842/moods-of-maizie-by-me-pen-2022"
      ]
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__REDDIT__/f/Art/10038/random-pencils-me-markers-and-pencils-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/116617/chester-bennington-me-string-art-2023",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/30768/wayamba-me-digital-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/30859/the-general-zapped-an-angel-karel-thole-oils-1970",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/30832/black-is-a-happy-color-me-watercolor-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/95719/the-simpler-days-dovgrub-digital-2023",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/51628/skely-jelly-me-digital-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/10121/la-bagnante-adornata-me-3d-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/51774/we6574-interior-me-digital-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/30772/origami-titan-beetle-designed-by-shuki-kato-and-folded-by-me",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/10050/king-me-coloured-pencils-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/10081/painting-pumpkins-me-gouache-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Art/30905/house-exterior-3-me-digital-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Art/30872/daytime-me-acrylic-on-canvas-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Art/10146/lost-me-oil-paint-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Art/30842/moods-of-maizie-by-me-pen-2022",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 30194,
    "sites": [
      "reddit"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/f/Washington",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Upvote all posts among the top {{number}} most voted that have a number of comments above the average in forum {{forum}}.",
    "intent": "Upvote all posts among the top 20 most voted that have a number of comments above the average in forum Washington.",
    "required_obs": "any",
    "required_wait": false,
    "affects_environment": true,
    "type_main": "calc",
    "description": "From the forum posts, calculate the average number of comments among the top N posts. Then, upvote all posts that have a number of comments equal to or above that average.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/f/Washington",
      "number": "20",
      "average": "39.95",
      "forum": "Washington",
      "urls": [
        "__REDDIT__/f/Washington/58175/first-recorded-moose-sighting-ever-in-mount-rainier-national",
        "__REDDIT__/f/Washington/16268/we-eloped-in-washington-today",
        "__REDDIT__/f/Washington/36974/got-some-snow-last-night",
        "__REDDIT__/f/Washington/102023/the-aurora-was-visible-from-central-washington-last-night",
        "__REDDIT__/f/Washington/37120/june-1955-my-grandfather-was-happy-to-return-home-after-a",
        "__REDDIT__/f/Washington/80243/visited-cape-disappointment-state-park-near-ilwaco-today-oc",
        "__REDDIT__/f/Washington/58186/stayed-at-a-cabin-in-plain-wa-this-was-one-night-of-snow",
        "__REDDIT__/f/Washington/16294/my-first-time-in-the-us-and-i-am-amazed-by-the-colors-of"
      ],
      "test": [
        "__REDDIT__/f/Washington/58250/a-population-density-map-of-washington",
        "__REDDIT__/f/Washington/37094/orcas-passing-by-the-point-robinson-lighthouse-on-vashon",
        "__REDDIT__/f/Washington/122910/as-an-oregonian-i-m-biased-but-damn-seattle-was-gorgeous"
      ]
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__REDDIT__/f/Washington/58175/first-recorded-moose-sighting-ever-in-mount-rainier-national",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/16268/we-eloped-in-washington-today",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/36974/got-some-snow-last-night",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/102023/the-aurora-was-visible-from-central-washington-last-night",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/37120/june-1955-my-grandfather-was-happy-to-return-home-after-a",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/80243/visited-cape-disappointment-state-park-near-ilwaco-today-oc",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/58186/stayed-at-a-cabin-in-plain-wa-this-was-one-night-of-snow",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/16294/my-first-time-in-the-us-and-i-am-amazed-by-the-colors-of",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "must_include": [
              "vote vote--user-upvoted"
            ]
          }
        },
        {
          "url": "__REDDIT__/f/Washington/58250/a-population-density-map-of-washington",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Washington/37094/orcas-passing-by-the-point-robinson-lighthouse-on-vashon",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        },
        {
          "url": "__REDDIT__/f/Washington/122910/as-an-oregonian-i-m-biased-but-damn-seattle-was-gorgeous",
          "locator": "document.querySelector('div.submission__vote').querySelector('form').getAttribute('class')",
          "required_contents": {
            "exact_match": "vote"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40000,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/a11yproject/a11yproject.com",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the total number of commits made by {{user1}} and {{user2}} in the main (master) branch since {{month}}/{{year}}? Include merged pull requests as well and do not skip them.",
    "intent": "What is the total number of commits made by Eric Bailey and dependabot in the main (master) branch since 10/2022? Include merged pull requests as well and do not skip them.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Go to the commit page and count the number of commits made by user1 and user2 during the specified period. Return the total number of commits made by both user1 and user2 combined.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/a11yproject/a11yproject.com",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/commits/main",
      "user1": "Eric Bailey",
      "user2": "dependabot",
      "year": "2022",
      "month": "10",
      "contents": "41",
      "checkpoint1": "31",
      "checkpoint2": "10",
      "checkpoint_info": "checkpoint1: The number of commits made by {{user1}}. checkpoint2: The total number of commits made by {{user2}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "41"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "41"
    }
  },
  {
    "task_id": 40001,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/umano/AndroidSlidingUpPanel",
    "start_url_lite": "__GITLAB__/umano/AndroidSlidingUpPanel/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the total number of commits made by {{user1}} and {{user2}} in the main (master) branch since {{month}}/{{year}}? Include merged pull requests as well and do not skip them.",
    "intent": "What is the total number of commits made by tokudu and Sergii Pechenizkyi in the main (master) branch since 11/2015? Include merged pull requests as well and do not skip them.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Go to the commit page and count the number of commits made by user1 and user2 during the specified period. Return the total number of commits made by both user1 and user2 combined.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/umano/AndroidSlidingUpPanel",
      "start_url_lite": "__GITLAB__/umano/AndroidSlidingUpPanel/-/commits/master",
      "user1": "tokudu",
      "user2": "Sergii Pechenizkyi",
      "year": "2015",
      "month": "11",
      "contents": "37",
      "checkpoint1": "25",
      "checkpoint2": "12",
      "checkpoint_info": "checkpoint1: The number of commits made by {{user1}}. checkpoint2: The total number of commits made by {{user2}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "37"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "37"
    }
  },
  {
    "task_id": 40002,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/thoughtbot/administrate",
    "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the total number of commits made by {{user1}} and {{user2}} in the main (master) branch since {{month}}/{{year}}? Include merged pull requests as well and do not skip them.",
    "intent": "What is the total number of commits made by dependabot and jubilee2 in the main (master) branch since 7/2022? Include merged pull requests as well and do not skip them.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Go to the commit page and count the number of commits made by user1 and user2 during the specified period. Return the total number of commits made by both user1 and user2 combined.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/thoughtbot/administrate",
      "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/commits/main",
      "user1": "dependabot",
      "user2": "jubilee2",
      "year": "2022",
      "month": "7",
      "contents": "51",
      "checkpoint1": "42",
      "checkpoint2": "9",
      "checkpoint_info": "checkpoint1: The number of commits made by {{user1}}. checkpoint2: The total number of commits made by {{user2}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "51"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "51"
    }
  },
  {
    "task_id": 40003,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/PyAV-Org/PyAV",
    "start_url_lite": "__GITLAB__/PyAV-Org/PyAV/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the total number of commits made by {{user1}} and {{user2}} in the main (master) branch since {{month}}/{{year}}? Include merged pull requests as well and do not skip them.",
    "intent": "What is the total number of commits made by Jeremy Lainé and Philip de Nier in the main (master) branch since 1/2021? Include merged pull requests as well and do not skip them.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Go to the commit page and count the number of commits made by user1 and user2 during the specified period. Return the total number of commits made by both user1 and user2 combined.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/PyAV-Org/PyAV",
      "start_url_lite": "__GITLAB__/PyAV-Org/PyAV/-/commits/main",
      "user1": "Jeremy Lainé",
      "user2": "Philip de Nier",
      "year": "2021",
      "month": "1",
      "contents": "101",
      "checkpoint1": "88",
      "checkpoint2": "13",
      "checkpoint_info": "checkpoint1: The number of commits made by {{user1}}. checkpoint2: The total number of commits made by {{user2}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "101"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "101"
    }
  },
  {
    "task_id": 40004,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/vinta/awesome-python",
    "start_url_lite": "__GITLAB__/vinta/awesome-python/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the total number of commits made by {{user1}} and {{user2}} in the main (master) branch since {{month}}/{{year}}? Include merged pull requests as well and do not skip them.",
    "intent": "What is the total number of commits made by Vinta Chen and Iheb Haboubi in the main (master) branch since 8/2020? Include merged pull requests as well and do not skip them.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "calc",
    "description": "Go to the commit page and count the number of commits made by user1 and user2 during the specified period. Return the total number of commits made by both user1 and user2 combined.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/vinta/awesome-python",
      "start_url_lite": "__GITLAB__/vinta/awesome-python/-/commits/master",
      "user1": "Vinta Chen",
      "user2": "Iheb Haboubi",
      "year": "2020",
      "month": "8",
      "contents": "56",
      "checkpoint1": "48",
      "checkpoint2": "8",
      "checkpoint_info": "checkpoint1: The number of commits made by {{user1}}. checkpoint2: The total number of commits made by {{user2}}.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "56"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "56"
    }
  },
  {
    "task_id": 40010,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many issues in total have the {{tag1}} label or the {{tag2}} label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "intent": "How many issues in total have the [Priority] Low label or the [Type] Enhancement label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to the Issue page. Then, count the number of issues with the tag1 label from ALL. Next, count the number of issues with the tag2 label. Finally, count the number of issues that have both the tag1 and tag2 labels. The answer will be the sum of the number of issues with the tag1 label and the number of issues with the tag2 label, minus the number of issues that have both labels.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
      "tag1": "[Priority] Low",
      "tag2": "[Type] Enhancement",
      "contents": "10",
      "checkpoint1": "7",
      "checkpoint2": "9",
      "checkpoint3": "6",
      "checkpoint_info": "checkpoint1: the number of issues with the {{tag1}} label, checkpoint2: the number of issues with the {{tag2}} label, checkpoint3: the number of issues with the {{tag1}} and {{tag2}} label",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "10"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "10"
    }
  },
  {
    "task_id": 40011,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many issues in total have the {{tag1}} label or the {{tag2}} label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "intent": "How many issues in total have the accessibility label or the redesign label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to the Issue page. Then, count the number of issues with the tag1 label from ALL. Next, count the number of issues with the tag2 label. Finally, count the number of issues that have both the tag1 and tag2 labels. The answer will be the sum of the number of issues with the tag1 label and the number of issues with the tag2 label, minus the number of issues that have both labels.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
      "tag1": "accessibility",
      "tag2": "redesign",
      "contents": "278",
      "checkpoint1": "256",
      "checkpoint2": "24",
      "checkpoint3": "2",
      "checkpoint_info": "checkpoint1: the number of issues with the {{tag1}} label, checkpoint2: the number of issues with the {{tag2}} label, checkpoint3: the number of issues with the {{tag1}} and {{tag2}} label",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "278"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "278"
    }
  },
  {
    "task_id": 40012,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many issues in total have the {{tag1}} label or the {{tag2}} label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "intent": "How many issues in total have the styling label or the claimed label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to the Issue page. Then, count the number of issues with the tag1 label from ALL. Next, count the number of issues with the tag2 label. Finally, count the number of issues that have both the tag1 and tag2 labels. The answer will be the sum of the number of issues with the tag1 label and the number of issues with the tag2 label, minus the number of issues that have both labels.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
      "tag1": "styling",
      "tag2": "claimed",
      "contents": "80",
      "checkpoint1": "26",
      "checkpoint2": "68",
      "checkpoint3": "14",
      "checkpoint_info": "checkpoint1: the number of issues with the {{tag1}} label, checkpoint2: the number of issues with the {{tag2}} label, checkpoint3: the number of issues with the {{tag1}} and {{tag2}} label",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "80"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "80"
    }
  },
  {
    "task_id": 40013,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many issues in total have the {{tag1}} label or the {{tag2}} label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "intent": "How many issues in total have the good first issue label or the help wanted label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to the Issue page. Then, count the number of issues with the tag1 label from ALL. Next, count the number of issues with the tag2 label. Finally, count the number of issues that have both the tag1 and tag2 labels. The answer will be the sum of the number of issues with the tag1 label and the number of issues with the tag2 label, minus the number of issues that have both labels.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
      "tag1": "good first issue",
      "tag2": "help wanted",
      "contents": "1157 |OR| 1,157",
      "checkpoint1": "255",
      "checkpoint2": "1021",
      "checkpoint3": "119",
      "checkpoint_info": "checkpoint1: the number of issues with the {{tag1}} label, checkpoint2: the number of issues with the {{tag2}} label, checkpoint3: the number of issues with the {{tag1}} and {{tag2}} label",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "1157 |OR| 1,157"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "1157 |OR| 1,157"
    }
  },
  {
    "task_id": 40014,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many issues in total have the {{tag1}} label or the {{tag2}} label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "intent": "How many issues in total have the feature label or the markup label? Include both Open and Closed issues (All). Consider all issues, not limited to yours. If an issue has both labels, count it only once.",
    "required_obs": "any",
    "type_main": "others",
    "description": "First, go to the Issue page. Then, count the number of issues with the tag1 label from ALL. Next, count the number of issues with the tag2 label. Finally, count the number of issues that have both the tag1 and tag2 labels. The answer will be the sum of the number of issues with the tag1 label and the number of issues with the tag2 label, minus the number of issues that have both labels.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/dashboard/issues?scope=all&state=all&assignee_id=Any",
      "tag1": "feature",
      "tag2": "markup",
      "contents": "2210 |OR| 2,210",
      "checkpoint1": "2194",
      "checkpoint2": "19",
      "checkpoint3": "3",
      "checkpoint_info": "checkpoint1: the number of issues with the {{tag1}} label, checkpoint2: the number of issues with the {{tag2}} label, checkpoint3: the number of issues with the {{tag1}} and {{tag2}} label",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "2210 |OR| 2,210"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2210 |OR| 2,210"
    }
  },
  {
    "task_id": 40020,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/abisubramanya27/projects",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Among {{user}}'s personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "intent": "Among Abishek S's personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to the user's profile. Then, navigate to the user's personal projects. From there, check the commit history of each repository and find the repository with the longest commit history.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/abisubramanya27/projects",
      "user": "Abishek S",
      "contents": "CS3500, 1419 |OR| CS3500, 1,419",
      "checkpoint1": "CS3500",
      "checkpoint2": "1,419",
      "checkpoint_info": "checkpoint1: the repository name, checkpoint2: the history length",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "CS3500, 1419 |OR| CS3500, 1,419"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "CS3500, 1419 |OR| CS3500, 1,419"
    }
  },
  {
    "task_id": 40021,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/byteblaze/projects",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Among {{user}}'s personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "intent": "Among Byte Blaze's personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to the user's profile. Then, navigate to the user's personal projects. From there, check the commit history of each repository and find the repository with the longest commit history.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/byteblaze/projects",
      "user": "Byte Blaze",
      "contents": "ericwbailey.website, 1646 |OR| ericwbailey.website, 1,646",
      "checkpoint1": "ericwbailey.website",
      "checkpoint2": "1646",
      "checkpoint_info": "checkpoint1: the repository name, checkpoint2: the history length",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "ericwbailey.website, 1646 |OR| ericwbailey.website, 1,646"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "ericwbailey.website, 1646 |OR| ericwbailey.website, 1,646"
    }
  },
  {
    "task_id": 40022,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/aklsh/projects",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Among {{user}}'s personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "intent": "Among Akilesh Kannan's personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to the user's profile. Then, navigate to the user's personal projects. From there, check the commit history of each repository and find the repository with the longest commit history.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/aklsh/projects",
      "user": "Akilesh Kannan",
      "contents": "nvidia-patch, 910",
      "checkpoint1": "nvidia-patch",
      "checkpoint2": "910",
      "checkpoint_info": "checkpoint1: the repository name, checkpoint2: the history length",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "nvidia-patch, 910"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "nvidia-patch, 910"
    }
  },
  {
    "task_id": 40023,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/murale127/projects",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Among {{user}}'s personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "intent": "Among Muralekrishnan R's personal repositories, which one has the longest commit history? Provide the repository name along with the history length in the format: {repository name}, {history length}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "First, go to the user's profile. Then, navigate to the user's personal projects. From there, check the commit history of each repository and find the repository with the longest commit history.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/murale127/projects",
      "user": "Muralekrishnan R",
      "contents": "HW-Spectrum-Analyzer, 37",
      "checkpoint1": "HW-Spectrum-Analyzer",
      "checkpoint2": "37",
      "checkpoint_info": "checkpoint1: the repository name, checkpoint2: the history length",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "HW-Spectrum-Analyzer, 37"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "HW-Spectrum-Analyzer, 37"
    }
  },
  {
    "task_id": 40030,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of stars for the top {{number}} most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of stars for the top 40 most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Calculate the total number of stars from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "40",
      "contents": "36",
      "checkpoint1": "831",
      "checkpoint2": "610",
      "checkpoint3": "1441",
      "checkpoint_info": "checkpoint1: sum of the stars in page1. checkpoint2: sum of the stars in page2. checkpoint3: sum of the stars in page1 and page2.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "36"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "36"
    }
  },
  {
    "task_id": 40031,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of stars for the top {{number}} most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of stars for the top 60 most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Calculate the total number of stars from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "60",
      "contents": "32",
      "checkpoint1": "831",
      "checkpoint2": "610",
      "checkpoint3": "462",
      "checkpoint4": "1903",
      "checkpoint_info": "checkpoint1: sum of the stars in page1. checkpoint2: sum of the stars in page2. checkpoint3: sum of the stars in page1 and page2.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "32"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "32"
    }
  },
  {
    "task_id": 40032,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of stars for the top {{number}} most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of stars for the top 80 most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Calculate the total number of stars from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "80",
      "contents": "27",
      "checkpoint1": "831",
      "checkpoint2": "610",
      "checkpoint3": "462",
      "checkpoint4": "226",
      "checkpoint5": "2129",
      "checkpoint_info": "checkpoint1: sum of the stars in page1. checkpoint2: sum of the stars in page2. checkpoint3: sum of the stars in page1 and page2.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "27"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "27"
    }
  },
  {
    "task_id": 40033,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of stars for the top {{number}} most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of stars for the top 100 most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Calculate the total number of stars from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "100",
      "contents": "22",
      "checkpoint1": "831",
      "checkpoint2": "610",
      "checkpoint3": "462",
      "checkpoint4": "226",
      "checkpoint5": "80",
      "checkpoint6": "2209",
      "checkpoint_info": "checkpoint1: sum of the stars in page1. checkpoint2: sum of the stars in page2. checkpoint3: sum of the stars in page1 and page2.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "22"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "22"
    }
  },
  {
    "task_id": 40034,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of stars for the top {{number}} most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of stars for the top 50 most-starred projects across all repositories? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Calculate the total number of stars from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "50",
      "contents": "34",
      "checkpoint1": "831",
      "checkpoint2": "610",
      "checkpoint3": "255",
      "checkpoint4": "1696",
      "checkpoint_info": "checkpoint1: sum of the stars in page1. checkpoint2: sum of the stars in page2. checkpoint3: sum of the stars in page3. checkpoint4: sum of the stars in page1 and page2.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "34"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "34"
    }
  },
  {
    "task_id": 40040,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of merged requests for the top {{number}} most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of merged requests for the top 40 most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The merged requests count of the projects displayed on each page will be shown. Calculate the total number of merged requests from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "40",
      "contents": "71",
      "checkpoint1": "1527",
      "checkpoint2": "1308",
      "checkpoint3": "2835",
      "checkpoint_info": "checkpoint1: sum of the merged requests in page1. checkpoint2: sum of the merged requests in page2. checkpoint3: sum of the merged requests in page1 and page2.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "71"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "71"
    }
  },
  {
    "task_id": 40041,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of merged requests for the top {{number}} most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of merged requests for the top 60 most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The merged requests count of the projects displayed on each page will be shown. Calculate the total number of merged requests from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "60",
      "contents": "51",
      "checkpoint1": "1527",
      "checkpoint2": "1308",
      "checkpoint3": "196",
      "checkpoint4": "3031",
      "checkpoint_info": "checkpoint1: sum of the merged requests in page1. checkpoint2: sum of the merged requests in page2. checkpoint3: sum of the merged requests in page1 and page2.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "51"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "51"
    }
  },
  {
    "task_id": 40042,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of merged requests for the top {{number}} most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of merged requests for the top 30 most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The merged requests count of the projects displayed on each page will be shown. Calculate the total number of merged requests from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "30",
      "contents": "77",
      "checkpoint1": "1527",
      "checkpoint2": "792",
      "checkpoint3": "2319",
      "checkpoint_info": "checkpoint1: sum of the merged requests in page1. checkpoint2: sum of the merged requests in page2. checkpoint3: sum of the merged requests in page1 and page2.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "77"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "77"
    }
  },
  {
    "task_id": 40043,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of merged requests for the top {{number}} most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of merged requests for the top 35 most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The merged requests count of the projects displayed on each page will be shown. Calculate the total number of merged requests from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "35",
      "contents": "77",
      "checkpoint1": "1527",
      "checkpoint2": "1168",
      "checkpoint3": "2695",
      "checkpoint_info": "checkpoint1: sum of the merged requests in page1. checkpoint2: sum of the merged requests in page2. checkpoint3: sum of the merged requests in page1 and page2.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "77"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "77"
    }
  },
  {
    "task_id": 40044,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "What is the average number of merged requests for the top {{number}} most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "intent": "What is the average number of merged requests for the top 50 most-starred projects? Please explore all the projects in this website, not limited to your projects. Round to the nearest whole number and provide the answer as an integer.",
    "required_obs": "any",
    "type_main": "calc",
    "type_sub": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The merged requests count of the projects displayed on each page will be shown. Calculate the total number of merged requests from the first page up to the specified count, divide this total by the number of projects, and output the result as an integer.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "50",
      "contents": "58",
      "checkpoint1": "1527",
      "checkpoint2": "1308",
      "checkpoint3": "64",
      "checkpoint4": "2899",
      "checkpoint_info": "checkpoint1: sum of the merged requests in page1. checkpoint2: sum of the merged requests in page2. checkpoint3: sum of the merged requests in page2. checkpoint4: sum of the merged requests in page1 and page2.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "58"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "58"
    }
  },
  {
    "task_id": 40050,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many projects have {{number}} or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "intent": "How many projects have 30 or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Count the total number of projects with the specified star numbers.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "30",
      "contents": "34",
      "checkpoint1": "20",
      "checkpoint2": "14",
      "checkpint_info": "checkpoint1: the number of projects in the first page, checkpoint2: the number of projects in the last page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "34"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "34"
    }
  },
  {
    "task_id": 40051,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many projects have {{number}} or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "intent": "How many projects have 25 or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Count the total number of projects with the specified star numbers.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "25",
      "contents": "48",
      "checkpoint1": "20",
      "checkpoint2": "8",
      "checkpint_info": "checkpoint1: the number of projects in the first page, checkpoint2: the number of projects in the last page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "48"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "48"
    }
  },
  {
    "task_id": 40052,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many projects have {{number}} or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "intent": "How many projects have 16 or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Count the total number of projects with the specified star numbers.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "16",
      "contents": "64",
      "checkpoint1": "20",
      "checkpoint2": "4",
      "checkpint_info": "checkpoint1: the number of projects in the first page, checkpoint2: the number of projects in the last page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "64"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "64"
    }
  },
  {
    "task_id": 40053,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many projects have {{number}} or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "intent": "How many projects have 6 or more stars across all projects? Note that this is not limited to only your projects. Please explore all the projects in this website.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "From Explore, select Most stars and navigate through the pages. The star count of the projects displayed on each page will be shown. Count the total number of projects with the specified star numbers.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects/starred",
      "number": "6",
      "contents": "85",
      "checkpoint1": "20",
      "checkpoint2": "5",
      "checkpint_info": "checkpoint1: the number of projects in the first page, checkpoint2: the number of projects in the last page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "85"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "85"
    }
  },
  {
    "task_id": 40060,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/explore/projects",
    "start_url_lite": "__GITLAB__/explore/projects",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "intent": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "Calculate the total number of stars from the first page up to the next page, output the stars.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/explore/projects",
      "start_url_lite": "__GITLAB__/explore/projects",
      "contents": "8, 1, 2, 21, 0, 1, 44, 12, 0, 28, 0, 7, 46, 55, 0, 0, 34, 5, 8, 22, 42, 29, 33, 2, 20, 1, 32, 0, 30, 29, 0, 0, 34, 32, 0, 0, 3, 39, 0, 0",
      "checkpoint1": "8, 1, 2, 21, 0, 1, 44, 12, 0, 28, 0, 7, 46, 55, 0, 0, 34, 5, 8, 22",
      "checkpoint2": "42, 29, 33, 2, 20, 1, 32, 0, 30, 29, 0, 0, 34, 32, 0, 0, 3, 39, 0, 0",
      "checkpoint_info": "checkpoint1: the numbers of stars in the first page, checkpoint2: the numbers of stars in the second page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "8, 1, 2, 21, 0, 1, 44, 12, 0, 28, 0, 7, 46, 55, 0, 0, 34, 5, 8, 22, 42, 29, 33, 2, 20, 1, 32, 0, 30, 29, 0, 0, 34, 32, 0, 0, 3, 39, 0, 0"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "8, 1, 2, 21, 0, 1, 44, 12, 0, 28, 0, 7, 46, 55, 0, 0, 34, 5, 8, 22, 42, 29, 33, 2, 20, 1, 32, 0, 30, 29, 0, 0, 34, 32, 0, 0, 3, 39, 0, 0"
    }
  },
  {
    "task_id": 40061,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/explore/projects?non_archived=true&page=3&sort=name_asc",
    "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=3&sort=name_asc",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "intent": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "Calculate the total number of stars from the first page up to the next page, output the stars.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/explore/projects?non_archived=true&page=3&sort=name_asc",
      "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=3&sort=name_asc",
      "contents": "0, 22, 7, 30, 16, 0, 7, 0, 0, 34, 4, 52, 0, 0, 0, 0, 0, 0, 0, 0, 11, 33, 3, 0, 21, 6, 0, 7, 4, 0, 0, 0, 0, 6, 30, 0, 0, 0, 0, 35",
      "checkpoint1": "0, 22, 7, 30, 16, 0, 7, 0, 0, 34, 4, 52, 0, 0, 0, 0, 0, 0, 0, 0",
      "checkpoint2": "11, 33, 3, 0, 21, 6, 0, 7, 4, 0, 0, 0, 0, 6, 30, 0, 0, 0, 0, 35",
      "checkpoint_info": "checkpoint1: the numbers of stars in the first page, checkpoint2: the numbers of stars in the second page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0, 22, 7, 30, 16, 0, 7, 0, 0, 34, 4, 52, 0, 0, 0, 0, 0, 0, 0, 0, 11, 33, 3, 0, 21, 6, 0, 7, 4, 0, 0, 0, 0, 6, 30, 0, 0, 0, 0, 35"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0, 22, 7, 30, 16, 0, 7, 0, 0, 34, 4, 52, 0, 0, 0, 0, 0, 0, 0, 0, 11, 33, 3, 0, 21, 6, 0, 7, 4, 0, 0, 0, 0, 6, 30, 0, 0, 0, 0, 35"
    }
  },
  {
    "task_id": 40062,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/explore/projects?non_archived=true&page=5&sort=name_asc",
    "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=5&sort=name_asc",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "intent": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "Calculate the total number of stars from the first page up to the next page, output the stars.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/explore/projects?non_archived=true&page=5&sort=name_asc",
      "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=5&sort=name_asc",
      "contents": "6, 0, 2, 1, 12, 51, 32, 35, 29, 27, 2, 5, 30, 27, 0, 0, 14, 21, 17, 25, 0, 0, 15, 0, 28, 23, 31, 26, 43, 0, 0, 0, 0, 0, 27, 31, 25, 0, 6, 2",
      "checkpoint1": "6, 0, 2, 1, 12, 51, 32, 35, 29, 27, 2, 5, 30, 27, 0, 0, 14, 21, 17, 25",
      "checkpoint2": "0, 0, 15, 0, 28, 23, 31, 26, 43, 0, 0, 0, 0, 0, 27, 31, 25, 0, 6, 2",
      "checkpoint_info": "checkpoint1: the numbers of stars in the first page, checkpoint2: the numbers of stars in the second page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "6, 0, 2, 1, 12, 51, 32, 35, 29, 27, 2, 5, 30, 27, 0, 0, 14, 21, 17, 25, 0, 0, 15, 0, 28, 23, 31, 26, 43, 0, 0, 0, 0, 0, 27, 31, 25, 0, 6, 2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "6, 0, 2, 1, 12, 51, 32, 35, 29, 27, 2, 5, 30, 27, 0, 0, 14, 21, 17, 25, 0, 0, 15, 0, 28, 23, 31, 26, 43, 0, 0, 0, 0, 0, 27, 31, 25, 0, 6, 2"
    }
  },
  {
    "task_id": 40063,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/explore/projects?non_archived=true&page=7&sort=name_asc",
    "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=7&sort=name_asc",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "intent": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "Calculate the total number of stars from the first page up to the next page, output the stars.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/explore/projects?non_archived=true&page=7&sort=name_asc",
      "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=7&sort=name_asc",
      "contents": "0, 12, 3, 0, 38, 26, 0, 42, 28, 17, 47, 19, 30, 39, 41, 45, 25, 8, 12, 2, 0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32",
      "checkpoint1": "0, 12, 3, 0, 38, 26, 0, 42, 28, 17, 47, 19, 30, 39, 41, 45, 25, 8, 12, 2",
      "checkpoint2": "0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32",
      "checkpoint_info": "checkpoint1: the numbers of stars in the first page, checkpoint2: the numbers of stars in the second page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0, 12, 3, 0, 38, 26, 0, 42, 28, 17, 47, 19, 30, 39, 41, 45, 25, 8, 12, 2, 0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0, 12, 3, 0, 38, 26, 0, 42, 28, 17, 47, 19, 30, 39, 41, 45, 25, 8, 12, 2, 0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32"
    }
  },
  {
    "task_id": 40064,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/explore/projects?non_archived=true&page=8&sort=name_asc",
    "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=8&sort=name_asc",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "intent": "Output the number of stars on this page and the next page, separated by a comma and space.",
    "required_obs": "any",
    "type_main": "massive_memory",
    "description": "Calculate the total number of stars from the first page up to the next page, output the stars.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/explore/projects?non_archived=true&page=8&sort=name_asc",
      "start_url_lite": "__GITLAB__/explore/projects?non_archived=true&page=8&sort=name_asc",
      "contents": "0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32, 0, 20, 0, 7, 2, 0, 0, 0, 0, 1, 35, 2",
      "checkpoint1": "0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32",
      "checkpoint2": "0, 20, 0, 7, 2, 0, 0, 0, 0, 1, 35, 2",
      "checkpoint_info": "checkpoint1: the numbers of stars in the first page, checkpoint2: the numbers of stars in the second page",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32, 0, 20, 0, 7, 2, 0, 0, 0, 0, 1, 35, 2"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0, 0, 5, 0, 0, 11, 0, 0, 24, 0, 19, 22, 33, 16, 0, 9, 0, 0, 5, 32, 0, 20, 0, 7, 2, 0, 0, 0, 0, 1, 35, 2"
    }
  },
  {
    "task_id": 40070,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the one with the most open issues among all the projects on the website. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the one with the most open issues among all the projects on the website",
      "answer": "OpenAPITools/openapi-generator |OR| OpenAPI Tools/openapi-generator",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "OpenAPITools/openapi-generator |OR| OpenAPI Tools/openapi-generator"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "OpenAPITools/openapi-generator |OR| OpenAPI Tools/openapi-generator"
    }
  },
  {
    "task_id": 40071,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the one for Javascript engine that displays beautiful math. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the one for Javascript engine that displays beautiful math",
      "answer": "mathjax/MathJax |OR| MathJax/MathJax",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "mathjax/MathJax |OR| MathJax/MathJax"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "mathjax/MathJax |OR| MathJax/MathJax"
    }
  },
  {
    "task_id": 40072,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the repository with already merged PRs assigned to me most recently. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the repository with already merged PRs assigned to me most recently",
      "answer": "a11yproject/a11yproject.com |OR| The A11Y Project/a11yproject.com",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "a11yproject/a11yproject.com |OR| The A11Y Project/a11yproject.com"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "a11yproject/a11yproject.com |OR| The A11Y Project/a11yproject.com"
    }
  },
  {
    "task_id": 40073,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the one with the smallest number of PRs among the projects by Facebook. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the one with the smallest number of PRs among the projects by Facebook",
      "answer": "facebook/buck |OR| Meta/buck",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "facebook/buck |OR| Meta/buck"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "facebook/buck |OR| Meta/buck"
    }
  },
  {
    "task_id": 40074,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the one for a Chrome extention that one of my followers hosts. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the one for a Chrome extention that one of my followers hosts",
      "answer": "panicsteve/cloud-to-butt |OR| Steven Frank/cloud-to-butt",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "panicsteve/cloud-to-butt |OR| Steven Frank/cloud-to-butt"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "panicsteve/cloud-to-butt |OR| Steven Frank/cloud-to-butt"
    }
  },
  {
    "task_id": 40075,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: the repository with the most forks, neither hosted nor forked by me, and updated most recently. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "the repository with the most forks, neither hosted nor forked by me, and updated most recently",
      "answer": "Roshanjossey/nvidia-patch |OR| Roshan Jossy/timeit",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "Roshanjossey/nvidia-patch |OR| Roshan Jossy/timeit"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Roshanjossey/nvidia-patch |OR| Roshan Jossy/timeit"
    }
  },
  {
    "task_id": 40076,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell the project that meets the following condition: {{target}}. Only return the (author)/(project_name) part.",
    "intent": "Tell the project that meets the following condition: Project ID 1. Only return the (author)/(project_name) part.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/",
      "start_url_lite": "__GITLAB__/explore",
      "target": "Project ID 1",
      "answer": "gitlab-instance-58545a48/Monitoring |OR| GitLab Instance/Monitoring",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "must_include": [
          "gitlab-instance-58545a48/Monitoring |OR| GitLab Instance/Monitoring"
        ]
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "gitlab-instance-58545a48/Monitoring |OR| GitLab Instance/Monitoring"
    }
  },
  {
    "task_id": 40080,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/thoughtbot/administrate",
    "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/merge_requests",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell me the file name that was changed in at least two of the {{PRnumber}} most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "intent": "Tell me the file name that was changed in at least two of the 4 most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should check out each PR in the \"Merge requests\" page and look for the files that were changed by the PRs. It should output the file name that was modified multiple times.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/thoughtbot/administrate",
      "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/merge_requests",
      "PRnumber": "4",
      "answer": "N/A",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "N/A"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "N/A"
    }
  },
  {
    "task_id": 40081,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/igraph/igraph",
    "start_url_lite": "__GITLAB__/igraph/igraph/-/merge_requests",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell me the file name that was changed in at least two of the {{PRnumber}} most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "intent": "Tell me the file name that was changed in at least two of the 5 most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should check out each PR in the \"Merge requests\" page and look for the files that were changed by the PRs. It should output the file name that was modified multiple times.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/igraph/igraph",
      "start_url_lite": "__GITLAB__/igraph/igraph/-/merge_requests",
      "PRnumber": "5",
      "answer": "interfaces/functions.def",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "interfaces/functions.def"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "interfaces/functions.def"
    }
  },
  {
    "task_id": 40082,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/geeeeeeeeek/electronic-wechat",
    "start_url_lite": "__GITLAB__/geeeeeeeeek/electronic-wechat/-/merge_requests",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell me the file name that was changed in at least two of the {{PRnumber}} most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "intent": "Tell me the file name that was changed in at least two of the 5 most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should check out each PR in the \"Merge requests\" page and look for the files that were changed by the PRs. It should output the file name that was modified multiple times.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/geeeeeeeeek/electronic-wechat",
      "start_url_lite": "__GITLAB__/geeeeeeeeek/electronic-wechat/-/merge_requests",
      "PRnumber": "5",
      "answer": "src/windows/controllers/app_tray.js",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "src/windows/controllers/app_tray.js"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "src/windows/controllers/app_tray.js"
    }
  },
  {
    "task_id": 40083,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/quickfixgo/quickfix",
    "start_url_lite": "__GITLAB__/quickfixgo/quickfix/-/merge_requests",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell me the file name that was changed in at least two of the {{PRnumber}} most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "intent": "Tell me the file name that was changed in at least two of the 4 most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should check out each PR in the \"Merge requests\" page and look for the files that were changed by the PRs. It should output the file name that was modified multiple times.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/quickfixgo/quickfix",
      "start_url_lite": "__GITLAB__/quickfixgo/quickfix/-/merge_requests",
      "PRnumber": "4",
      "answer": "cmd/generate-fix/internal/template_helpers.go",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "cmd/generate-fix/internal/template_helpers.go"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "cmd/generate-fix/internal/template_helpers.go"
    }
  },
  {
    "task_id": 40084,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__/http-party/node-http-proxy",
    "start_url_lite": "__GITLAB__/http-party/node-http-proxy/-/merge_requests",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Tell me the file name that was changed in at least two of the {{PRnumber}} most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "intent": "Tell me the file name that was changed in at least two of the 3 most recently updated all PRs in this respository. Return the path to the file and \"N/A\" if such file does not exist. If there are multiple applicable files, return all of them separated by commas.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should check out each PR in the \"Merge requests\" page and look for the files that were changed by the PRs. It should output the file name that was modified multiple times.",
    "instantiation_dict": {
      "start_url": "__GITLAB__/http-party/node-http-proxy",
      "start_url_lite": "__GITLAB__/http-party/node-http-proxy/-/merge_requests",
      "PRnumber": "3",
      "answer": "package-lock.json",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "package-lock.json"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "package-lock.json"
    }
  },
  {
    "task_id": 40090,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/twbs/bootstrap",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "{{question}} according to the readme? {{format}}.",
    "intent": "What is the URL to visit first if I want to look into my tweets without going to the twitter.com website according to the readme? Only return the url.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition. It should also extract the exact information from the readme of the repository found.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/twbs/bootstrap",
      "question": "What is the URL to visit first if I want to look into my tweets without going to the twitter.com website",
      "format": "Only return the url",
      "answer": "https://github.com/amwhalen/archive-my-tweets/archive/master.zip",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "https://github.com/amwhalen/archive-my-tweets/archive/master.zip"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "https://github.com/amwhalen/archive-my-tweets/archive/master.zip"
    }
  },
  {
    "task_id": 40091,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/abisubramanya27/CS6910_Assignment2",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "{{question}} according to the readme? {{format}}.",
    "intent": "What could be Abishek S's student number according to the readme? Only return the student number.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition. It should also extract the exact information from the readme of the repository found.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/abisubramanya27/CS6910_Assignment2",
      "question": "What could be Abishek S's student number",
      "format": "Only return the student number",
      "answer": "EE18B001",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "EE18B001"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "EE18B001"
    }
  },
  {
    "task_id": 40092,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/kkroening/ffmpeg-python",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "{{question}} according to the readme? {{format}}.",
    "intent": "What would be the command to execute if I get an import error from ffmpeg according to the readme? Only return the command and its arguments.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition. It should also extract the exact information from the readme of the repository found.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/kkroening/ffmpeg-python",
      "question": "What would be the command to execute if I get an import error from ffmpeg",
      "format": "Only return the command and its arguments",
      "answer": "pip install ffmpeg-python",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "pip install ffmpeg-python"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "pip install ffmpeg-python"
    }
  },
  {
    "task_id": 40093,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/crashtech/torque-postgresql",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "{{question}} according to the readme? {{format}}.",
    "intent": "What command should I add to the Gemfile to use crashtech/torque-postgresql for Rails version 6.1.7.1 according to the readme? .",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition. It should also extract the exact information from the readme of the repository found.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/crashtech/torque-postgresql",
      "question": "What command should I add to the Gemfile to use crashtech/torque-postgresql for Rails version 6.1.7.1",
      "format": "",
      "answer": "gem 'torque-postgresql', '~> 2.0.4'",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "gem 'torque-postgresql', '~> 2.0.4'"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "gem 'torque-postgresql', '~> 2.0.4'"
    }
  },
  {
    "task_id": 40094,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/keylase/nvidia-patch",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "{{question}} according to the readme? {{format}}.",
    "intent": "What is the command to execute first to use the NVENC and NvFBC patches for Nvidia drivers without a driver according to the readme? Only return the command and its arguments.",
    "required_obs": "any",
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the condition. It should also extract the exact information from the readme of the repository found.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/keylase/nvidia-patch",
      "question": "What is the command to execute first to use the NVENC and NvFBC patches for Nvidia drivers without a driver",
      "format": "Only return the command and its arguments",
      "answer": "mkdir /opt/nvidia && cd /opt/nvidia",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "mkdir /opt/nvidia && cd /opt/nvidia"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "mkdir /opt/nvidia && cd /opt/nvidia"
    }
  },
  {
    "task_id": 40100,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/opensourcediversity/opensourcediversity.org/-/branches",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List the name of the branches in {{repository}} that is more than {{count}} commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "intent": "List the name of the branches in opensourcediversity/opensourcediversity.org that is more than 10 commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should also check out every branch at the \"Branches\" page and look at the number of commits behind the default.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/opensourcediversity/opensourcediversity.org/-/branches",
      "repository": "opensourcediversity/opensourcediversity.org",
      "count": "10",
      "answer": "articles\nfaq\ngithub/fork/2201monesh/patch-1\ngithub/fork/Ahcatan/master\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/bunnydays/faq\ngithub/fork/emmairwin/master\ngithub/fork/joelwass/twitterCardPic\ngithub/fork/kulendu/master\ngithub/fork/mayuribotre15/main\ngithub/fork/shub-garg/master\ngithub/fork/siddhanth339/master\nmore-projects\npublications",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "articles\nfaq\ngithub/fork/2201monesh/patch-1\ngithub/fork/Ahcatan/master\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/bunnydays/faq\ngithub/fork/emmairwin/master\ngithub/fork/joelwass/twitterCardPic\ngithub/fork/kulendu/master\ngithub/fork/mayuribotre15/main\ngithub/fork/shub-garg/master\ngithub/fork/siddhanth339/master\nmore-projects\npublications"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "articles\nfaq\ngithub/fork/2201monesh/patch-1\ngithub/fork/Ahcatan/master\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/bunnydays/faq\ngithub/fork/emmairwin/master\ngithub/fork/joelwass/twitterCardPic\ngithub/fork/kulendu/master\ngithub/fork/mayuribotre15/main\ngithub/fork/shub-garg/master\ngithub/fork/siddhanth339/master\nmore-projects\npublications"
    }
  },
  {
    "task_id": 40101,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/branches",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List the name of the branches in {{repository}} that is more than {{count}} commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "intent": "List the name of the branches in my repository for removing board movement events from the GitHub Issue timeline that is more than 10 commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should also check out every branch at the \"Branches\" page and look at the number of commits behind the default.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/branches",
      "repository": "my repository for removing board movement events from the GitHub Issue timeline",
      "count": "10",
      "answer": "N/A",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "N/A"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "N/A"
    }
  },
  {
    "task_id": 40102,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/kahun/awesome-sysadmin/-/branches",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List the name of the branches in {{repository}} that is more than {{count}} commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "intent": "List the name of the branches in a list of awesome open source sysadmin resources that is more than 250 commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should also check out every branch at the \"Branches\" page and look at the number of commits behind the default.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/kahun/awesome-sysadmin/-/branches",
      "repository": "a list of awesome open source sysadmin resources",
      "count": "250",
      "answer": "gh-pages\ngithub/fork/dstergiou/added-ip-address-management\ngithub/fork/tsaavik/master",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "gh-pages\ngithub/fork/dstergiou/added-ip-address-management\ngithub/fork/tsaavik/master"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "gh-pages\ngithub/fork/dstergiou/added-ip-address-management\ngithub/fork/tsaavik/master"
    }
  },
  {
    "task_id": 40103,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/amwhalen/archive-my-tweets/-/branches",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List the name of the branches in {{repository}} that is more than {{count}} commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "intent": "List the name of the branches in the repository for an app that archives my tweets that is more than 10 commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should also check out every branch at the \"Branches\" page and look at the number of commits behind the default.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/amwhalen/archive-my-tweets/-/branches",
      "repository": "the repository for an app that archives my tweets",
      "count": "10",
      "answer": "php52",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "php52"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "php52"
    }
  },
  {
    "task_id": 40104,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/lahwaacz/arch-wiki-docs/-/branches",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List the name of the branches in {{repository}} that is more than {{count}} commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "intent": "List the name of the branches in the repository for a script to download pages from Arch Wiki that is more than 3 commits behind the default. Sort the branches by their names in alphabetical order, and output each branch in a separate line. Return 'N/A' if such branch does not exist.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should also check out every branch at the \"Branches\" page and look at the number of commits behind the default.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/lahwaacz/arch-wiki-docs/-/branches",
      "repository": "the repository for a script to download pages from Arch Wiki",
      "count": "3",
      "answer": "github/fork/PQYPLZXHGF/patch-1\ngithub/fork/kiasoc5/index.html",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "github/fork/PQYPLZXHGF/patch-1\ngithub/fork/kiasoc5/index.html"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "github/fork/PQYPLZXHGF/patch-1\ngithub/fork/kiasoc5/index.html"
    }
  },
  {
    "task_id": 40110,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator/-/tags",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List all tags in {{repository}} in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "intent": "List all tags in OpenAPI Generator in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Tags\" page and check the updated time. The time should be modified to be UTC.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator/-/tags",
      "repository": "OpenAPI Generator",
      "answer": "2.0.17:2014-08-26\nswagger-codegen_2.9.1-1.1:2012-04-13\nswagger-codegen_2.9.1-2.0.0:2012-10-11\nswagger-codegen_2.9.1-2.0.1:2012-12-05\nv2.0.13:2014-02-21\nv2.0.18:2015-02-09\nv2.1.0-M1:2015-02-17\nv2.1.0-M2:2015-04-08\nv2.1.1-M1:2015-02-18\nv2.1.2:2015-06-09\nv2.1.2-M1:2015-02-24\nv2.1.3:2015-08-24\nv2.1.4:2015-10-26\nv2.1.5:2016-01-06\nv2.1.6:2016-04-06\nv2.2.0:2016-07-17\nv2.2.1:2016-08-07\nv2.2.2:2017-03-01\nv2.2.3:2017-07-15\nv2.3.0:2017-12-22\nv2.3.1:2018-01-13\nv3.0.0:2018-06-01\nv3.0.0-rc0:2018-01-24\nv3.0.1:2018-06-11\nv3.0.2:2018-06-18\nv3.0.3:2018-06-27\nv3.1.0:2018-07-06\nv3.1.1:2018-07-18\nv3.1.2:2018-07-25\nv3.2.0:2018-08-06\nv3.2.1:2018-08-14\nv3.2.2:2018-08-22\nv3.2.3:2018-08-30\nv3.3.0:2018-10-01\nv3.3.1:2018-10-15\nv3.3.2:2018-10-31\nv3.3.3:2018-11-15\nv3.3.4:2018-11-30\nv4.0.0:2019-05-13\nv4.0.0-beta:2018-12-31\nv4.0.0-beta2:2019-01-31\nv4.0.0-beta3:2019-04-04\nv4.0.1:2019-05-31\nv4.0.2:2019-06-20\nv4.0.3:2019-07-09\nv4.1.0:2019-08-09\nv4.1.1:2019-08-26\nv4.1.2:2019-09-11\nv4.1.3:2019-10-04\nv4.2.0:2019-10-31\nv4.2.1:2019-11-15\nv4.2.2:2019-12-02\nv4.2.3:2020-01-31\nv4.3.0:2020-03-27\nv4.3.1:2020-05-06\nv5.0.0:2020-12-21\nv5.0.0-beta:2020-06-29\nv5.0.0-beta2:2020-09-04\nv5.0.0-beta3:2020-11-20\nv5.0.1:2021-02-06\nv5.1.0:2021-03-20\nv5.1.1:2021-05-07\nv5.2.0:2021-07-09\nv5.2.1:2021-08-16\nv5.3.0:2021-10-24\nv5.3.1:2021-12-21\nv5.4.0:2022-01-31\nv6.0.0:2022-05-26\nv6.0.0-beta:2022-04-04\nv6.0.1:2022-07-03\nv6.1.0:2022-09-11\nv6.2.0:2022-09-24\nv6.2.1:2022-11-01\nv6.3.0:2023-02-01\nv6.4.0:2023-02-19",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "2.0.17:2014-08-26\nswagger-codegen_2.9.1-1.1:2012-04-13\nswagger-codegen_2.9.1-2.0.0:2012-10-11\nswagger-codegen_2.9.1-2.0.1:2012-12-05\nv2.0.13:2014-02-21\nv2.0.18:2015-02-09\nv2.1.0-M1:2015-02-17\nv2.1.0-M2:2015-04-08\nv2.1.1-M1:2015-02-18\nv2.1.2:2015-06-09\nv2.1.2-M1:2015-02-24\nv2.1.3:2015-08-24\nv2.1.4:2015-10-26\nv2.1.5:2016-01-06\nv2.1.6:2016-04-06\nv2.2.0:2016-07-17\nv2.2.1:2016-08-07\nv2.2.2:2017-03-01\nv2.2.3:2017-07-15\nv2.3.0:2017-12-22\nv2.3.1:2018-01-13\nv3.0.0:2018-06-01\nv3.0.0-rc0:2018-01-24\nv3.0.1:2018-06-11\nv3.0.2:2018-06-18\nv3.0.3:2018-06-27\nv3.1.0:2018-07-06\nv3.1.1:2018-07-18\nv3.1.2:2018-07-25\nv3.2.0:2018-08-06\nv3.2.1:2018-08-14\nv3.2.2:2018-08-22\nv3.2.3:2018-08-30\nv3.3.0:2018-10-01\nv3.3.1:2018-10-15\nv3.3.2:2018-10-31\nv3.3.3:2018-11-15\nv3.3.4:2018-11-30\nv4.0.0:2019-05-13\nv4.0.0-beta:2018-12-31\nv4.0.0-beta2:2019-01-31\nv4.0.0-beta3:2019-04-04\nv4.0.1:2019-05-31\nv4.0.2:2019-06-20\nv4.0.3:2019-07-09\nv4.1.0:2019-08-09\nv4.1.1:2019-08-26\nv4.1.2:2019-09-11\nv4.1.3:2019-10-04\nv4.2.0:2019-10-31\nv4.2.1:2019-11-15\nv4.2.2:2019-12-02\nv4.2.3:2020-01-31\nv4.3.0:2020-03-27\nv4.3.1:2020-05-06\nv5.0.0:2020-12-21\nv5.0.0-beta:2020-06-29\nv5.0.0-beta2:2020-09-04\nv5.0.0-beta3:2020-11-20\nv5.0.1:2021-02-06\nv5.1.0:2021-03-20\nv5.1.1:2021-05-07\nv5.2.0:2021-07-09\nv5.2.1:2021-08-16\nv5.3.0:2021-10-24\nv5.3.1:2021-12-21\nv5.4.0:2022-01-31\nv6.0.0:2022-05-26\nv6.0.0-beta:2022-04-04\nv6.0.1:2022-07-03\nv6.1.0:2022-09-11\nv6.2.0:2022-09-24\nv6.2.1:2022-11-01\nv6.3.0:2023-02-01\nv6.4.0:2023-02-19"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "2.0.17:2014-08-26\nswagger-codegen_2.9.1-1.1:2012-04-13\nswagger-codegen_2.9.1-2.0.0:2012-10-11\nswagger-codegen_2.9.1-2.0.1:2012-12-05\nv2.0.13:2014-02-21\nv2.0.18:2015-02-09\nv2.1.0-M1:2015-02-17\nv2.1.0-M2:2015-04-08\nv2.1.1-M1:2015-02-18\nv2.1.2:2015-06-09\nv2.1.2-M1:2015-02-24\nv2.1.3:2015-08-24\nv2.1.4:2015-10-26\nv2.1.5:2016-01-06\nv2.1.6:2016-04-06\nv2.2.0:2016-07-17\nv2.2.1:2016-08-07\nv2.2.2:2017-03-01\nv2.2.3:2017-07-15\nv2.3.0:2017-12-22\nv2.3.1:2018-01-13\nv3.0.0:2018-06-01\nv3.0.0-rc0:2018-01-24\nv3.0.1:2018-06-11\nv3.0.2:2018-06-18\nv3.0.3:2018-06-27\nv3.1.0:2018-07-06\nv3.1.1:2018-07-18\nv3.1.2:2018-07-25\nv3.2.0:2018-08-06\nv3.2.1:2018-08-14\nv3.2.2:2018-08-22\nv3.2.3:2018-08-30\nv3.3.0:2018-10-01\nv3.3.1:2018-10-15\nv3.3.2:2018-10-31\nv3.3.3:2018-11-15\nv3.3.4:2018-11-30\nv4.0.0:2019-05-13\nv4.0.0-beta:2018-12-31\nv4.0.0-beta2:2019-01-31\nv4.0.0-beta3:2019-04-04\nv4.0.1:2019-05-31\nv4.0.2:2019-06-20\nv4.0.3:2019-07-09\nv4.1.0:2019-08-09\nv4.1.1:2019-08-26\nv4.1.2:2019-09-11\nv4.1.3:2019-10-04\nv4.2.0:2019-10-31\nv4.2.1:2019-11-15\nv4.2.2:2019-12-02\nv4.2.3:2020-01-31\nv4.3.0:2020-03-27\nv4.3.1:2020-05-06\nv5.0.0:2020-12-21\nv5.0.0-beta:2020-06-29\nv5.0.0-beta2:2020-09-04\nv5.0.0-beta3:2020-11-20\nv5.0.1:2021-02-06\nv5.1.0:2021-03-20\nv5.1.1:2021-05-07\nv5.2.0:2021-07-09\nv5.2.1:2021-08-16\nv5.3.0:2021-10-24\nv5.3.1:2021-12-21\nv5.4.0:2022-01-31\nv6.0.0:2022-05-26\nv6.0.0-beta:2022-04-04\nv6.0.1:2022-07-03\nv6.1.0:2022-09-11\nv6.2.0:2022-09-24\nv6.2.1:2022-11-01\nv6.3.0:2023-02-01\nv6.4.0:2023-02-19"
    }
  },
  {
    "task_id": 40111,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/bblanchon/ArduinoJson/-/tags",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List all tags in {{repository}} in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "intent": "List all tags in the C++ JSON library for Arduino in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Tags\" page and check the updated time. The time should be modified to be UTC.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/bblanchon/ArduinoJson/-/tags",
      "repository": "the C++ JSON library for Arduino",
      "answer": "v1.0:2014-01-23\nv1.1:2014-02-27\nv1.2:2014-03-03\nv2.0:2014-07-09\nv2.1:2014-07-15\nv3.0:2014-07-23\nv3.1:2014-08-03\nv3.2:2014-08-04\nv3.3:2014-09-01\nv3.4:2014-09-09\nv4.0:2014-11-29\nv4.0-beta-1:2014-11-11\nv4.1:2014-12-21\nv4.2:2015-02-07\nv4.3:2015-05-03\nv4.4:2015-05-09\nv4.5:2015-06-10\nv4.6:2015-08-01\nv4.6.1:2015-08-02\nv5.0-beta-1:2015-05-31\nv5.0-beta-2:2015-07-10\nv5.0-beta-3:2015-07-25\nv5.0-beta-4:2015-07-27\nv5.0-beta-5:2015-08-10\nv5.0.0:2015-08-20\nv5.0.1:2015-08-24\nv5.0.2:2015-09-01\nv5.0.3:2015-09-19\nv5.0.4:2015-09-29\nv5.0.5:2015-10-30\nv5.0.6:2015-11-09\nv5.0.7:2015-11-25\nv5.0.8:2016-01-31\nv5.1.0:2016-02-14\nv5.1.0-beta.1:2016-02-01\nv5.1.0-beta.2:2016-02-06\nv5.1.1:2016-02-23\nv5.10.0:2017-05-20\nv5.10.1:2017-06-12\nv5.11.0:2017-06-25\nv5.11.1:2017-07-14\nv5.11.2:2017-10-17\nv5.12.0:2017-12-11\nv5.13.0:2018-01-19\nv5.13.1:2018-02-19\nv5.13.2:2018-06-01\nv5.13.3:2018-10-06\nv5.13.4:2018-12-04\nv5.13.5:2019-03-01\nv5.2.0:2016-04-16\nv5.3.0:2016-04-30\nv5.4.0:2016-05-06\nv5.5.0:2016-05-22\nv5.5.1:2016-06-06\nv5.6.0:2016-06-22\nv5.6.1:2016-06-24\nv5.6.2:2016-06-30\nv5.6.3:2016-07-19\nv5.6.4:2016-07-20\nv5.6.5:2016-08-15\nv5.6.6:2016-08-29\nv5.6.7:2016-09-20\nv5.7.0:2016-11-06\nv5.7.1:2016-11-13\nv5.7.2:2016-11-23\nv5.7.3:2016-12-10\nv5.8.0:2017-01-03\nv5.8.1:2017-01-15\nv5.8.2:2017-01-22\nv5.8.3:2017-02-11\nv5.8.4:2017-03-26\nv5.9.0:2017-04-24\nv6.0.0-beta:2018-06-07\nv6.0.1-beta:2018-06-11\nv6.1.0-beta:2018-07-02\nv6.10.0:2019-03-22\nv6.10.1:2019-04-23\nv6.11.0:2019-05-26\nv6.11.1:2019-06-21\nv6.11.2:2019-07-08\nv6.11.3:2019-07-22\nv6.11.4:2019-08-12\nv6.11.5:2019-08-23\nv6.12.0:2019-09-05\nv6.13.0:2019-11-01\nv6.14.0:2020-01-16\nv6.14.1:2020-01-27\nv6.15.0:2020-03-22\nv6.15.1:2020-04-08\nv6.15.2:2020-05-15\nv6.16.0:2020-08-01\nv6.16.1:2020-08-04\nv6.17.0:2020-10-19\nv6.17.1:2020-11-07\nv6.17.2:2020-11-14\nv6.17.3:2021-02-15\nv6.18.0:2021-05-05\nv6.18.1:2021-07-03\nv6.18.2:2021-07-19\nv6.18.3:2021-07-27\nv6.18.4:2021-09-06\nv6.18.5:2021-09-28\nv6.19.0:2022-01-08\nv6.19.1:2022-01-14\nv6.19.2:2022-02-14\nv6.19.3:2022-03-08\nv6.19.4:2022-04-05\nv6.2.0-beta:2018-07-12\nv6.2.1-beta:2018-07-17\nv6.2.2-beta:2018-07-18\nv6.2.3-beta:2018-07-19\nv6.20.0:2022-12-26\nv6.20.1:2023-02-08\nv6.21.0:2023-03-14\nv6.3.0-beta:2018-08-31\nv6.4.0-beta:2018-09-11\nv6.5.0-beta:2018-10-13\nv6.6.0-beta:2018-11-13\nv6.7.0-beta:2018-12-07\nv6.8.0-beta:2019-01-30\nv6.9.0:2019-02-26\nv6.9.1:2019-03-01",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "v1.0:2014-01-23\nv1.1:2014-02-27\nv1.2:2014-03-03\nv2.0:2014-07-09\nv2.1:2014-07-15\nv3.0:2014-07-23\nv3.1:2014-08-03\nv3.2:2014-08-04\nv3.3:2014-09-01\nv3.4:2014-09-09\nv4.0:2014-11-29\nv4.0-beta-1:2014-11-11\nv4.1:2014-12-21\nv4.2:2015-02-07\nv4.3:2015-05-03\nv4.4:2015-05-09\nv4.5:2015-06-10\nv4.6:2015-08-01\nv4.6.1:2015-08-02\nv5.0-beta-1:2015-05-31\nv5.0-beta-2:2015-07-10\nv5.0-beta-3:2015-07-25\nv5.0-beta-4:2015-07-27\nv5.0-beta-5:2015-08-10\nv5.0.0:2015-08-20\nv5.0.1:2015-08-24\nv5.0.2:2015-09-01\nv5.0.3:2015-09-19\nv5.0.4:2015-09-29\nv5.0.5:2015-10-30\nv5.0.6:2015-11-09\nv5.0.7:2015-11-25\nv5.0.8:2016-01-31\nv5.1.0:2016-02-14\nv5.1.0-beta.1:2016-02-01\nv5.1.0-beta.2:2016-02-06\nv5.1.1:2016-02-23\nv5.10.0:2017-05-20\nv5.10.1:2017-06-12\nv5.11.0:2017-06-25\nv5.11.1:2017-07-14\nv5.11.2:2017-10-17\nv5.12.0:2017-12-11\nv5.13.0:2018-01-19\nv5.13.1:2018-02-19\nv5.13.2:2018-06-01\nv5.13.3:2018-10-06\nv5.13.4:2018-12-04\nv5.13.5:2019-03-01\nv5.2.0:2016-04-16\nv5.3.0:2016-04-30\nv5.4.0:2016-05-06\nv5.5.0:2016-05-22\nv5.5.1:2016-06-06\nv5.6.0:2016-06-22\nv5.6.1:2016-06-24\nv5.6.2:2016-06-30\nv5.6.3:2016-07-19\nv5.6.4:2016-07-20\nv5.6.5:2016-08-15\nv5.6.6:2016-08-29\nv5.6.7:2016-09-20\nv5.7.0:2016-11-06\nv5.7.1:2016-11-13\nv5.7.2:2016-11-23\nv5.7.3:2016-12-10\nv5.8.0:2017-01-03\nv5.8.1:2017-01-15\nv5.8.2:2017-01-22\nv5.8.3:2017-02-11\nv5.8.4:2017-03-26\nv5.9.0:2017-04-24\nv6.0.0-beta:2018-06-07\nv6.0.1-beta:2018-06-11\nv6.1.0-beta:2018-07-02\nv6.10.0:2019-03-22\nv6.10.1:2019-04-23\nv6.11.0:2019-05-26\nv6.11.1:2019-06-21\nv6.11.2:2019-07-08\nv6.11.3:2019-07-22\nv6.11.4:2019-08-12\nv6.11.5:2019-08-23\nv6.12.0:2019-09-05\nv6.13.0:2019-11-01\nv6.14.0:2020-01-16\nv6.14.1:2020-01-27\nv6.15.0:2020-03-22\nv6.15.1:2020-04-08\nv6.15.2:2020-05-15\nv6.16.0:2020-08-01\nv6.16.1:2020-08-04\nv6.17.0:2020-10-19\nv6.17.1:2020-11-07\nv6.17.2:2020-11-14\nv6.17.3:2021-02-15\nv6.18.0:2021-05-05\nv6.18.1:2021-07-03\nv6.18.2:2021-07-19\nv6.18.3:2021-07-27\nv6.18.4:2021-09-06\nv6.18.5:2021-09-28\nv6.19.0:2022-01-08\nv6.19.1:2022-01-14\nv6.19.2:2022-02-14\nv6.19.3:2022-03-08\nv6.19.4:2022-04-05\nv6.2.0-beta:2018-07-12\nv6.2.1-beta:2018-07-17\nv6.2.2-beta:2018-07-18\nv6.2.3-beta:2018-07-19\nv6.20.0:2022-12-26\nv6.20.1:2023-02-08\nv6.21.0:2023-03-14\nv6.3.0-beta:2018-08-31\nv6.4.0-beta:2018-09-11\nv6.5.0-beta:2018-10-13\nv6.6.0-beta:2018-11-13\nv6.7.0-beta:2018-12-07\nv6.8.0-beta:2019-01-30\nv6.9.0:2019-02-26\nv6.9.1:2019-03-01"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "v1.0:2014-01-23\nv1.1:2014-02-27\nv1.2:2014-03-03\nv2.0:2014-07-09\nv2.1:2014-07-15\nv3.0:2014-07-23\nv3.1:2014-08-03\nv3.2:2014-08-04\nv3.3:2014-09-01\nv3.4:2014-09-09\nv4.0:2014-11-29\nv4.0-beta-1:2014-11-11\nv4.1:2014-12-21\nv4.2:2015-02-07\nv4.3:2015-05-03\nv4.4:2015-05-09\nv4.5:2015-06-10\nv4.6:2015-08-01\nv4.6.1:2015-08-02\nv5.0-beta-1:2015-05-31\nv5.0-beta-2:2015-07-10\nv5.0-beta-3:2015-07-25\nv5.0-beta-4:2015-07-27\nv5.0-beta-5:2015-08-10\nv5.0.0:2015-08-20\nv5.0.1:2015-08-24\nv5.0.2:2015-09-01\nv5.0.3:2015-09-19\nv5.0.4:2015-09-29\nv5.0.5:2015-10-30\nv5.0.6:2015-11-09\nv5.0.7:2015-11-25\nv5.0.8:2016-01-31\nv5.1.0:2016-02-14\nv5.1.0-beta.1:2016-02-01\nv5.1.0-beta.2:2016-02-06\nv5.1.1:2016-02-23\nv5.10.0:2017-05-20\nv5.10.1:2017-06-12\nv5.11.0:2017-06-25\nv5.11.1:2017-07-14\nv5.11.2:2017-10-17\nv5.12.0:2017-12-11\nv5.13.0:2018-01-19\nv5.13.1:2018-02-19\nv5.13.2:2018-06-01\nv5.13.3:2018-10-06\nv5.13.4:2018-12-04\nv5.13.5:2019-03-01\nv5.2.0:2016-04-16\nv5.3.0:2016-04-30\nv5.4.0:2016-05-06\nv5.5.0:2016-05-22\nv5.5.1:2016-06-06\nv5.6.0:2016-06-22\nv5.6.1:2016-06-24\nv5.6.2:2016-06-30\nv5.6.3:2016-07-19\nv5.6.4:2016-07-20\nv5.6.5:2016-08-15\nv5.6.6:2016-08-29\nv5.6.7:2016-09-20\nv5.7.0:2016-11-06\nv5.7.1:2016-11-13\nv5.7.2:2016-11-23\nv5.7.3:2016-12-10\nv5.8.0:2017-01-03\nv5.8.1:2017-01-15\nv5.8.2:2017-01-22\nv5.8.3:2017-02-11\nv5.8.4:2017-03-26\nv5.9.0:2017-04-24\nv6.0.0-beta:2018-06-07\nv6.0.1-beta:2018-06-11\nv6.1.0-beta:2018-07-02\nv6.10.0:2019-03-22\nv6.10.1:2019-04-23\nv6.11.0:2019-05-26\nv6.11.1:2019-06-21\nv6.11.2:2019-07-08\nv6.11.3:2019-07-22\nv6.11.4:2019-08-12\nv6.11.5:2019-08-23\nv6.12.0:2019-09-05\nv6.13.0:2019-11-01\nv6.14.0:2020-01-16\nv6.14.1:2020-01-27\nv6.15.0:2020-03-22\nv6.15.1:2020-04-08\nv6.15.2:2020-05-15\nv6.16.0:2020-08-01\nv6.16.1:2020-08-04\nv6.17.0:2020-10-19\nv6.17.1:2020-11-07\nv6.17.2:2020-11-14\nv6.17.3:2021-02-15\nv6.18.0:2021-05-05\nv6.18.1:2021-07-03\nv6.18.2:2021-07-19\nv6.18.3:2021-07-27\nv6.18.4:2021-09-06\nv6.18.5:2021-09-28\nv6.19.0:2022-01-08\nv6.19.1:2022-01-14\nv6.19.2:2022-02-14\nv6.19.3:2022-03-08\nv6.19.4:2022-04-05\nv6.2.0-beta:2018-07-12\nv6.2.1-beta:2018-07-17\nv6.2.2-beta:2018-07-18\nv6.2.3-beta:2018-07-19\nv6.20.0:2022-12-26\nv6.20.1:2023-02-08\nv6.21.0:2023-03-14\nv6.3.0-beta:2018-08-31\nv6.4.0-beta:2018-09-11\nv6.5.0-beta:2018-10-13\nv6.6.0-beta:2018-11-13\nv6.7.0-beta:2018-12-07\nv6.8.0-beta:2019-01-30\nv6.9.0:2019-02-26\nv6.9.1:2019-03-01"
    }
  },
  {
    "task_id": 40112,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/wting/autojump/-/tags",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List all tags in {{repository}} in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "intent": "List all tags in autojump in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Tags\" page and check the updated time. The time should be modified to be UTC.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/wting/autojump/-/tags",
      "repository": "autojump",
      "answer": "release-v1:2009-03-02\nrelease-v10:2010-06-22\nrelease-v11:2010-07-07\nrelease-v12:2010-08-25\nrelease-v13:2010-10-01\nrelease-v14:2010-12-03\nrelease-v15:2011-03-30\nrelease-v16:2011-07-28\nrelease-v17:2011-09-08\nrelease-v18:2011-11-18\nrelease-v19:2011-12-11\nrelease-v2:2009-04-17\nrelease-v20:2012-04-12\nrelease-v20.5:2012-06-16\nrelease-v20.6:2012-06-16\nrelease-v20.7:2012-06-16\nrelease-v20.8:2012-06-16\nrelease-v20.9:2012-06-16\nrelease-v21.0.2:2012-10-31\nrelease-v21.0.3:2012-11-01\nrelease-v21.0.5:2012-11-21\nrelease-v21.1.0:2012-11-22\nrelease-v21.1.2:2012-11-24\nrelease-v21.1.4:2012-12-15\nrelease-v21.2.0:2012-12-15\nrelease-v21.2.1:2012-12-17\nrelease-v21.3.0:2013-01-05\nrelease-v21.4.2:2013-02-01\nrelease-v21.5.1:2013-02-25\nrelease-v21.5.8:2013-04-29\nrelease-v21.6.8:2013-05-25\nrelease-v21.6.9:2013-05-29\nrelease-v21.7.1:2013-11-26\nrelease-v22.2.2:2014-12-16\nrelease-v22.2.4:2015-01-25\nrelease-v22.3.0:2016-02-02\nrelease-v22.3.1:2016-06-19\nrelease-v22.3.2:2016-06-22\nrelease-v22.3.3:2016-07-14\nrelease-v22.3.4:2016-07-14\nrelease-v22.3.5:2016-09-09\nrelease-v22.4.0:2016-09-30\nrelease-v22.4.1:2016-09-30\nrelease-v22.5.0:2016-10-01\nrelease-v22.5.1:2017-02-17\nrelease-v22.5.3:2018-09-09\nrelease-v3:2009-05-13\nrelease-v4:2009-05-14\nrelease-v5:2009-05-30\nrelease-v6:2009-09-16\nrelease-v7:2009-10-03\nrelease-v8:2010-01-26\nrelease-v9:2010-04-27",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "release-v1:2009-03-02\nrelease-v10:2010-06-22\nrelease-v11:2010-07-07\nrelease-v12:2010-08-25\nrelease-v13:2010-10-01\nrelease-v14:2010-12-03\nrelease-v15:2011-03-30\nrelease-v16:2011-07-28\nrelease-v17:2011-09-08\nrelease-v18:2011-11-18\nrelease-v19:2011-12-11\nrelease-v2:2009-04-17\nrelease-v20:2012-04-12\nrelease-v20.5:2012-06-16\nrelease-v20.6:2012-06-16\nrelease-v20.7:2012-06-16\nrelease-v20.8:2012-06-16\nrelease-v20.9:2012-06-16\nrelease-v21.0.2:2012-10-31\nrelease-v21.0.3:2012-11-01\nrelease-v21.0.5:2012-11-21\nrelease-v21.1.0:2012-11-22\nrelease-v21.1.2:2012-11-24\nrelease-v21.1.4:2012-12-15\nrelease-v21.2.0:2012-12-15\nrelease-v21.2.1:2012-12-17\nrelease-v21.3.0:2013-01-05\nrelease-v21.4.2:2013-02-01\nrelease-v21.5.1:2013-02-25\nrelease-v21.5.8:2013-04-29\nrelease-v21.6.8:2013-05-25\nrelease-v21.6.9:2013-05-29\nrelease-v21.7.1:2013-11-26\nrelease-v22.2.2:2014-12-16\nrelease-v22.2.4:2015-01-25\nrelease-v22.3.0:2016-02-02\nrelease-v22.3.1:2016-06-19\nrelease-v22.3.2:2016-06-22\nrelease-v22.3.3:2016-07-14\nrelease-v22.3.4:2016-07-14\nrelease-v22.3.5:2016-09-09\nrelease-v22.4.0:2016-09-30\nrelease-v22.4.1:2016-09-30\nrelease-v22.5.0:2016-10-01\nrelease-v22.5.1:2017-02-17\nrelease-v22.5.3:2018-09-09\nrelease-v3:2009-05-13\nrelease-v4:2009-05-14\nrelease-v5:2009-05-30\nrelease-v6:2009-09-16\nrelease-v7:2009-10-03\nrelease-v8:2010-01-26\nrelease-v9:2010-04-27"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "release-v1:2009-03-02\nrelease-v10:2010-06-22\nrelease-v11:2010-07-07\nrelease-v12:2010-08-25\nrelease-v13:2010-10-01\nrelease-v14:2010-12-03\nrelease-v15:2011-03-30\nrelease-v16:2011-07-28\nrelease-v17:2011-09-08\nrelease-v18:2011-11-18\nrelease-v19:2011-12-11\nrelease-v2:2009-04-17\nrelease-v20:2012-04-12\nrelease-v20.5:2012-06-16\nrelease-v20.6:2012-06-16\nrelease-v20.7:2012-06-16\nrelease-v20.8:2012-06-16\nrelease-v20.9:2012-06-16\nrelease-v21.0.2:2012-10-31\nrelease-v21.0.3:2012-11-01\nrelease-v21.0.5:2012-11-21\nrelease-v21.1.0:2012-11-22\nrelease-v21.1.2:2012-11-24\nrelease-v21.1.4:2012-12-15\nrelease-v21.2.0:2012-12-15\nrelease-v21.2.1:2012-12-17\nrelease-v21.3.0:2013-01-05\nrelease-v21.4.2:2013-02-01\nrelease-v21.5.1:2013-02-25\nrelease-v21.5.8:2013-04-29\nrelease-v21.6.8:2013-05-25\nrelease-v21.6.9:2013-05-29\nrelease-v21.7.1:2013-11-26\nrelease-v22.2.2:2014-12-16\nrelease-v22.2.4:2015-01-25\nrelease-v22.3.0:2016-02-02\nrelease-v22.3.1:2016-06-19\nrelease-v22.3.2:2016-06-22\nrelease-v22.3.3:2016-07-14\nrelease-v22.3.4:2016-07-14\nrelease-v22.3.5:2016-09-09\nrelease-v22.4.0:2016-09-30\nrelease-v22.4.1:2016-09-30\nrelease-v22.5.0:2016-10-01\nrelease-v22.5.1:2017-02-17\nrelease-v22.5.3:2018-09-09\nrelease-v3:2009-05-13\nrelease-v4:2009-05-14\nrelease-v5:2009-05-30\nrelease-v6:2009-09-16\nrelease-v7:2009-10-03\nrelease-v8:2010-01-26\nrelease-v9:2010-04-27"
    }
  },
  {
    "task_id": 40113,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/timeit/-/tags",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List all tags in {{repository}} in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "intent": "List all tags in my timeit project in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Tags\" page and check the updated time. The time should be modified to be UTC.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/timeit/-/tags",
      "repository": "my timeit project",
      "answer": "N/A",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "N/A"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "N/A"
    }
  },
  {
    "task_id": 40114,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/auth0/angular-storage/-/tags",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "List all tags in {{repository}} in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "intent": "List all tags in the angular-storage project by auth0 in the alphabetical order and show the date of the latest commit that each tag points to in UTC. Return 'N/A' if no tag exists. Output in the following format, each in a separate line-> (tag name):(yyyy-mm-dd)",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Tags\" page and check the updated time. The time should be modified to be UTC.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/auth0/angular-storage/-/tags",
      "repository": "the angular-storage project by auth0",
      "answer": "0.0.1:2014-10-02\n0.0.10:2015-04-17\n0.0.11:2015-05-18\n0.0.12:2015-07-22\n0.0.13:2015-07-23\n0.0.14:2016-03-25\n0.0.15:2016-04-03\n0.0.3:2014-10-07\n0.0.4:2014-10-07\n0.0.5:2014-10-08\n0.0.6:2014-10-08\nv0.0.7:2014-11-20\nv0.0.8:2014-12-10\nv0.0.9:2014-12-10",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "0.0.1:2014-10-02\n0.0.10:2015-04-17\n0.0.11:2015-05-18\n0.0.12:2015-07-22\n0.0.13:2015-07-23\n0.0.14:2016-03-25\n0.0.15:2016-04-03\n0.0.3:2014-10-07\n0.0.4:2014-10-07\n0.0.5:2014-10-08\n0.0.6:2014-10-08\nv0.0.7:2014-11-20\nv0.0.8:2014-12-10\nv0.0.9:2014-12-10"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "0.0.1:2014-10-02\n0.0.10:2015-04-17\n0.0.11:2015-05-18\n0.0.12:2015-07-22\n0.0.13:2015-07-23\n0.0.14:2016-03-25\n0.0.15:2016-04-03\n0.0.3:2014-10-07\n0.0.4:2014-10-07\n0.0.5:2014-10-08\n0.0.6:2014-10-08\nv0.0.7:2014-11-20\nv0.0.8:2014-12-10\nv0.0.9:2014-12-10"
    }
  },
  {
    "task_id": 40120,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/opensourcediversity/opensourcediversity.org/-/branches/all",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Show the list of branches in {{repository}} in descending order of the latest commit date. Output each branch name in a separate line.",
    "intent": "Show the list of branches in opensourcediversity.org repository in descending order of the latest commit date. Output each branch name in a separate line.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Branches\" page and check the updated time.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/opensourcediversity/opensourcediversity.org/-/branches/all",
      "repository": "opensourcediversity.org repository",
      "answer": "github/fork/PhuocOng/peterbranch\ngithub/fork/uixaadi/my_first_contribution\nmain\ngithub/fork/2201monesh/patch-1\njg-ahcatan-add-projects\ngithub/fork/Richie1136/richie1136\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/mayuribotre15/main\ngithub/fork/siddhanth339/master\ngithub/fork/emmairwin/master\ngithub/fork/Ahcatan/master\ngithub/fork/kulendu/master\ngithub/fork/shub-garg/master\ngithub/fork/joelwass/twitterCardPic\npublications\nmore-projects\nfaq\ngithub/fork/bunnydays/faq\narticles",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "github/fork/PhuocOng/peterbranch\ngithub/fork/uixaadi/my_first_contribution\nmain\ngithub/fork/2201monesh/patch-1\njg-ahcatan-add-projects\ngithub/fork/Richie1136/richie1136\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/mayuribotre15/main\ngithub/fork/siddhanth339/master\ngithub/fork/emmairwin/master\ngithub/fork/Ahcatan/master\ngithub/fork/kulendu/master\ngithub/fork/shub-garg/master\ngithub/fork/joelwass/twitterCardPic\npublications\nmore-projects\nfaq\ngithub/fork/bunnydays/faq\narticles"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "github/fork/PhuocOng/peterbranch\ngithub/fork/uixaadi/my_first_contribution\nmain\ngithub/fork/2201monesh/patch-1\njg-ahcatan-add-projects\ngithub/fork/Richie1136/richie1136\ngithub/fork/SANJAY072000/failing-html-checks-#123\ngithub/fork/mayuribotre15/main\ngithub/fork/siddhanth339/master\ngithub/fork/emmairwin/master\ngithub/fork/Ahcatan/master\ngithub/fork/kulendu/master\ngithub/fork/shub-garg/master\ngithub/fork/joelwass/twitterCardPic\npublications\nmore-projects\nfaq\ngithub/fork/bunnydays/faq\narticles"
    }
  },
  {
    "task_id": 40121,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/wting/autojump/-/branches/all",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Show the list of branches in {{repository}} in descending order of the latest commit date. Output each branch name in a separate line.",
    "intent": "Show the list of branches in wting/autojump in descending order of the latest commit date. Output each branch name in a separate line.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Branches\" page and check the updated time.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/wting/autojump/-/branches/all",
      "repository": "wting/autojump",
      "answer": "github/fork/writeameer/master\ngithub/fork/Komi7/fix-git-clone-url\ngithub/fork/abubakrsiddq/repo-path-fix\ngithub/fork/geo7/patch-1\ngithub/fork/hustnzj/master\ngithub/fork/kianmeng/fix-typos\ngithub/fork/alanhoyle/master\ngithub/fork/opelr/557/support-for-initials\ngithub/fork/rico-chet/fix-duplicate-matches-with-legacy-py\nwting_default_python3\ngithub/fork/mattst88/mock\ngithub/fork/JS-Zheng/master\ngithub/fork/joebb97/master\ngithub/fork/DeepMechatronics/patch-1\ngithub/fork/faiz-crypto/patch-1\ngithub/fork/GlazerMann/patch-3\ngithub/fork/GlazerMann/patch-2\ngithub/fork/GlazerMann/patch-1\ngithub/fork/timgates42/bugfix_typo_requires\ngithub/fork/lxp521125/master\ngithub/fork/asellappen/master\ngithub/fork/mesmerx/master\ngithub/fork/maludwig/master\ngithub/fork/mbologna/patch-1\ngithub/fork/azriel91/feature/issue-356-support-git-bash-msysgit\ngithub/fork/ashwinvis/master\ngithub/fork/abravalheri/make-sh-file-posix\ngithub/fork/Tarik02/wsl-explorer\ngithub/fork/dalanicolai/patch-2\ngithub/fork/dalanicolai/patch-1\ngithub/fork/MrKriss/refactor-windows-tests\ngithub/fork/MrKriss/add-windows-ci-with-appveyor\ngithub/fork/MrKriss/master\ngithub/fork/floydpink/fix-for-windows\ngithub/fork/L-P/fix/child\ngithub/fork/wang-ye/patch-1\nmaster\ngithub/fork/eklitzke/master\ngithub/fork/orschiro/patch-1\ngithub/fork/LinuxMercedes/master\ngithub/fork/findstr/master\ngithub/fork/n4nagappan/master\ngithub/fork/pistole/tcsh\ngithub/fork/mqudsi/fish_no_dot\ngithub/fork/Vaelatern/VoidLinuxMention\ngithub/fork/kynan/patch-1\ngithub/fork/emanresusername/master\ngithub/fork/duganchen/master\ngithub/fork/cpmsmith/master\ngithub/fork/jared-hess/multi-dir-add\ngithub/fork/vkotovv/doc_fixes\ngithub/fork/ashwin/master\ngithub/fork/leni536/master\ngithub/fork/leonid-shevtsov/master\ngithub/fork/youtux/patch-1\ngithub/fork/grota/autocomplete_jc_jco",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "github/fork/writeameer/master\ngithub/fork/Komi7/fix-git-clone-url\ngithub/fork/abubakrsiddq/repo-path-fix\ngithub/fork/geo7/patch-1\ngithub/fork/hustnzj/master\ngithub/fork/kianmeng/fix-typos\ngithub/fork/alanhoyle/master\ngithub/fork/opelr/557/support-for-initials\ngithub/fork/rico-chet/fix-duplicate-matches-with-legacy-py\nwting_default_python3\ngithub/fork/mattst88/mock\ngithub/fork/JS-Zheng/master\ngithub/fork/joebb97/master\ngithub/fork/DeepMechatronics/patch-1\ngithub/fork/faiz-crypto/patch-1\ngithub/fork/GlazerMann/patch-3\ngithub/fork/GlazerMann/patch-2\ngithub/fork/GlazerMann/patch-1\ngithub/fork/timgates42/bugfix_typo_requires\ngithub/fork/lxp521125/master\ngithub/fork/asellappen/master\ngithub/fork/mesmerx/master\ngithub/fork/maludwig/master\ngithub/fork/mbologna/patch-1\ngithub/fork/azriel91/feature/issue-356-support-git-bash-msysgit\ngithub/fork/ashwinvis/master\ngithub/fork/abravalheri/make-sh-file-posix\ngithub/fork/Tarik02/wsl-explorer\ngithub/fork/dalanicolai/patch-2\ngithub/fork/dalanicolai/patch-1\ngithub/fork/MrKriss/refactor-windows-tests\ngithub/fork/MrKriss/add-windows-ci-with-appveyor\ngithub/fork/MrKriss/master\ngithub/fork/floydpink/fix-for-windows\ngithub/fork/L-P/fix/child\ngithub/fork/wang-ye/patch-1\nmaster\ngithub/fork/eklitzke/master\ngithub/fork/orschiro/patch-1\ngithub/fork/LinuxMercedes/master\ngithub/fork/findstr/master\ngithub/fork/n4nagappan/master\ngithub/fork/pistole/tcsh\ngithub/fork/mqudsi/fish_no_dot\ngithub/fork/Vaelatern/VoidLinuxMention\ngithub/fork/kynan/patch-1\ngithub/fork/emanresusername/master\ngithub/fork/duganchen/master\ngithub/fork/cpmsmith/master\ngithub/fork/jared-hess/multi-dir-add\ngithub/fork/vkotovv/doc_fixes\ngithub/fork/ashwin/master\ngithub/fork/leni536/master\ngithub/fork/leonid-shevtsov/master\ngithub/fork/youtux/patch-1\ngithub/fork/grota/autocomplete_jc_jco"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "github/fork/writeameer/master\ngithub/fork/Komi7/fix-git-clone-url\ngithub/fork/abubakrsiddq/repo-path-fix\ngithub/fork/geo7/patch-1\ngithub/fork/hustnzj/master\ngithub/fork/kianmeng/fix-typos\ngithub/fork/alanhoyle/master\ngithub/fork/opelr/557/support-for-initials\ngithub/fork/rico-chet/fix-duplicate-matches-with-legacy-py\nwting_default_python3\ngithub/fork/mattst88/mock\ngithub/fork/JS-Zheng/master\ngithub/fork/joebb97/master\ngithub/fork/DeepMechatronics/patch-1\ngithub/fork/faiz-crypto/patch-1\ngithub/fork/GlazerMann/patch-3\ngithub/fork/GlazerMann/patch-2\ngithub/fork/GlazerMann/patch-1\ngithub/fork/timgates42/bugfix_typo_requires\ngithub/fork/lxp521125/master\ngithub/fork/asellappen/master\ngithub/fork/mesmerx/master\ngithub/fork/maludwig/master\ngithub/fork/mbologna/patch-1\ngithub/fork/azriel91/feature/issue-356-support-git-bash-msysgit\ngithub/fork/ashwinvis/master\ngithub/fork/abravalheri/make-sh-file-posix\ngithub/fork/Tarik02/wsl-explorer\ngithub/fork/dalanicolai/patch-2\ngithub/fork/dalanicolai/patch-1\ngithub/fork/MrKriss/refactor-windows-tests\ngithub/fork/MrKriss/add-windows-ci-with-appveyor\ngithub/fork/MrKriss/master\ngithub/fork/floydpink/fix-for-windows\ngithub/fork/L-P/fix/child\ngithub/fork/wang-ye/patch-1\nmaster\ngithub/fork/eklitzke/master\ngithub/fork/orschiro/patch-1\ngithub/fork/LinuxMercedes/master\ngithub/fork/findstr/master\ngithub/fork/n4nagappan/master\ngithub/fork/pistole/tcsh\ngithub/fork/mqudsi/fish_no_dot\ngithub/fork/Vaelatern/VoidLinuxMention\ngithub/fork/kynan/patch-1\ngithub/fork/emanresusername/master\ngithub/fork/duganchen/master\ngithub/fork/cpmsmith/master\ngithub/fork/jared-hess/multi-dir-add\ngithub/fork/vkotovv/doc_fixes\ngithub/fork/ashwin/master\ngithub/fork/leni536/master\ngithub/fork/leonid-shevtsov/master\ngithub/fork/youtux/patch-1\ngithub/fork/grota/autocomplete_jc_jco"
    }
  },
  {
    "task_id": 40122,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt/-/branches/all",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Show the list of branches in {{repository}} in descending order of the latest commit date. Output each branch name in a separate line.",
    "intent": "Show the list of branches in my cloud-to-butt project in descending order of the latest commit date. Output each branch name in a separate line.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Branches\" page and check the updated time.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt/-/branches/all",
      "repository": "my cloud-to-butt project",
      "answer": "master\ngithub/fork/RF-Nelson/patch-1\ngithub/fork/jandahl/master\ngithub/fork/mwhite/master",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "master\ngithub/fork/RF-Nelson/patch-1\ngithub/fork/jandahl/master\ngithub/fork/mwhite/master"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "master\ngithub/fork/RF-Nelson/patch-1\ngithub/fork/jandahl/master\ngithub/fork/mwhite/master"
    }
  },
  {
    "task_id": 40123,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/test123/boo/-/branches/all",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Show the list of branches in {{repository}} in descending order of the latest commit date. Output each branch name in a separate line.",
    "intent": "Show the list of branches in boo project by test123 in descending order of the latest commit date. Output each branch name in a separate line.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Branches\" page and check the updated time.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/test123/boo/-/branches/all",
      "repository": "boo project by test123",
      "answer": "main",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "main"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "main"
    }
  },
  {
    "task_id": 40124,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/facebook/buck/-/branches/all",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Show the list of branches in {{repository}} in descending order of the latest commit date. Output each branch name in a separate line.",
    "intent": "Show the list of branches in the buck project in descending order of the latest commit date. Output each branch name in a separate line.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Branches\" page and check the updated time.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/facebook/buck/-/branches/all",
      "repository": "the buck project",
      "answer": "nc/test-circle-ci\nnc/fix-m1\ndev\nmain\ngithub/fork/EdTice/patch-2\ngithub/fork/marcesengel/fix/m1\ngithub/fork/Solace-Studios/patch-M1_aarch64_Support\ngithub/fork/nmcardoso/update-copyright\ngithub/fork/egpast/dev\ngithub/fork/mdzyuba/tools_import_deps\nsource-db\ngithub/fork/adolfojunior/export-D35240414-to-dev\ngithub/fork/patosai/main\ngh-pages\ngithub/fork/mikekap/patch-5\ncircleci-editor/969/main\ngithub/fork/cortinico/patch-1\ngithub/fork/yifuwang/export-D31106794-to-dev\ngithub/fork/lujiefsi/MovePythonWhlDataStep\ngithub/fork/yifuwang/export-D30802446-to-dev\ngithub/fork/R1kk3r/support_ndk_22\ngithub/fork/Lcsmarcal/feature/xcframework\ngithub/fork/alekseevpg/change-default-umbrella-header\ngithub/fork/yanks/jforbes-xcodeproj-2\ngithub/fork/yanks/jforbes-xcodeproj-3\ngithub/fork/yanks/jforbes-xcodeproj-1\ngithub/fork/yanks/jforbes-skip-appex-copy\ngithub/fork/yanks/jforbes-resources-from-deps\ngithub/fork/SiddhantRanade/patch-1\nbrianduff-patch-1\nclairehjk-patch-1\noss_fix_non_predexed_builds",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "nc/test-circle-ci\nnc/fix-m1\ndev\nmain\ngithub/fork/EdTice/patch-2\ngithub/fork/marcesengel/fix/m1\ngithub/fork/Solace-Studios/patch-M1_aarch64_Support\ngithub/fork/nmcardoso/update-copyright\ngithub/fork/egpast/dev\ngithub/fork/mdzyuba/tools_import_deps\nsource-db\ngithub/fork/adolfojunior/export-D35240414-to-dev\ngithub/fork/patosai/main\ngh-pages\ngithub/fork/mikekap/patch-5\ncircleci-editor/969/main\ngithub/fork/cortinico/patch-1\ngithub/fork/yifuwang/export-D31106794-to-dev\ngithub/fork/lujiefsi/MovePythonWhlDataStep\ngithub/fork/yifuwang/export-D30802446-to-dev\ngithub/fork/R1kk3r/support_ndk_22\ngithub/fork/Lcsmarcal/feature/xcframework\ngithub/fork/alekseevpg/change-default-umbrella-header\ngithub/fork/yanks/jforbes-xcodeproj-2\ngithub/fork/yanks/jforbes-xcodeproj-3\ngithub/fork/yanks/jforbes-xcodeproj-1\ngithub/fork/yanks/jforbes-skip-appex-copy\ngithub/fork/yanks/jforbes-resources-from-deps\ngithub/fork/SiddhantRanade/patch-1\nbrianduff-patch-1\nclairehjk-patch-1\noss_fix_non_predexed_builds"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "nc/test-circle-ci\nnc/fix-m1\ndev\nmain\ngithub/fork/EdTice/patch-2\ngithub/fork/marcesengel/fix/m1\ngithub/fork/Solace-Studios/patch-M1_aarch64_Support\ngithub/fork/nmcardoso/update-copyright\ngithub/fork/egpast/dev\ngithub/fork/mdzyuba/tools_import_deps\nsource-db\ngithub/fork/adolfojunior/export-D35240414-to-dev\ngithub/fork/patosai/main\ngh-pages\ngithub/fork/mikekap/patch-5\ncircleci-editor/969/main\ngithub/fork/cortinico/patch-1\ngithub/fork/yifuwang/export-D31106794-to-dev\ngithub/fork/lujiefsi/MovePythonWhlDataStep\ngithub/fork/yifuwang/export-D30802446-to-dev\ngithub/fork/R1kk3r/support_ndk_22\ngithub/fork/Lcsmarcal/feature/xcframework\ngithub/fork/alekseevpg/change-default-umbrella-header\ngithub/fork/yanks/jforbes-xcodeproj-2\ngithub/fork/yanks/jforbes-xcodeproj-3\ngithub/fork/yanks/jforbes-xcodeproj-1\ngithub/fork/yanks/jforbes-skip-appex-copy\ngithub/fork/yanks/jforbes-resources-from-deps\ngithub/fork/SiddhantRanade/patch-1\nbrianduff-patch-1\nclairehjk-patch-1\noss_fix_non_predexed_builds"
    }
  },
  {
    "task_id": 40130,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/facebook/create-react-app/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Calculate the ratio of the number of commits in {{repository}} that contain {{keyword}} in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "intent": "Calculate the ratio of the number of commits in the Create React App repository that contain react in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the commit messages for all commits.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/facebook/create-react-app/-/commits/main",
      "repository": "the Create React App repository",
      "keyword": "react",
      "answer": "13.4%",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "13.4%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "13.4%"
    }
  },
  {
    "task_id": 40131,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/vinta/awesome-python/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Calculate the ratio of the number of commits in {{repository}} that contain {{keyword}} in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "intent": "Calculate the ratio of the number of commits in vinta/awesome-python that contain py in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the commit messages for all commits.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/vinta/awesome-python/-/commits/master",
      "repository": "vinta/awesome-python",
      "keyword": "py",
      "answer": "23.5%",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "23.5%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "23.5%"
    }
  },
  {
    "task_id": 40132,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/geeeeeeeeek/electronic-wechat/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Calculate the ratio of the number of commits in {{repository}} that contain {{keyword}} in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "intent": "Calculate the ratio of the number of commits in the repository for a better WeChat that contain chat in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the commit messages for all commits.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/geeeeeeeeek/electronic-wechat/-/commits/master",
      "repository": "the repository for a better WeChat",
      "keyword": "chat",
      "answer": "5.5%",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "5.5%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "5.5%"
    }
  },
  {
    "task_id": 40133,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Calculate the ratio of the number of commits in {{repository}} that contain {{keyword}} in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "intent": "Calculate the ratio of the number of commits in the administrate project by thoughtbot, inc. that contain bump in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the commit messages for all commits.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/thoughtbot/administrate/-/commits/main",
      "repository": "the administrate project by thoughtbot, inc.",
      "keyword": "bump",
      "answer": "25.0%",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "25.0%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "25.0%"
    }
  },
  {
    "task_id": 40134,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/solarized-prism-theme/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Calculate the ratio of the number of commits in {{repository}} that contain {{keyword}} in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "intent": "Calculate the ratio of the number of commits in my project for a solarized theme for prism.js that contain update in the commit message. Round the ratio so that the output would be like '14.2%'.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the commit messages for all commits.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/solarized-prism-theme/-/commits/master",
      "repository": "my project for a solarized theme for prism.js",
      "keyword": "update",
      "answer": "42.9%",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "42.9%"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "42.9%"
    }
  },
  {
    "task_id": 40140,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/facebook/create-react-app/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Identify the most active contributor in {{repository}} {{date}} and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "intent": "Identify the most active contributor in facebook/create-react-app during 2021 and 2022 and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the author for the commits within the specified timeframe.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/facebook/create-react-app/-/commits/main",
      "repository": "facebook/create-react-app",
      "date": "during 2021 and 2022",
      "enddate": "2022",
      "answer": "Ian Sutherland, 21 commits",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ian Sutherland, 21 commits"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Ian Sutherland, 21 commits"
    }
  },
  {
    "task_id": 40141,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/solarized-prism-theme/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Identify the most active contributor in {{repository}} {{date}} and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "intent": "Identify the most active contributor in my project for a solarized theme for prism.js between 2010 and 2015 and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the author for the commits within the specified timeframe.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/solarized-prism-theme/-/commits/master",
      "repository": "my project for a solarized theme for prism.js",
      "date": "between 2010 and 2015",
      "answer": "小子欠扁, 4 commits",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "小子欠扁, 4 commits"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "小子欠扁, 4 commits"
    }
  },
  {
    "task_id": 40142,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Identify the most active contributor in {{repository}} {{date}} and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "intent": "Identify the most active contributor in The A11Y Project from August 2022 and February 2023 and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the author for the commits within the specified timeframe.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/commits/main",
      "repository": "The A11Y Project",
      "date": "from August 2022 and February 2023",
      "answer": "Eric Bailey, 36 commits",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Eric Bailey, 36 commits"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Eric Bailey, 36 commits"
    }
  },
  {
    "task_id": 40143,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/cppmap/cppmap.docs/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Identify the most active contributor in {{repository}} {{date}} and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "intent": "Identify the most active contributor in the reposotiry for C++ の歩き方 during the latter half of 2022 and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the author for the commits within the specified timeframe.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/cppmap/cppmap.docs/-/commits/master",
      "repository": "the reposotiry for C++ の歩き方",
      "date": "during the latter half of 2022",
      "answer": "Ryo Suzuki, 2 commits",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Ryo Suzuki, 2 commits"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Ryo Suzuki, 2 commits"
    }
  },
  {
    "task_id": 40144,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/root/metaseq/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Identify the most active contributor in {{repository}} {{date}} and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "intent": "Identify the most active contributor in the repo for external large-scale work by the administrator until 2022 and show the number of commits during that period. Show the results in the following format: (contributor name), (number of commits) commits",
    "required_obs": "any",
    "type_main": "massive_memory",
    "type_sub": "long-term",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"Commits\" page and check the author for the commits within the specified timeframe.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/root/metaseq/-/commits/main",
      "repository": "the repo for external large-scale work by the administrator",
      "date": "until 2022",
      "answer": "Susan Zhang, 64 commits",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "Susan Zhang, 64 commits"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "Susan Zhang, 64 commits"
    }
  },
  {
    "task_id": 40150,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/abisubramanya27",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are {{user1}}, {{user2}}, {{user3}}, {{user4}}, and {{user5}}. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "intent": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are Abishek S, Byte Blaze, Meta, Primer, and Karl Kroening. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access each user's profile page and check their user ID and the number of stars they have received.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/abisubramanya27",
      "user1": "Abishek S",
      "user2": "Byte Blaze",
      "user3": "Meta",
      "user4": "Primer",
      "user5": "Karl Kroening",
      "total_star": "{5:0,439:86,1553:51,2330:18,2367:21}",
      "memo1": "Abishek S, 5, 0",
      "memo2": "Byte Blaze, 2330, 18",
      "memo3": "Meta, 439, 86",
      "memo4": "Primer, 2367, 21",
      "memo5": "Karl Kroening, 1553, 51",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{5:0,439:86,1553:51,2330:18,2367:21}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{5:0,439:86,1553:51,2330:18,2367:21}"
    }
  },
  {
    "task_id": 40151,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/mk-j",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are {{user1}}, {{user2}}, {{user3}}, {{user4}}, and {{user5}}. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "intent": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are mk-j, Koushik Dutta, Erik Linder-Norén, thoughtbot, inc., and Keycloak. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access each user's profile page and check their user ID and the number of stars they have received.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/mk-j",
      "user1": "mk-j",
      "user2": "Koushik Dutta",
      "user3": "Erik Linder-Norén",
      "user4": "thoughtbot, inc.",
      "user5": "Keycloak",
      "total_star": "{311:45,830:47,1097:44,1847:43,1912:46}",
      "memo1": "mk-j, 830, 47",
      "memo2": "Koushik Dutta, 1912, 46",
      "memo3": "Erik Linder-Norén, 311, 45",
      "memo4": "thoughtbot, inc., 1097, 44",
      "memo5": "Keycloak, 1847, 43",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{311:45,830:47,1097:44,1847:43,1912:46}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{311:45,830:47,1097:44,1847:43,1912:46}"
    }
  },
  {
    "task_id": 40152,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/OpenAPITools",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are {{user1}}, {{user2}}, {{user3}}, {{user4}}, and {{user5}}. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "intent": "Generate a JSON object that maps each user's ID to the total number of stars they have received for their personal projects. The target users are OpenAPI Tools, William Ting, http ... PARTY!, Arachni - Web Application Security Scanner Framework, and Yue Zhao. The output must be a single-line JSON object with no unnecessary spaces or newlines, and the User IDs must be sorted in ascending order. For example: {123:10,1012:7,3023:15,4001:3,5000:8}.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access each user's profile page and check their user ID and the number of stars they have received.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/OpenAPITools",
      "user1": "OpenAPI Tools",
      "user2": "William Ting",
      "user3": "http ... PARTY!",
      "user4": "Arachni - Web Application Security Scanner Framework",
      "user5": "Yue Zhao",
      "total_star": "{391:42,1044:34,1213:38,1604:42,1759:41}",
      "memo1": "OpenAPI Tools, 391, 42",
      "memo2": "William Ting, 1604, 42",
      "memo3": "http ... PARTY!, 1213, 38",
      "memo4": "Arachni - Web Application Security Scanner Framework, 1044, 34",
      "memo5": "Yue Zhao, 1759, 41",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{391:42,1044:34,1213:38,1604:42,1759:41}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": "",
      "reference_answer_raw_annotation": "{391:42,1044:34,1213:38,1604:42,1759:41}"
    }
  },
  {
    "task_id": 40160,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that have at least {{lowerbound}} comments in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that have at least 5 comments in a11yproject/a11yproject.com. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that satisfy the condition. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
      "project": "a11yproject/a11yproject.com",
      "lowerbound": "5",
      "issues_count": "14",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "14"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40161,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that have at least {{lowerbound}} comments in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that have at least 2 comments in metaseq. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that satisfy the condition. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
      "project": "metaseq",
      "lowerbound": "2",
      "issues_count": "38",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "38"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40162,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that have at least {{lowerbound}} comments in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that have at least 1 comments in mozfest-program-2018. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that satisfy the condition. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
      "project": "mozfest-program-2018",
      "lowerbound": "1",
      "issues_count": "23",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "23"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40163,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that have at least {{lowerbound}} comments in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that have at least 2 comments in wxpy. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that satisfy the condition. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
      "project": "wxpy",
      "lowerbound": "2",
      "issues_count": "132",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "132"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40164,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/zhongyang219/TrafficMonitor/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that have at least {{lowerbound}} comments in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that have at least 2 comments in TrafficMonitor. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that satisfy the condition. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/zhongyang219/TrafficMonitor/-/issues",
      "project": "TrafficMonitor",
      "lowerbound": "2",
      "issues_count": "86",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "86"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40170,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each label to the number of open issues in {{project}}. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "intent": "Generate a JSON object mapping each label to the number of open issues in a11yproject/a11yproject.com. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues for each label. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
      "project": "a11yproject/a11yproject.com",
      "issue_counts": "{\"accessibility\":3,\"administration\":1,\"article audit\":3,\"bug\":3,\"checklist\":2,\"claimed\":22,\"content\":8,\"data\":1,\"design\":5,\"eleventy\":3,\"enhancement\":4,\"feature\":4,\"good first issue\":4,\"gulp\":1,\"help wanted\":8,\"idea\":3,\"javascript\":2,\"markup\":1,\"node\":1,\"post\":13,\"question\":1,\"redesign\":2,\"resource\":2,\"styling\":3}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"accessibility\":3,\"administration\":1,\"article audit\":3,\"bug\":3,\"checklist\":2,\"claimed\":22,\"content\":8,\"data\":1,\"design\":5,\"eleventy\":3,\"enhancement\":4,\"feature\":4,\"good first issue\":4,\"gulp\":1,\"help wanted\":8,\"idea\":3,\"javascript\":2,\"markup\":1,\"node\":1,\"post\":13,\"question\":1,\"redesign\":2,\"resource\":2,\"styling\":3}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40171,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each label to the number of open issues in {{project}}. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "intent": "Generate a JSON object mapping each label to the number of open issues in metaseq. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues for each label. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
      "project": "metaseq",
      "issue_counts": "{\"api\":2,\"better-eng\":27,\"bug\":31,\"checkpointing\":2,\"cleanup\":9,\"config\":6,\"enhancement\":29,\"eval\":1,\"good first issue\":8,\"question\":17,\"telemetry\":3,\"test-coverage\":3}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"api\":2,\"better-eng\":27,\"bug\":31,\"checkpointing\":2,\"cleanup\":9,\"config\":6,\"enhancement\":29,\"eval\":1,\"good first issue\":8,\"question\":17,\"telemetry\":3,\"test-coverage\":3}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40172,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each label to the number of open issues in {{project}}. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "intent": "Generate a JSON object mapping each label to the number of open issues in wxpy. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues for each label. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
      "project": "wxpy",
      "issue_counts": "{\"bug\":1,\"enhancement\":3,\"new-core\":1,\"question\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"bug\":1,\"enhancement\":3,\"new-core\":1,\"question\":1}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40173,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/wting/autojump/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each label to the number of open issues in {{project}}. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "intent": "Generate a JSON object mapping each label to the number of open issues in autojump. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues for each label. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/wting/autojump/-/issues",
      "project": "autojump",
      "issue_counts": "{\"bug\":7,\"enhancement\":9,\"help-wanted\":2,\"needs-info\":9,\"os-mac\":1,\"os-windows\":7,\"packaging-arch-linux\":1,\"priority-high\":6,\"priority-medium\":4,\"shell-bash\":1,\"shell-zsh\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"bug\":7,\"enhancement\":9,\"help-wanted\":2,\"needs-info\":9,\"os-mac\":1,\"os-windows\":7,\"packaging-arch-linux\":1,\"priority-high\":6,\"priority-medium\":4,\"shell-bash\":1,\"shell-zsh\":1}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40174,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/mathjax/MathJax/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each label to the number of open issues in {{project}}. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "intent": "Generate a JSON object mapping each label to the number of open issues in mathjax. Include only labels that have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Labels must be sorted in ascending order based on ASCII values. For example: {\"bug\":5,\"documentation\":2,\"enhancement\":3}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues for each label. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/mathjax/MathJax/-/issues",
      "project": "mathjax",
      "issue_counts": "{\"Accepted\":112,\"Address Later\":4,\"Browser Bug\":15,\"Cannot Reproduce\":9,\"Code Example\":42,\"Duplicate\":10,\"Expected Behavior\":21,\"Feature Request\":126,\"Investigate\":12,\"MML spec limitation\":3,\"Merged\":49,\"Needs Documentation\":15,\"Question\":12,\"Ready for Development\":11,\"Ready for Review\":14,\"SRE\":2,\"Test Available\":3,\"Test Needed\":51,\"Test Not Needed\":7,\"Upstream\":8,\"good first contribution\":6,\"v2\":30,\"v3\":94,\"v4\":12}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"Accepted\":112,\"Address Later\":4,\"Browser Bug\":15,\"Cannot Reproduce\":9,\"Code Example\":42,\"Duplicate\":10,\"Expected Behavior\":21,\"Feature Request\":126,\"Investigate\":12,\"MML spec limitation\":3,\"Merged\":49,\"Needs Documentation\":15,\"Question\":12,\"Ready for Development\":11,\"Ready for Review\":14,\"SRE\":2,\"Test Available\":3,\"Test Needed\":51,\"Test Not Needed\":7,\"Upstream\":8,\"good first contribution\":6,\"v2\":30,\"v3\":94,\"v4\":12}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40180,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many unique people have starred {{project1}}, {{project2}}, {{project3}}, {{project4}}, {{project5}}? The output must be a single integer with no extra text, spaces or formatting.",
    "intent": "How many unique people have starred AndroidSlidingUpPanel, create-react-app, PyTorch-GAN, PHP_XLSXWriter, pyod? The output must be a single integer with no extra text, spaces or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "For each project, go to the page that lists the people who starred it, and write down the names of the people who starred the project. Then, calculate the size of the union of these sets.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "AndroidSlidingUpPanel",
      "project2": "create-react-app",
      "project3": "PyTorch-GAN",
      "project4": "PHP_XLSXWriter",
      "project5": "pyod",
      "unique_users_num": "239",
      "memo1": "55 + 52 + 45 + 47 + 41 - 1 = 239",
      "memo2": "edwardcho stars PyTorch-GAN and pyod.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "239"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40181,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many unique people have starred {{project1}}, {{project2}}, {{project3}}, {{project4}}, {{project5}}? The output must be a single integer with no extra text, spaces or formatting.",
    "intent": "How many unique people have starred AndroidSlidingUpPanel, a11yproject.com, empathy-prompts, first-contributions, opensourcediversity.org? The output must be a single integer with no extra text, spaces or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "For each project, go to the page that lists the people who starred it, and write down the names of the people who starred the project. Then, calculate the size of the union of these sets.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "AndroidSlidingUpPanel",
      "project2": "a11yproject.com",
      "project3": "empathy-prompts",
      "project4": "first-contributions",
      "project5": "opensourcediversity.org",
      "unique_users_num": "138",
      "memo1": "55 + 21 + 6 + 32 + 28 - 4 = 138",
      "memo2": "esjay stars a11yproject.com and empathy-prompts.",
      "memo3": "Roshanjossey stars a11yproject.com, first-contributions and opensourcediversity.org.",
      "memo4": "byteblaze stars a11yproject.com and empathy-prompts.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "138"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40182,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many unique people have starred {{project1}}, {{project2}}, {{project3}}, {{project4}}, {{project5}}? The output must be a single integer with no extra text, spaces or formatting.",
    "intent": "How many unique people have starred a11yproject.com, empathy-prompts, opensourcediversity.org, PyTorch-GAN, pyod? The output must be a single integer with no extra text, spaces or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "massive_memory",
    "description": "For each project, go to the page that lists the people who starred it, and write down the names of the people who starred the project. Then, calculate the size of the union of these sets.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "a11yproject.com",
      "project2": "empathy-prompts",
      "project3": "opensourcediversity.org",
      "project4": "PyTorch-GAN",
      "project5": "pyod",
      "unique_users_num": "137",
      "memo1": "21 + 6 + 28 + 45 + 41 - 4 = 137",
      "memo2": "edwardcho stars PyTorch-GAN and pyod.",
      "memo3": "esjay stars a11yproject.com and empathy-prompts.",
      "memo4": "Roshanjossey stars a11yproject.com and opensourcediversity.org.",
      "memo5": "byteblaze stars a11yproject.com and empathy-prompts.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "137"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40190,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/DynamoRIO/dynamorio/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many open issues are assigned to {{userName}} in {{project}}? The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "How many open issues are assigned to Derek Bruening in dynamorio? The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to the user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/DynamoRIO/dynamorio/-/issues",
      "project": "dynamorio",
      "userName": "Derek Bruening",
      "issues_count": "76",
      "memo": "{\"Abhinav Anil Sharma\":8,\"Al Grant\":2,\"Assad Hashmi\":21,\"Derek Bruening\":76,\"Hendrik Greving\":13,\"John F.X. Galea\":3,\"Kirill\":1,\"Nahome Bete\":3,\"S.J.R. van Schaik\":1,\"Sotiris Apostolakis\":2,\"prasun3\":2,\"qidongzhao\":1,\"yxy\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "76"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40191,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/DynamoRIO/dynamorio/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many open issues are assigned to {{userName}} in {{project}}? The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "How many open issues are assigned to Assad Hashmi in dynamorio? The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to the user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/DynamoRIO/dynamorio/-/issues",
      "project": "dynamorio",
      "userName": "Assad Hashmi",
      "issues_count": "21",
      "memo": "{\"Abhinav Anil Sharma\":8,\"Al Grant\":2,\"Assad Hashmi\":21,\"Derek Bruening\":76,\"Hendrik Greving\":13,\"John F.X. Galea\":3,\"Kirill\":1,\"Nahome Bete\":3,\"S.J.R. van Schaik\":1,\"Sotiris Apostolakis\":2,\"prasun3\":2,\"qidongzhao\":1,\"yxy\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "21"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40192,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/keycloak/keycloak/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many open issues are assigned to {{userName}} in {{project}}? The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "How many open issues are assigned to Martin Bartoš in keycloak? The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to the user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/keycloak/keycloak/-/issues",
      "project": "keycloak",
      "userName": "Martin Bartoš",
      "issues_count": "25",
      "memo": "{\"Alexander Schwartz\":22,\"Erik Jan de Wit\":10,\"Jon Koops\":10,\"Lukas Hanusovsky\":1,\"Martin Bartoš\":25,\"Martin Kanis\":5,\"Michal Hajas\":18,\"Pedro Igor\":17,\"Ricardo Martin\":9,\"Stefan Guilhen\":14,\"Vlasta Ramik\":8,\"Václav Muzikář\":22,\"agagancarczyk\":6,\"fwojnar\":5,\"ikhomyn\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "25"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40193,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/keycloak/keycloak/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many open issues are assigned to {{userName}} in {{project}}? The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "How many open issues are assigned to Václav Muzikář in keycloak? The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to the user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/keycloak/keycloak/-/issues",
      "project": "keycloak",
      "userName": "Václav Muzikář",
      "issues_count": "22",
      "memo": "{\"Alexander Schwartz\":22,\"Erik Jan de Wit\":10,\"Jon Koops\":10,\"Lukas Hanusovsky\":1,\"Martin Bartoš\":25,\"Martin Kanis\":5,\"Michal Hajas\":18,\"Pedro Igor\":17,\"Ricardo Martin\":9,\"Stefan Guilhen\":14,\"Vlasta Ramik\":8,\"Václav Muzikář\":22,\"agagancarczyk\":6,\"fwojnar\":5,\"ikhomyn\":1}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "22"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40194,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "How many open issues are assigned to {{userName}} in {{project}}? The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "How many open issues are assigned to Jim Schubert in openapi-generator? The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to the user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator/-/issues",
      "project": "openapi-generator",
      "userName": "Jim Schubert",
      "issues_count": "6",
      "memo": "{\"Jim Schubert\":6}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "6"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40200,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each user's display name to their number of open assigned issues in {{project}}. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "intent": "Generate a JSON object mapping each user's display name to their number of open assigned issues in a11yproject/a11yproject.com. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to each user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/issues",
      "project": "a11yproject/a11yproject.com",
      "issue_counts": "{\"Agustina Chaer\":1,\"Byte Blaze\":4,\"Conor\":1,\"Dan Matthew\":1,\"EJ Mason\":3,\"Kiri\":1,\"Roshan Jossy\":4,\"Wayne Elgin\":1,\"ilknureren\":1}",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"Agustina Chaer\":1,\"Byte Blaze\":4,\"Conor\":1,\"Dan Matthew\":1,\"EJ Mason\":3,\"Kiri\":1,\"Roshan Jossy\":4,\"Wayne Elgin\":1,\"ilknureren\":1}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40201,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/wting/autojump/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each user's display name to their number of open assigned issues in {{project}}. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "intent": "Generate a JSON object mapping each user's display name to their number of open assigned issues in wting/autojump. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to each user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/wting/autojump/-/issues",
      "project": "wting/autojump",
      "issue_counts": "{\"William Ting\":2}",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"William Ting\":2}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40202,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Generate a JSON object mapping each user's display name to their number of open assigned issues in {{project}}. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "intent": "Generate a JSON object mapping each user's display name to their number of open assigned issues in mozfest-program-2018. Include only users who have at least one open issue. The output must be a single-line JSON object with no unnecessary spaces or newlines. Display names (not usernames) must be sorted in ascending order based on ASCII values. For example: {\"Alice Johnson\":3,\"Bob Smith\":5,\"Charlie Williams\":2}",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues assigned to each user. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task. In addition, searching with 'Assignee = Any' also reduces the number of steps.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
      "project": "mozfest-program-2018",
      "issue_counts": "{\"@Btayeg\":16,\"AngelJum\":8,\"Chad Sansing\":14,\"David Ross\":44,\"Geraldo Barros\":10,\"Jon Tutcher\":14,\"Joseph Thomas\":9,\"Mark Boas\":9,\"arroway\":15}",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "{\"@Btayeg\":16,\"AngelJum\":8,\"Chad Sansing\":14,\"David Ross\":44,\"Geraldo Barros\":10,\"Jon Tutcher\":14,\"Joseph Thomas\":9,\"Mark Boas\":9,\"arroway\":15}"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40210,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/byteblaze/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Please provide the sum of {{target}} for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "intent": "Please provide the sum of commits for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access the page that lists the projects you have starred, and count the number of the target for all the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/byteblaze/starred",
      "target": "commits",
      "answers": "2668",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "2668"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40211,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/byteblaze/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Please provide the sum of {{target}} for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "intent": "Please provide the sum of branches for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access the page that lists the projects you have starred, and count the number of the target for all the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/byteblaze/starred",
      "target": "branches",
      "answers": "21",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "21"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40212,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/users/byteblaze/starred",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Please provide the sum of {{target}} for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "intent": "Please provide the sum of tags for all the projects I have starred. The output must be a single integer without commas, spaces, or any other formatting. For example, if the sum is one thousand two hundred thirty-four, the correct output is '1234' (not '1,234' or ' 1234 ').",
    "required_obs": "any",
    "type_main": "long-term",
    "type_sub": "calc",
    "description": "Access the page that lists the projects you have starred, and count the number of the target for all the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/users/byteblaze/starred",
      "target": "tags",
      "answers": "27",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "27"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40220,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Compute and output the total number of commits made by {{userName}} in the main (or master) branch of repositories {{repository1}}, {{repository2}}, and {{repository3}}, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "Compute and output the total number of commits made by Steven Frank in the main (or master) branch of repositories byteblaze/cloud-to-butt, byteblaze/millennials-to-snake-people, and sample-gitlab, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the commits page of the repository, and count the number of commits made by the user.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt/-/commits/master",
      "userName": "Steven Frank",
      "repository1": "byteblaze/cloud-to-butt",
      "repository2": "byteblaze/millennials-to-snake-people",
      "repository3": "sample-gitlab",
      "commitSum": "36",
      "memo": "git log --author=USER_NAME --pretty=oneline | wc -l \n 21 + 15 + 0 = 36",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "36"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40221,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/empathy-prompts/-/commits/main",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Compute and output the total number of commits made by {{userName}} in the main (or master) branch of repositories {{repository1}}, {{repository2}}, and {{repository3}}, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "Compute and output the total number of commits made by Eric Bailey in the main (or master) branch of repositories byteblaze/empathy-prompts, byteblaze/a11y-syntax-highlighting, and byteblaze/millennials-to-snake-people, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the commits page of the repository, and count the number of commits made by the user.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/empathy-prompts/-/commits/main",
      "userName": "Eric Bailey",
      "repository1": "byteblaze/empathy-prompts",
      "repository2": "byteblaze/a11y-syntax-highlighting",
      "repository3": "byteblaze/millennials-to-snake-people",
      "commitSum": "270",
      "memo": "git log --author=USER_NAME --pretty=oneline | wc -l \n 151 + 39 + 80 = 270",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "270"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40222,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/millennials-to-snake-people/-/commits/master",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Compute and output the total number of commits made by {{userName}} in the main (or master) branch of repositories {{repository1}}, {{repository2}}, and {{repository3}}, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "intent": "Compute and output the total number of commits made by Eric Bailey in the main (or master) branch of repositories byteblaze/millennials-to-snake-people, sample-gitlab, and byteblaze/empathy-prompts, including the number of times a pull request was merged. The output must be a single integer with no extra text, spaces, or formatting.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the commits page of the repository, and count the number of commits made by the user.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/millennials-to-snake-people/-/commits/master",
      "userName": "Eric Bailey",
      "repository1": "byteblaze/millennials-to-snake-people",
      "repository2": "sample-gitlab",
      "repository3": "byteblaze/empathy-prompts",
      "commitSum": "231",
      "memo": "git log --author=USER_NAME --pretty=oneline | wc -l \n 80 + 0 + 151 = 231",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "231"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40230,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Determine the order of the projects among {{project1}}, {{project2}}, and {{project3}} based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "intent": "Determine the order of the projects among a11y-webring.club, design, and sample-gitlab based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the Contributors page of the project, and check the timestamps of the first commits of the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "a11y-webring.club",
      "project2": "design",
      "project3": "sample-gitlab",
      "orderedProjects": "sample-gitlab,a11y-webring.club,design",
      "memo": "sample-gitlab: 2021-02-15T15:52:03+00:00, a11y-webring.club: 2018-12-12T13:14:49-06:00, design: 2018-10-22T16:33:30-04:00, empathy-prompts: 2017-04-19T23:31:37-04:00, ericwbailey.website: 2016-10-10T16:25:14-04:00",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "sample-gitlab,a11y-webring.club,design"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40231,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Determine the order of the projects among {{project1}}, {{project2}}, and {{project3}} based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "intent": "Determine the order of the projects among a11y-syntax-highlighting, a11yproject.com, and cloud-to-butt based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the Contributors page of the project, and check the timestamps of the first commits of the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "a11y-syntax-highlighting",
      "project2": "a11yproject.com",
      "project3": "cloud-to-butt",
      "orderedProjects": "a11y-syntax-highlighting,cloud-to-butt,a11yproject.com",
      "memo": "a11y-syntax-highlighting: 2013-04-25T06:54:06-07:00, a11yproject.com: 2013-01-10T12:39:57-08:00, cloud-to-butt: 2013-03-11T22:27:10-07:00, empathy-prompts: 2017-04-19T23:31:37-04:00, a11y-webring.club: 2018-12-12T13:14:49-06:00",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "a11y-syntax-highlighting,cloud-to-butt,a11yproject.com"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40232,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Determine the order of the projects among {{project1}}, {{project2}}, and {{project3}} based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "intent": "Determine the order of the projects among ericwbailey.website, design, and sample-gitlab based on the timestamps of their first commits, sorted from newest to oldest. Output only their repository names (without any organization prefixes) as a single-line comma-separated string with no extra spaces or text.",
    "required_obs": "any",
    "type_main": "long-term",
    "description": "Access the Contributors page of the project, and check the timestamps of the first commits of the projects.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore",
      "project1": "ericwbailey.website",
      "project2": "design",
      "project3": "sample-gitlab",
      "orderedProjects": "sample-gitlab,design,ericwbailey.website",
      "memo": "ericwbailey.website: 2016-10-10T16:25:14-04:00, design: 2018-10-22T16:33:30-04:00, sample-gitlab: 2021-02-15T15:52:03+00:00, a11y-syntax-highlighting: 2013-04-25T06:54:06-07:00, empathy-prompts: 2017-04-19T23:31:37-04:00",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "sample-gitlab,design,ericwbailey.website"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40240,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that were last updated on or after {{lastupdatetime}} (UTC) in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that were last updated on or after 2021-03-10 00:00:00 (UTC) in a11yproject/a11yproject.com. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that were last updated on or after the specified timestamp. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com/-/issues",
      "project": "a11yproject/a11yproject.com",
      "lastupdatetime": "2021-03-10 00:00:00",
      "issues_count": "36",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "36"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40241,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that were last updated on or after {{lastupdatetime}} (UTC) in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that were last updated on or after 2022-10-01 00:00:00 (UTC) in metaseq. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that were last updated on or after the specified timestamp. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/root/metaseq/-/issues",
      "project": "metaseq",
      "lastupdatetime": "2022-10-01 00:00:00",
      "issues_count": "77",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "77"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40242,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that were last updated on or after {{lastupdatetime}} (UTC) in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that were last updated on or after 2019-03-10 00:00:00 (UTC) in mozfest-program-2018. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that were last updated on or after the specified timestamp. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/MozillaFestival/mozfest-program-2018/-/issues",
      "project": "mozfest-program-2018",
      "lastupdatetime": "2019-03-10 00:00:00",
      "issues_count": "34",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "34"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40243,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that were last updated on or after {{lastupdatetime}} (UTC) in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that were last updated on or after 2018-03-10 00:00:00 (UTC) in wxpy. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that were last updated on or after the specified timestamp. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/youfou/wxpy/-/issues",
      "project": "wxpy",
      "lastupdatetime": "2018-03-10 00:00:00",
      "issues_count": "189",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "189"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40244,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/zhongyang219/TrafficMonitor/-/issues",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Count the number of open issues that were last updated on or after {{lastupdatetime}} (UTC) in {{project}}. Output the count as a single integer with no extra text, spaces, or formatting.",
    "intent": "Count the number of open issues that were last updated on or after 2022-03-10 00:00:00 (UTC) in TrafficMonitor. Output the count as a single integer with no extra text, spaces, or formatting.",
    "required_obs": "text",
    "type_main": "long-term",
    "description": "Access the issues page of the project, and count the number of open issues that were last updated on or after the specified timestamp. Increasing the number of items displayed on a screen to 100 reduces the number of steps required to complete a task.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/zhongyang219/TrafficMonitor/-/issues",
      "project": "TrafficMonitor",
      "lastupdatetime": "2022-03-10 00:00:00",
      "issues_count": "350",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "string_match"
      ],
      "reference_answers": {
        "exact_match": "350"
      },
      "reference_url": "",
      "program_html": [],
      "string_note": ""
    }
  },
  {
    "task_id": 40250,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/facebook/create-react-app",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a license for {{repository1}} that is the same type as the license for {{repository2}}. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "intent": "Create a license for byteblaze/cloud-to-butt that is the same type as the license for Meta/create-react-app. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Go to the repository page of repository2 and find the license type. Then, create a file in repository1 with the same license type as repository2.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/facebook/create-react-app",
      "repository1": "byteblaze/cloud-to-butt",
      "repository2": "Meta/create-react-app",
      "url": "__GITLAB__/byteblaze/cloud-to-butt/-/blob/master/LICENSE.txt",
      "license": "MIT License",
      "checkpoint1": "MIT",
      "checkpoint_info": "The license for {{repository2}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/cloud-to-butt/-/blob/master/LICENSE.txt",
          "locator": "",
          "required_contents": {
            "must_include": [
              "MIT License"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 40251,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a license for {{repository1}} that is the same type as the license for {{repository2}}. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "intent": "Create a license for byteblaze/accessible-html-content-patterns that is the same type as the license for OpenAPI Tools/openapi-generator. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Go to the repository page of repository2 and find the license type. Then, create a file in repository1 with the same license type as repository2.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/OpenAPITools/openapi-generator",
      "repository1": "byteblaze/accessible-html-content-patterns",
      "repository2": "OpenAPI Tools/openapi-generator",
      "url": "__GITLAB__/byteblaze/accessible-html-content-patterns/-/blob/main/LICENSE",
      "license": "Apache License",
      "checkpoint1": "Apache",
      "checkpoint_info": "The license for {{repository2}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/accessible-html-content-patterns/-/blob/main/LICENSE",
          "locator": "",
          "required_contents": {
            "must_include": [
              "Apache License"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 40252,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/layeh/gumble",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a license for {{repository1}} that is the same type as the license for {{repository2}}. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "intent": "Create a license for byteblaze/a11y-syntax-highlighting that is the same type as the license for layeh/gumble. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Go to the repository page of repository2 and find the license type. Then, create a file in repository1 with the same license type as repository2.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/layeh/gumble",
      "repository1": "byteblaze/a11y-syntax-highlighting",
      "repository2": "layeh/gumble",
      "url": "__GITLAB__/byteblaze/a11y-syntax-highlighting/-/blob/main/LICENSE",
      "license": "Mozilla Public License",
      "checkpoint1": "Mozilla Public",
      "checkpoint_info": "The license for {{repository2}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/a11y-syntax-highlighting/-/blob/main/LICENSE",
          "locator": "",
          "required_contents": {
            "must_include": [
              "Mozilla Public License"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 40253,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/evilcos/xssor2",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a license for {{repository1}} that is the same type as the license for {{repository2}}. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "intent": "Create a license for byteblaze/dotfiles that is the same type as the license for evilcos/xssor2. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Go to the repository page of repository2 and find the license type. Then, create a file in repository1 with the same license type as repository2.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/evilcos/xssor2",
      "repository1": "byteblaze/dotfiles",
      "repository2": "evilcos/xssor2",
      "url": "__GITLAB__/byteblaze/dotfiles/-/blob/main/LICENSE",
      "license": "BSD 2-Clause License",
      "checkpoint1": "BSD 2-Clause",
      "checkpoint_info": "The license for {{repository2}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/dotfiles/-/blob/main/LICENSE",
          "locator": "",
          "required_contents": {
            "must_include": [
              "BSD 2-Clause License"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 40254,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/yjlou/2019-nCov",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a license for {{repository1}} that is the same type as the license for {{repository2}}. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "intent": "Create a license for byteblaze/timeit that is the same type as the license for yjlou/2019-nCov. If the license file is already present, it should be replaced (make sure there are no multiple license files).",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Go to the repository page of repository2 and find the license type. Then, create a file in repository1 with the same license type as repository2.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/yjlou/2019-nCov",
      "repository1": "byteblaze/timeit",
      "repository2": "yjlou/2019-nCov",
      "url": "__GITLAB__/byteblaze/timeit/-/blob/master/LICENSE",
      "license": "GNU GENERAL PUBLIC LICENSE",
      "checkpoint1": "GNU GENERAL PUBLIC",
      "checkpoint_info": "The license for {{repository2}}.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/timeit/-/blob/master/LICENSE",
          "locator": "",
          "required_contents": {
            "must_include": [
              "GNU GENERAL PUBLIC LICENSE"
            ]
          }
        }
      ]
    }
  },
  {
    "task_id": 40260,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/a11y-syntax-highlighting",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Change the list in the .gitignore file of {{repository}} to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "intent": "Change the list in the .gitignore file of byteblaze/a11y-syntax-highlighting to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"edit\" menu to modify the gitignore file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/a11y-syntax-highlighting",
      "default_branch": "main",
      "repository": "byteblaze/a11y-syntax-highlighting",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/a11y-syntax-highlighting/-/raw/main/.gitignore",
          "locator": "document.querySelector('body > pre').innerText",
          "required_contents": {
            "exact_match": ".DS_Store\nnode_modules\n.vscode"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40261,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/primer/design",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Change the list in the .gitignore file of {{repository}} to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "intent": "Change the list in the .gitignore file of the repository for the Primer Interface Guidelines to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"edit\" menu to modify the gitignore file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/primer/design",
      "default_branch": "main",
      "repository": "the repository for the Primer Interface Guidelines",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/primer/design/-/raw/main/.gitignore",
          "locator": "document.querySelector('body > pre').innerText",
          "required_contents": {
            "exact_match": ".DS_Store\nnode_modules\n.vscode"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40262,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/ericwbailey.website",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Change the list in the .gitignore file of {{repository}} to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "intent": "Change the list in the .gitignore file of my personal webpage to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"edit\" menu to modify the gitignore file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/ericwbailey.website",
      "default_branch": "main",
      "repository": "my personal webpage",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/ericwbailey.website/-/raw/main/.gitignore",
          "locator": "document.querySelector('body > pre').innerText",
          "required_contents": {
            "exact_match": ".DS_Store\nnode_modules\n.vscode"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40263,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Change the list in the .gitignore file of {{repository}} to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "intent": "Change the list in the .gitignore file of my cloud-to-butt project to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"edit\" menu to modify the gitignore file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/cloud-to-butt",
      "default_branch": "master",
      "repository": "my cloud-to-butt project",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/cloud-to-butt/-/raw/master/.gitignore",
          "locator": "document.querySelector('body > pre').innerText",
          "required_contents": {
            "exact_match": ".DS_Store\nnode_modules\n.vscode"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40264,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/gimmiethat.space",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Change the list in the .gitignore file of {{repository}} to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "intent": "Change the list in the .gitignore file of byteblaze/gimmiethat.space to '.DS_Store', 'node_modules/', and '.vscode'. You may add the file if it does not exist.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "others",
    "description": "The agent should search for the appropriate repository with the search box by choosing the best keyword according to the description. It should navigate to the \"edit\" menu to modify the gitignore file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/gimmiethat.space",
      "default_branch": "main",
      "repository": "byteblaze/gimmiethat.space",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/gimmiethat.space/-/raw/main/.gitignore",
          "locator": "document.querySelector('body > pre').innerText",
          "required_contents": {
            "exact_match": ".DS_Store\nnode_modules\n.vscode"
          }
        }
      ],
      "string_note": "",
      "reference_answer_raw_annotation": ""
    }
  },
  {
    "task_id": 40270,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a new repository named {{repository2}} and copy the README.md file from {{repository1}}.",
    "intent": "Create a new repository named byteblaze/new_a11y-syntax-highlighting and copy the README.md file from a11yproject/a11yproject.com.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access the README.md file of {{repository1}}, display the source code, and copy it. Then, create a new repository named {{repository2}}, access the README.md file, paste the copied source code into it, and commit the changes.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/a11yproject/a11yproject.com",
      "repository1": "a11yproject/a11yproject.com",
      "repository2": "byteblaze/new_a11y-syntax-highlighting",
      "readme_repo1": "![A11Y.](https://github.com/a11yproject/a11yproject.com/blob/main/src/img/social/og-image-home.png?raw=true)\n\n# The A11Y Project\n\nThe Accessibility [(A11Y)](https://a11yproject.com/posts/a11y-and-other-numeronyms/) Project is an Open-source, community-driven effort to make digital accessibility easier.\n\n\n## Contributing\n\nYou can learn about helping this project by reading our [Code of Conduct](https://a11yproject.com/code-of-conduct/), [Contributor documentation](https://a11yproject.com/contributing-guidelines/), and [Content Style Guide](https://a11yproject.com/content-style-guide/). Please familiarize yourself with them before submitting content.\n\nThis `README` is focused on the technical side of the project. If you are interested in contributing information like Posts or Resources, please refer to our [Contributing Guidelines](https://a11yproject.com/contributing-guidelines/).\n\n\n## Development\n\n### Technology\n\nThe A11Y Project uses [Eleventy](https://www.11ty.io/) to manage its content. Eleventy relies on [Markdown](https://daringfireball.net/projects/markdown/syntax), [Sass](https://sass-lang.com/), [Nunjucks](https://mozilla.github.io/nunjucks/), and [JSON](https://www.json.org/) to function.\n\nIt may be helpful to familiarize yourself with these technologies, depending on what you want to do. For more information, check out our [Contributor documentation](https://a11yproject.com/contributing-guidelines/).\n\n### Requirements\n\nYou'll need access to the following programs and technology in order to get the website running on your computer to work on:\n\n1. A command line application such as Terminal.\n    - If you want to learn more about working in the command line, Wes Bos offers [a great free course](https://commandlinepoweruser.com/).\n    - If you are using Windows, [Hyper](https://hyper.is/) is a good, free command-line application you can download, install, and run.\n1. [Git](https://git-scm.com/) version control and a [GitHub account](https://github.com/).\n    - You can check to see if Git is already installed on your computer by typing `git --version` into your command line application. If it is installed it will list the currently installed version (e.g. `git version 2.18.0`).\n    - If you prefer to use a GUI to work with version control, GitHub offers a [free desktop app](https://desktop.github.com).\n1. [Node.js](https://nodejs.org/en/), a programming environment powered by JavaScript.\n    - You can check to see if Node.js is already installed on your computer by typing `node -v` into your command line application. If it is installed it will list the currently installed version (e.g. `v16.4.0`). The A11Y Project requires a minimum version of `16.0.0`.\n    - It may also be helpful to use a program such as [nvm](https://github.com/creationix/nvm) to help manage your Node.js versions. This will ensure that the version of Node.js your computer uses to run various things won't conflict with an updated version. For Windows users, you could use [coreybutler/nvm-windows](https://github.com/coreybutler/nvm-windows).\n\n### Installation\n\nOnce you have met [the prerequisites](#requirements), follow these steps to install the website on your computer:\n\n1. Clone this repository by entering this command into your command line application: `git clone https://github.com/a11yproject/a11yproject.com.git`. It will create a version-controlled copy of the website in the directory you entered the command in.\n1. Navigate into the project's [root directory](https://en.m.wikipedia.org/wiki/Root_directory) by typing `cd a11yproject.com` in your command line application.\n1. Install the project's Node.js modules by typing `npm install` into your command line application. A list of these modules should be displayed after they are downloaded and installed.\n\n### Running the website\n\nAfter cloning and installing project Node.js modules, you will need to tell Node.js to compile the project and turn it into a website. To do this:\n\n- **macOS and Linux:** Type `npm start` into your command line application.\n- **Windows:** Type `npm run eleventy-watch & npm run gulp-watch` into your command line application.\n\nYour command line application will then display some information about Eleventy, including a line that starts with `Local:`. You can copy the URL it points to (it should read something like [`http://localhost:3000`](http://localhost:3000)) and paste it into a browser tab. This will load a local copy of the website that you can interact with to preview your changes.\n\nYou can also use the `External` URL to preview the local copy on another device connected to the same network, which helps you check to see how the site looks and functions on things like smartphones. This is done via [Browsersync](https://www.browsersync.io/).\n\n### Updating the website\n\nSaving project files will make Node.js regenerate the website to reflect the changes you made. Your command line application will display some new messaging to reflect this, including any errors you might accidentally make. Don't worry! Since the site uses version control, you're not in danger of seriously breaking anything. If you fix the error, Node.js should continue to run.\n\nMake sure you edit the files in the `src/` subdirectory. Any edits made in the `dist` subdirectory will be overwritten by the next change to any file in `src/` and all your hard work will be lost!\n\n### Quitting\n\nYou can tell Node.js to stop running by pressing the <kbd>Control</kbd> and <kbd>C</kbd> keys at the same time in your command line application, or by closing the command line application window or tab.\n\n### Code Tour\n\nIf you use [Visual Studio Code](https://code.visualstudio.com/) as your code editor, you can take an introductory tour of the repository via the [CodeTour extension](https://marketplace.visualstudio.com/items?itemName=vsls-contrib.codetour).\n\n## Troubleshooting\n\nPlease refer to our [Troubleshooting documentation](https://github.com/a11yproject/a11yproject.com/blob/main/TROUBLESHOOTING.md) for help with issues running the site.\n",
      "readme_repo2_url": "__GITLAB__/byteblaze/new_a11y-syntax-highlighting/-/raw/main/README.md",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/new_a11y-syntax-highlighting/-/raw/main/README.md",
          "locator": "document.querySelector('pre').innerText",
          "required_contents": {
            "exact_match": "![A11Y.](https://github.com/a11yproject/a11yproject.com/blob/main/src/img/social/og-image-home.png?raw=true)\n\n# The A11Y Project\n\nThe Accessibility [(A11Y)](https://a11yproject.com/posts/a11y-and-other-numeronyms/) Project is an Open-source, community-driven effort to make digital accessibility easier.\n\n\n## Contributing\n\nYou can learn about helping this project by reading our [Code of Conduct](https://a11yproject.com/code-of-conduct/), [Contributor documentation](https://a11yproject.com/contributing-guidelines/), and [Content Style Guide](https://a11yproject.com/content-style-guide/). Please familiarize yourself with them before submitting content.\n\nThis `README` is focused on the technical side of the project. If you are interested in contributing information like Posts or Resources, please refer to our [Contributing Guidelines](https://a11yproject.com/contributing-guidelines/).\n\n\n## Development\n\n### Technology\n\nThe A11Y Project uses [Eleventy](https://www.11ty.io/) to manage its content. Eleventy relies on [Markdown](https://daringfireball.net/projects/markdown/syntax), [Sass](https://sass-lang.com/), [Nunjucks](https://mozilla.github.io/nunjucks/), and [JSON](https://www.json.org/) to function.\n\nIt may be helpful to familiarize yourself with these technologies, depending on what you want to do. For more information, check out our [Contributor documentation](https://a11yproject.com/contributing-guidelines/).\n\n### Requirements\n\nYou'll need access to the following programs and technology in order to get the website running on your computer to work on:\n\n1. A command line application such as Terminal.\n    - If you want to learn more about working in the command line, Wes Bos offers [a great free course](https://commandlinepoweruser.com/).\n    - If you are using Windows, [Hyper](https://hyper.is/) is a good, free command-line application you can download, install, and run.\n1. [Git](https://git-scm.com/) version control and a [GitHub account](https://github.com/).\n    - You can check to see if Git is already installed on your computer by typing `git --version` into your command line application. If it is installed it will list the currently installed version (e.g. `git version 2.18.0`).\n    - If you prefer to use a GUI to work with version control, GitHub offers a [free desktop app](https://desktop.github.com).\n1. [Node.js](https://nodejs.org/en/), a programming environment powered by JavaScript.\n    - You can check to see if Node.js is already installed on your computer by typing `node -v` into your command line application. If it is installed it will list the currently installed version (e.g. `v16.4.0`). The A11Y Project requires a minimum version of `16.0.0`.\n    - It may also be helpful to use a program such as [nvm](https://github.com/creationix/nvm) to help manage your Node.js versions. This will ensure that the version of Node.js your computer uses to run various things won't conflict with an updated version. For Windows users, you could use [coreybutler/nvm-windows](https://github.com/coreybutler/nvm-windows).\n\n### Installation\n\nOnce you have met [the prerequisites](#requirements), follow these steps to install the website on your computer:\n\n1. Clone this repository by entering this command into your command line application: `git clone https://github.com/a11yproject/a11yproject.com.git`. It will create a version-controlled copy of the website in the directory you entered the command in.\n1. Navigate into the project's [root directory](https://en.m.wikipedia.org/wiki/Root_directory) by typing `cd a11yproject.com` in your command line application.\n1. Install the project's Node.js modules by typing `npm install` into your command line application. A list of these modules should be displayed after they are downloaded and installed.\n\n### Running the website\n\nAfter cloning and installing project Node.js modules, you will need to tell Node.js to compile the project and turn it into a website. To do this:\n\n- **macOS and Linux:** Type `npm start` into your command line application.\n- **Windows:** Type `npm run eleventy-watch & npm run gulp-watch` into your command line application.\n\nYour command line application will then display some information about Eleventy, including a line that starts with `Local:`. You can copy the URL it points to (it should read something like [`http://localhost:3000`](http://localhost:3000)) and paste it into a browser tab. This will load a local copy of the website that you can interact with to preview your changes.\n\nYou can also use the `External` URL to preview the local copy on another device connected to the same network, which helps you check to see how the site looks and functions on things like smartphones. This is done via [Browsersync](https://www.browsersync.io/).\n\n### Updating the website\n\nSaving project files will make Node.js regenerate the website to reflect the changes you made. Your command line application will display some new messaging to reflect this, including any errors you might accidentally make. Don't worry! Since the site uses version control, you're not in danger of seriously breaking anything. If you fix the error, Node.js should continue to run.\n\nMake sure you edit the files in the `src/` subdirectory. Any edits made in the `dist` subdirectory will be overwritten by the next change to any file in `src/` and all your hard work will be lost!\n\n### Quitting\n\nYou can tell Node.js to stop running by pressing the <kbd>Control</kbd> and <kbd>C</kbd> keys at the same time in your command line application, or by closing the command line application window or tab.\n\n### Code Tour\n\nIf you use [Visual Studio Code](https://code.visualstudio.com/) as your code editor, you can take an introductory tour of the repository via the [CodeTour extension](https://marketplace.visualstudio.com/items?itemName=vsls-contrib.codetour).\n\n## Troubleshooting\n\nPlease refer to our [Troubleshooting documentation](https://github.com/a11yproject/a11yproject.com/blob/main/TROUBLESHOOTING.md) for help with issues running the site.\n"
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 40271,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/root/sample-gitlab",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a new repository named {{repository2}} and copy the README.md file from {{repository1}}.",
    "intent": "Create a new repository named byteblaze/sample-gitlab-v2 and copy the README.md file from sample-gitlab.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access the README.md file of {{repository1}}, display the source code, and copy it. Then, create a new repository named {{repository2}}, access the README.md file, paste the copied source code into it, and commit the changes.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/root/sample-gitlab",
      "repository1": "sample-gitlab",
      "repository2": "byteblaze/sample-gitlab-v2",
      "readme_repo1": "# Sample GitLab Project\n\nThis sample project shows how a project in GitLab looks for demonstration purposes. It contains issues, merge requests and Markdown files in many branches,\nnamed and filled with lorem ipsum.\n\nYou can look around to get an idea how to structure your project and, when done, you can safely delete this project.\n\n[Learn more about creating GitLab projects.](https://docs.gitlab.com/ee/gitlab-basics/create-project.html)\n",
      "readme_repo2_url": "__GITLAB__/byteblaze/sample-gitlab-v2/-/raw/main/README.md",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/sample-gitlab-v2/-/raw/main/README.md",
          "locator": "document.querySelector('pre').innerText",
          "required_contents": {
            "exact_match": "# Sample GitLab Project\n\nThis sample project shows how a project in GitLab looks for demonstration purposes. It contains issues, merge requests and Markdown files in many branches,\nnamed and filled with lorem ipsum.\n\nYou can look around to get an idea how to structure your project and, when done, you can safely delete this project.\n\n[Learn more about creating GitLab projects.](https://docs.gitlab.com/ee/gitlab-basics/create-project.html)\n"
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 40272,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/primer/design",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a new repository named {{repository2}} and copy the README.md file from {{repository1}}.",
    "intent": "Create a new repository named byteblaze/primer-design-v2 and copy the README.md file from primer/design.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access the README.md file of {{repository1}}, display the source code, and copy it. Then, create a new repository named {{repository2}}, access the README.md file, paste the copied source code into it, and commit the changes.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/primer/design",
      "repository1": "primer/design",
      "repository2": "byteblaze/primer-design-v2",
      "readme_repo1": "# Primer Interface Guidelines\n\nDocumentation for UI patterns and interaction guidelines.\n\n## Status\n\nThis is currently a work in progress! Follow along on our [project board](https://github.com/primer/design/projects/1).\n\n## Local development\n\n1. Clone this repo, e.g. with:\n\n   ```sh\n   git clone https://github.com/primer/design\n   ```\n\n2. In the terminal, navigate (`cd`) to the repo directory\n3. `nvm use --default` to use the correct node version.\n4. `yarn` to install dependencies\n5. `yarn start` to start the dev server\n\n## Deployment\n\nWe deploy this site using [GitHub Pages](https://pages.github.com/). Every push to a branch other than `main` will deploy to a URL unique to the preview environment. Merges to `main` will automatically deploy the site to `https://primer.github.io/design/`.\n",
      "readme_repo2_url": "__GITLAB__/byteblaze/primer-design-v2/-/raw/main/README.md",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/primer-design-v2/-/raw/main/README.md",
          "locator": "document.querySelector('pre').innerText",
          "required_contents": {
            "exact_match": "# Primer Interface Guidelines\n\nDocumentation for UI patterns and interaction guidelines.\n\n## Status\n\nThis is currently a work in progress! Follow along on our [project board](https://github.com/primer/design/projects/1).\n\n## Local development\n\n1. Clone this repo, e.g. with:\n\n   ```sh\n   git clone https://github.com/primer/design\n   ```\n\n2. In the terminal, navigate (`cd`) to the repo directory\n3. `nvm use --default` to use the correct node version.\n4. `yarn` to install dependencies\n5. `yarn start` to start the dev server\n\n## Deployment\n\nWe deploy this site using [GitHub Pages](https://pages.github.com/). Every push to a branch other than `main` will deploy to a URL unique to the preview environment. Merges to `main` will automatically deploy the site to `https://primer.github.io/design/`.\n"
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 40273,
    "sites": [
      "gitlab"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/byteblaze/empathy-prompts",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Create a new repository named {{repository2}} and copy the README.md file from {{repository1}}.",
    "intent": "Create a new repository named byteblaze/new-empathy-prompts and copy the README.md file from byteblaze/empathy-prompts.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access the README.md file of {{repository1}}, display the source code, and copy it. Then, create a new repository named {{repository2}}, access the README.md file, paste the copied source code into it, and commit the changes.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/byteblaze/empathy-prompts",
      "repository1": "byteblaze/empathy-prompts",
      "repository2": "byteblaze/new-empathy-prompts",
      "readme_repo1": "# [Empathy Prompts](https://empathyprompts.net/)\n\nPrompts to consider when making things for others to use.\n\nThis project is geared towards anyone involved with making digital products. It is my hope that this reaches both:\n\n- People who are not necessarily involved in the day-to-day part of the process, but who help shape things like budget, timeline, and scope, and\n- People who work every day to help to give these products shape and form\n\nThese prompts are intended to help build empathy, not describe any one person's experience. These prompts are <em>not</em> intended to tokenize the experience of the individuals experiencing these conditions. For further reading about disability simulations, please refer to [Job van Achterberg](https://twitter.com/detonite)'s excellent presentation, [The Imitation Game](https://noti.st/jkva/tF5o8J/slides).\n\n\n## Table of Contents\n\n1. [About this page](#about-this-page)\n1. [Contributing](#contributing)\n    1. [Suggest a prompt](#suggest-a-prompt)\n    1. [Language and terminology concerns](#language-and-terminology-concerns)\n    1. [Issues and Pull Requests](#issues-and-pull-requests)\n1. [Additional resources](#additional-resources)\n    1. [Prompt formats](#prompt-formats)\n    1. [Links](#links)\n1. [Resetting technology](#resetting-technology)\n    1. [Brightness](#brightness)\n    1. [Dyslexia simulator bookmarklet](#dyslexia-simulator-bookmarklet)\n    1. [High Contrast Mode](#high-contrast-mode)\n    1. [NoCoffee Chrome Extension](#nocoffee-chrome-extension)\n    1. [Screen magnifiers](#screen-magnifiers)\n    1. [Screen readers](#screen-readers)\n    1. [Zoomed Browser](#zoomed-browser)\n1. [Thanks](#thanks)\n1. [License](#license)\n\n\n## About this page\n\nYou're on [GitHub](https://github.com/), a service that helps people build digital things. Projects are called \"repositories\", or \"repos\" for short. Repositories are collections of files managed by [Git](https://git-scm.com/), software that helps people code and collaborate.\n\nOne file in this repo is called a Readme, which helps helps describe what the project is, why it was made, and how you can help out with it. GitHub takes the Readme for every repo and displays it on the repo's homepage for easier discovery.\n\nTo return to the prompt you were viewing, use your browser's back button.\n\n\n## Contributing\n\nIf you do not have a GitHub account, you can [contact me via email](https://github.com/ericwbailey/empathy-prompts/blob/master/AUTHORS). Please remember that requests submitted via email also need to conform to [the project's contributing guidelines](https://github.com/ericwbailey/empathy-prompts/blob/master/CONTRIBUTING.md).\n\n\n### Suggest a prompt\n\nTo suggest a prompt, please [submit a GitHub Issue](https://github.com/ericwbailey/empathy-prompts/issues) and follow the Issue template's instructions.\n\nPlease remember to:\n\n- Keep the title, description, and examples brief\n- Use simple, direct language\n- Use as little jargon as possible\n- Provide links to resources\n\nPrompts will be considered and added on a case-by-case basis. Questions and feedback will be handled in the submitted Issue.\n\n### Language and terminology concerns\n\nI'm striving to be as respectful as possible. If you feel the words or tone for one of the prompts isn't using the proper terminology, or isn't representative of the condition, please let me know either [publicly](https://github.com/ericwbailey/empathy-prompts/labels/%5BType%5D%20Terminology) or [privately](https://github.com/ericwbailey/empathy-prompts/blob/master/AUTHORS).\n\n### Issues and Pull Requests\n\nThe best way to submit Issues (problems with the project) and Pull Requests (adding features to the project, fixing problems, or improving project code) is using this project's [Issue tracker](https://github.com/ericwbailey/empathy-prompts/issues). Please make sure you [read the contributing guidelines](https://github.com/ericwbailey/empathy-prompts/blob/master/CONTRIBUTING.md) before doing so!\n\n\n## Additional resources\n\n### Prompt formats\n- [JSON](https://github.com/ericwbailey/empathy-prompts/blob/master/source/content.json)\n- [PDF](https://empathyprompts.net/static/downloads/empathy-prompt-cards.pdf)\n\n### Links\n- [30 Days of Accessibility Testing](https://dojo.ministryoftesting.com/lessons/30-days-of-accessibility-testing)\n- [Conscious Styleguide](http://consciousstyleguide.com/)\n- [Designing inclusively](https://medium.com/simple-human/designing-inclusively-5442ca2850ba)\n- [Empathy Maker](http://maya-benari.com/empathy-maker/)\n- [Highlights from Drop-in Time & Local Tech Interactions](https://storify.com/jessamyn/highlights-from-drop-in-time)\n- [Microsoft's Inclusive Design Principles and Resources](https://www.microsoft.com/en-us/design/inclusive)\n- [Writing Accessible Content](https://foxland.fi/writing-accessible-content/)\n\n\n## Resetting technology\n\nInstructions on how to reset any of the technology a prompt makes you install:\n\n### Brightness\n\n#### Mac\n\n- Use the brightness keys (`F1` and `F2`) to restore brightness to a level you find comfortable, or\n- Go to `System Preferences` > `Displays`, and drag the brightness slider to a level you find comfortable\n\n#### Windows\n\n- Select `Start` > `Settings` > `System` > `Display`, then drag the brightness slider to a level you find comfortable\n\n### Dyslexia simulator bookmarklet\n\n- Right click on the bookmarklet on your browser's bookmarks bar and choose the `Delete` option\n- You may also have to refresh the page\n\n### High Contrast Mode\n\n#### Mac\n\n- Go to `System Preferences` > `Accessibility` > `Display`, then drag the slider for `Display contrast` to `Normal`\n\n#### Windows\n\n- Use the `Left ALT` + `Left Shift` + `Print Screen` keyboard shortcut\n\n### Low Bandwidth\n\n- Close the Chrome Developer Tools\n- You may also have to refresh the page\n\n### NoCoffee Chrome Extension\n\n- To disable:\n    1. Click on the extension's icon\n    1. Choose the `Reset all` button\n    1. You may also have to refresh the page\n- To remove:\n    1. Open Chrome's Preferences\n    1. On the sidebar, select `Extensions`\n    1. Find the NoCoffee extension and either uncheck `Enabled` to disable the extension, or select the trash can icon to delete it\n    1. You may also have to refresh the page\n\n### Screen magnifiers\n\n#### Mac\n\n- Use either the keyboard shortcut (`CMD`+`OPT` `-`) or the mouse command (`CMD` + `Scroll Down`) until the screen stops shrinking\n\n#### Windows\n\n- Quit the magnifier program by pressing either `WIN` + `ESC` or select the magnifying glass icon and then select the `Close` button on the Magnifier toolbar.\n\n### Screen readers\n\n#### NVDA (Windows)\n\n- You can quit NVDA like any other Windows program, or\n- Use NVDA's keyboard shortcut: `INSERT` + `Q`\n\n#### VoiceOver (Mac)\n\n- Use the `CMD` + `F5` keyboard shortcut, or\n- Go to `System Preferences` > `Accessibility` > `VoiceOver`, then uncheck `Enable VoiceOver`\n\n### Zoomed Browser\n\n#### Mac\n\n- Use the `CMD` + `0` keyboard shortcut to restore zoom to 100%\n\n#### Windows\n\n- Use the `CTRL` + `0` keyboard shortcut to restore zoom to 100%\n\n\n## Thanks\n\n- [Wayne Elgin](https://github.com/esjay) and [Dan McLaughlin](https://github.com/danielsmc) for JavaScript help 🎉\n- [Scott Doxey](https://github.com/neogeek/) for Progressive Web App help! 🍟\n\n\n## License\n\n[MIT License](https://raw.githubusercontent.com/ericwbailey/empathy-prompts/master/LICENSE).\n",
      "readme_repo2_url": "__GITLAB__/byteblaze/new-empathy-prompts/-/raw/main/README.md",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/new-empathy-prompts/-/raw/main/README.md",
          "locator": "document.querySelector('pre').innerText",
          "required_contents": {
            "exact_match": "# [Empathy Prompts](https://empathyprompts.net/)\n\nPrompts to consider when making things for others to use.\n\nThis project is geared towards anyone involved with making digital products. It is my hope that this reaches both:\n\n- People who are not necessarily involved in the day-to-day part of the process, but who help shape things like budget, timeline, and scope, and\n- People who work every day to help to give these products shape and form\n\nThese prompts are intended to help build empathy, not describe any one person's experience. These prompts are <em>not</em> intended to tokenize the experience of the individuals experiencing these conditions. For further reading about disability simulations, please refer to [Job van Achterberg](https://twitter.com/detonite)'s excellent presentation, [The Imitation Game](https://noti.st/jkva/tF5o8J/slides).\n\n\n## Table of Contents\n\n1. [About this page](#about-this-page)\n1. [Contributing](#contributing)\n    1. [Suggest a prompt](#suggest-a-prompt)\n    1. [Language and terminology concerns](#language-and-terminology-concerns)\n    1. [Issues and Pull Requests](#issues-and-pull-requests)\n1. [Additional resources](#additional-resources)\n    1. [Prompt formats](#prompt-formats)\n    1. [Links](#links)\n1. [Resetting technology](#resetting-technology)\n    1. [Brightness](#brightness)\n    1. [Dyslexia simulator bookmarklet](#dyslexia-simulator-bookmarklet)\n    1. [High Contrast Mode](#high-contrast-mode)\n    1. [NoCoffee Chrome Extension](#nocoffee-chrome-extension)\n    1. [Screen magnifiers](#screen-magnifiers)\n    1. [Screen readers](#screen-readers)\n    1. [Zoomed Browser](#zoomed-browser)\n1. [Thanks](#thanks)\n1. [License](#license)\n\n\n## About this page\n\nYou're on [GitHub](https://github.com/), a service that helps people build digital things. Projects are called \"repositories\", or \"repos\" for short. Repositories are collections of files managed by [Git](https://git-scm.com/), software that helps people code and collaborate.\n\nOne file in this repo is called a Readme, which helps helps describe what the project is, why it was made, and how you can help out with it. GitHub takes the Readme for every repo and displays it on the repo's homepage for easier discovery.\n\nTo return to the prompt you were viewing, use your browser's back button.\n\n\n## Contributing\n\nIf you do not have a GitHub account, you can [contact me via email](https://github.com/ericwbailey/empathy-prompts/blob/master/AUTHORS). Please remember that requests submitted via email also need to conform to [the project's contributing guidelines](https://github.com/ericwbailey/empathy-prompts/blob/master/CONTRIBUTING.md).\n\n\n### Suggest a prompt\n\nTo suggest a prompt, please [submit a GitHub Issue](https://github.com/ericwbailey/empathy-prompts/issues) and follow the Issue template's instructions.\n\nPlease remember to:\n\n- Keep the title, description, and examples brief\n- Use simple, direct language\n- Use as little jargon as possible\n- Provide links to resources\n\nPrompts will be considered and added on a case-by-case basis. Questions and feedback will be handled in the submitted Issue.\n\n### Language and terminology concerns\n\nI'm striving to be as respectful as possible. If you feel the words or tone for one of the prompts isn't using the proper terminology, or isn't representative of the condition, please let me know either [publicly](https://github.com/ericwbailey/empathy-prompts/labels/%5BType%5D%20Terminology) or [privately](https://github.com/ericwbailey/empathy-prompts/blob/master/AUTHORS).\n\n### Issues and Pull Requests\n\nThe best way to submit Issues (problems with the project) and Pull Requests (adding features to the project, fixing problems, or improving project code) is using this project's [Issue tracker](https://github.com/ericwbailey/empathy-prompts/issues). Please make sure you [read the contributing guidelines](https://github.com/ericwbailey/empathy-prompts/blob/master/CONTRIBUTING.md) before doing so!\n\n\n## Additional resources\n\n### Prompt formats\n- [JSON](https://github.com/ericwbailey/empathy-prompts/blob/master/source/content.json)\n- [PDF](https://empathyprompts.net/static/downloads/empathy-prompt-cards.pdf)\n\n### Links\n- [30 Days of Accessibility Testing](https://dojo.ministryoftesting.com/lessons/30-days-of-accessibility-testing)\n- [Conscious Styleguide](http://consciousstyleguide.com/)\n- [Designing inclusively](https://medium.com/simple-human/designing-inclusively-5442ca2850ba)\n- [Empathy Maker](http://maya-benari.com/empathy-maker/)\n- [Highlights from Drop-in Time & Local Tech Interactions](https://storify.com/jessamyn/highlights-from-drop-in-time)\n- [Microsoft's Inclusive Design Principles and Resources](https://www.microsoft.com/en-us/design/inclusive)\n- [Writing Accessible Content](https://foxland.fi/writing-accessible-content/)\n\n\n## Resetting technology\n\nInstructions on how to reset any of the technology a prompt makes you install:\n\n### Brightness\n\n#### Mac\n\n- Use the brightness keys (`F1` and `F2`) to restore brightness to a level you find comfortable, or\n- Go to `System Preferences` > `Displays`, and drag the brightness slider to a level you find comfortable\n\n#### Windows\n\n- Select `Start` > `Settings` > `System` > `Display`, then drag the brightness slider to a level you find comfortable\n\n### Dyslexia simulator bookmarklet\n\n- Right click on the bookmarklet on your browser's bookmarks bar and choose the `Delete` option\n- You may also have to refresh the page\n\n### High Contrast Mode\n\n#### Mac\n\n- Go to `System Preferences` > `Accessibility` > `Display`, then drag the slider for `Display contrast` to `Normal`\n\n#### Windows\n\n- Use the `Left ALT` + `Left Shift` + `Print Screen` keyboard shortcut\n\n### Low Bandwidth\n\n- Close the Chrome Developer Tools\n- You may also have to refresh the page\n\n### NoCoffee Chrome Extension\n\n- To disable:\n    1. Click on the extension's icon\n    1. Choose the `Reset all` button\n    1. You may also have to refresh the page\n- To remove:\n    1. Open Chrome's Preferences\n    1. On the sidebar, select `Extensions`\n    1. Find the NoCoffee extension and either uncheck `Enabled` to disable the extension, or select the trash can icon to delete it\n    1. You may also have to refresh the page\n\n### Screen magnifiers\n\n#### Mac\n\n- Use either the keyboard shortcut (`CMD`+`OPT` `-`) or the mouse command (`CMD` + `Scroll Down`) until the screen stops shrinking\n\n#### Windows\n\n- Quit the magnifier program by pressing either `WIN` + `ESC` or select the magnifying glass icon and then select the `Close` button on the Magnifier toolbar.\n\n### Screen readers\n\n#### NVDA (Windows)\n\n- You can quit NVDA like any other Windows program, or\n- Use NVDA's keyboard shortcut: `INSERT` + `Q`\n\n#### VoiceOver (Mac)\n\n- Use the `CMD` + `F5` keyboard shortcut, or\n- Go to `System Preferences` > `Accessibility` > `VoiceOver`, then uncheck `Enable VoiceOver`\n\n### Zoomed Browser\n\n#### Mac\n\n- Use the `CMD` + `0` keyboard shortcut to restore zoom to 100%\n\n#### Windows\n\n- Use the `CTRL` + `0` keyboard shortcut to restore zoom to 100%\n\n\n## Thanks\n\n- [Wayne Elgin](https://github.com/esjay) and [Dan McLaughlin](https://github.com/danielsmc) for JavaScript help 🎉\n- [Scott Doxey](https://github.com/neogeek/) for Progressive Web App help! 🍟\n\n\n## License\n\n[MIT License](https://raw.githubusercontent.com/ericwbailey/empathy-prompts/master/LICENSE).\n"
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50000,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "intent": "Sort all the repositories on GitLab by \"Updated date\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects",
      "category": "Updated date",
      "forum": "deeplearning",
      "contents": "solarized-prism-theme: 7, gimmiethat.space: 3, dotfiles: 553, timeit: 22, cloud-to-butt: 29",
      "checkpoint1": "solarized-prism-theme, gimmiethat.space, dotfiles, timeit, cloud-to-butt",
      "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "solarized-prism-theme: 7, gimmiethat.space: 3, dotfiles: 553, timeit: 22, cloud-to-butt: 29"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50001,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "intent": "Sort all the repositories on GitLab by \"Name\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects",
      "category": "Name",
      "forum": "deeplearning",
      "contents": "2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2320, abisubramanya27: 17 |OR| 2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2,320, abisubramanya27: 17",
      "checkpoint1": "2019-nCov, a11y-syntax-highlighting, a11y-webring.club, a11yproject.com, abisubramanya27",
      "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2320, abisubramanya27: 17 |OR| 2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2,320, abisubramanya27: 17"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50002,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__GITLAB__/explore/projects",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "intent": "Sort all the repositories on GitLab by \"Most stars\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__GITLAB__/explore/projects",
      "category": "Most stars",
      "forum": "deeplearning",
      "contents": "AndroidSlidingUpPanel: 361, create-react-app: 2800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1097 |OR| AndroidSlidingUpPanel: 361, create-react-app: 2,800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1,097",
      "checkpoint1": "AndroidSlidingUpPanel, create-react-app, ffmpeg-python, PHP_XLSXWriter, AndroidAsync",
      "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__inner').outerText",
          "required_contents": {
            "must_include": [
              "AndroidSlidingUpPanel: 361, create-react-app: 2800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1097 |OR| AndroidSlidingUpPanel: 361, create-react-app: 2,800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1,097"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50010,
    "sites": [
      "reddit",
      "gitlab"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "intent": "Find user Akilesh Kannan's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Akilesh Kannan's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/",
      "user": "Akilesh Kannan",
      "forum": "deeplearning",
      "content": "empathy-prompts: __GITLAB__/aklsh/empathy-prompts, CacheEval: __GITLAB__/aklsh/CacheEval, nvidia-patch: __GITLAB__/aklsh/nvidia-patch, SimCache: __GITLAB__/aklsh/SimCache, viewgrades-scraper: __GITLAB__/aklsh/viewgrades-scraper, dots: __GITLAB__/aklsh/dots",
      "checkpoint1": "empathy-prompts, CacheEval, nvidia-patch, SimCache, viewgrades-scraper, dots",
      "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "user Akilesh Kannan's personal projects"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "empathy-prompts: __GITLAB__/aklsh/empathy-prompts, CacheEval: __GITLAB__/aklsh/CacheEval, nvidia-patch: __GITLAB__/aklsh/nvidia-patch, SimCache: __GITLAB__/aklsh/SimCache, viewgrades-scraper: __GITLAB__/aklsh/viewgrades-scraper, dots: __GITLAB__/aklsh/dots"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50011,
    "sites": [
      "reddit",
      "gitlab"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "intent": "Find user Meta's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Meta's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/",
      "user": "Meta",
      "forum": "deeplearning",
      "content": "create-react-app: __GITLAB__/facebook/create-react-app, buck: __GITLAB__/facebook/buck",
      "checkpoint1": "create-react-app, buck",
      "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "user Meta's personal projects"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "create-react-app: __GITLAB__/facebook/create-react-app, buck: __GITLAB__/facebook/buck"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50012,
    "sites": [
      "reddit",
      "gitlab"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "intent": "Find user First Contributions's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser First Contributions's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/",
      "user": "First Contributions",
      "forum": "deeplearning",
      "content": "first-contributions: __GITLAB__/firstcontributions/first-contributions, frontend: __GITLAB__/firstcontributions/frontend",
      "checkpoint1": "first-contributions, frontend",
      "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "user First Contributions's personal projects"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "first-contributions: __GITLAB__/firstcontributions/first-contributions, frontend: __GITLAB__/firstcontributions/frontend"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50013,
    "sites": [
      "reddit",
      "gitlab"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "intent": "Find user Roshan Jossy's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Roshan Jossy's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/",
      "user": "Roshan Jossy",
      "forum": "deeplearning",
      "content": "timeit: __GITLAB__/Roshanjossey/timeit, dot-files: __GITLAB__/Roshanjossey/dot-files, ultimate-voting-app: __GITLAB__/Roshanjossey/ultimate-voting-app",
      "checkpoint1": "timeit, dot-files, ultimate-voting-app",
      "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "user Roshan Jossy's personal projects"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "timeit: __GITLAB__/Roshanjossey/timeit, dot-files: __GITLAB__/Roshanjossey/dot-files, ultimate-voting-app: __GITLAB__/Roshanjossey/ultimate-voting-app"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50014,
    "sites": [
      "reddit",
      "gitlab"
    ],
    "start_url": "__REDDIT__/",
    "start_url_lite": "__REDDIT__/",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "intent": "Find user Convex Eggtart's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Convex Eggtart's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
    "instantiation_dict": {
      "start_url": "__REDDIT__/",
      "start_url_lite": "__REDDIT__/",
      "user": "Convex Eggtart",
      "forum": "deeplearning",
      "content": "chatgpt: __GITLAB__/convexegg/chatgpt, super_awesome_robot: __GITLAB__/convexegg/super_awesome_robot |OR| Chatgpt: __GITLAB__/convexegg/chatgpt, Super_Awesome_Robot: __GITLAB__/convexegg/super_awesome_robot",
      "checkpoint1": "Chatgpt, Super_Awesome_Robot",
      "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/deeplearning",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "user Convex Eggtart's personal projects"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "chatgpt: __GITLAB__/convexegg/chatgpt, super_awesome_robot: __GITLAB__/convexegg/super_awesome_robot |OR| Chatgpt: __GITLAB__/convexegg/chatgpt, Super_Awesome_Robot: __GITLAB__/convexegg/super_awesome_robot"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50020,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/samsung-galaxy-note-9-128gb-lavender-purple-unlocked-renewed.html",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "intent": "Please compare the following two items by their SKU codes: B08N3J7GJ8 and B07H8PXT7K, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum gadgets on Reddit.\n\nTitle should be:\nComparison of item sku B08N3J7GJ8 and item sku B07H8PXT7K\n\nBody should follow this format:\n\nItem1: B08N3J7GJ8, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B07H8PXT7K, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/samsung-galaxy-note-9-128gb-lavender-purple-unlocked-renewed.html",
      "item1": "B08N3J7GJ8",
      "item2": "B07H8PXT7K",
      "forum": "gadgets",
      "price1": "$590.01",
      "price2": "$277.78",
      "review_score1": "67%",
      "review_score2": "50%"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/gadgets",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Item1: B08N3J7GJ8, Price1: $590.01, Positive reviews percentage1: 67%, Item2: B07H8PXT7K, Price2: $277.78, Positive reviews percentage2: 50%"
            ]
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "must_include": [
              "Comparison of item sku B08N3J7GJ8 and item sku B07H8PXT7K"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50021,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/minnetonka-tamson-men-s-suede-slippers.html",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "intent": "Please compare the following two items by their SKU codes: B0976WN9JY and B07VPGT4YR, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum BuyItForLife on Reddit.\n\nTitle should be:\nComparison of item sku B0976WN9JY and item sku B07VPGT4YR\n\nBody should follow this format:\n\nItem1: B0976WN9JY, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B07VPGT4YR, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/minnetonka-tamson-men-s-suede-slippers.html",
      "item1": "B0976WN9JY",
      "item2": "B07VPGT4YR",
      "forum": "BuyItForLife",
      "price1": "$74.95",
      "price2": "$24.99",
      "review_score1": "60%",
      "review_score2": "75%"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/BuyItForLife",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Item1: B0976WN9JY, Price1: $74.95, Positive reviews percentage1: 60%, Item2: B07VPGT4YR, Price2: $24.99, Positive reviews percentage2: 75%"
            ]
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "must_include": [
              "Comparison of item sku B0976WN9JY and item sku B07VPGT4YR"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50022,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B00W9EPK3W",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "intent": "Please compare the following two items by their SKU codes: B00W9EPK3W and B091FT6ZJC, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum Art on Reddit.\n\nTitle should be:\nComparison of item sku B00W9EPK3W and item sku B091FT6ZJC\n\nBody should follow this format:\n\nItem1: B00W9EPK3W, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B091FT6ZJC, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B00W9EPK3W",
      "item1": "B00W9EPK3W",
      "item2": "B091FT6ZJC",
      "forum": "Art",
      "price1": "$14.99",
      "price2": "$15.99",
      "review_score1": "92%",
      "review_score2": "80%"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/Art",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Item1: B00W9EPK3W, Price1: $14.99, Positive reviews percentage1: 92%, Item2: B091FT6ZJC, Price2: $15.99, Positive reviews percentage2: 80%"
            ]
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "must_include": [
              "Comparison of item sku B00W9EPK3W and item sku B091FT6ZJC"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50023,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/vizio-d40f-g9-40-inch-1080p-full-array-led-smartcast-hdtv-renewed.html",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "intent": "Please compare the following two items by their SKU codes: B07M8RM5HQ and B0773WWKHH, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum television on Reddit.\n\nTitle should be:\nComparison of item sku B07M8RM5HQ and item sku B0773WWKHH\n\nBody should follow this format:\n\nItem1: B07M8RM5HQ, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B0773WWKHH, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/vizio-d40f-g9-40-inch-1080p-full-array-led-smartcast-hdtv-renewed.html",
      "item1": "B07M8RM5HQ",
      "item2": "B0773WWKHH",
      "forum": "television",
      "price1": "$308.95",
      "price2": "$299.99",
      "review_score1": "50%",
      "review_score2": "33%"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/television",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Item1: B07M8RM5HQ, Price1: $308.95, Positive reviews percentage1: 50%, Item2: B0773WWKHH, Price2: $299.99, Positive reviews percentage2: 33%"
            ]
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "must_include": [
              "Comparison of item sku B07M8RM5HQ and item sku B0773WWKHH"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50024,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B097F5LT5K",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "intent": "Please compare the following two items by their SKU codes: B097F5LT5K and B089ZPBQY3, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum headphones on Reddit.\n\nTitle should be:\nComparison of item sku B097F5LT5K and item sku B089ZPBQY3\n\nBody should follow this format:\n\nItem1: B097F5LT5K, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B089ZPBQY3, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B097F5LT5K",
      "item1": "B097F5LT5K",
      "item2": "B089ZPBQY3",
      "forum": "headphones",
      "price1": "$29.95",
      "price2": "$54.99",
      "review_score1": "92%",
      "review_score2": "100%"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/headphones",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Item1: B097F5LT5K, Price1: $29.95, Positive reviews percentage1: 92%, Item2: B089ZPBQY3, Price2: $54.99, Positive reviews percentage2: 100%"
            ]
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "must_include": [
              "Comparison of item sku B097F5LT5K and item sku B089ZPBQY3"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50030,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "intent": "Find the most expensive headphone and post it on the forum Music with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive headphone on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find the specified item on the specified forum and post it to Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__REDDIT__/f/science",
      "price": "most expensive",
      "forum": "Music",
      "item": "headphone",
      "link": "__SHOPPING__/hedd-phone-one-headphone.html"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/Music",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "One Stop Market Info"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "This is the most expensive headphone on One Stop Market. The link is __SHOPPING__/hedd-phone-one-headphone.html."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED",
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/hedd-phone-one-headphone.html"
    }
  },
  {
    "task_id": 50031,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "intent": "Find the cheapest Case for iPhone and post it on the forum iphone with the following messages. Title: One Stop Market Info, Body: 'This is the cheapest Case for iPhone on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find the specified item on the specified forum and post it to Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__REDDIT__/f/science",
      "price": "cheapest",
      "forum": "iphone",
      "item": "Case for iPhone",
      "link": "__SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/iphone",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "One Stop Market Info"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "This is the cheapest Case for iPhone on One Stop Market. The link is __SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED",
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html"
    }
  },
  {
    "task_id": 50032,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "intent": "Find the most expensive Record Player and post it on the forum Music with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive Record Player on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find the specified item on the specified forum and post it to Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__REDDIT__/f/science",
      "price": "most expensive",
      "forum": "Music",
      "item": "Record Player",
      "link": "__SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/Music",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "One Stop Market Info"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "This is the most expensive Record Player on One Stop Market. The link is __SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED",
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html"
    }
  },
  {
    "task_id": 50033,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "intent": "Find the most expensive Wall Mirror and post it on the forum DIY with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive Wall Mirror on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find the specified item on the specified forum and post it to Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__REDDIT__/f/science",
      "price": "most expensive",
      "forum": "DIY",
      "item": "Wall Mirror",
      "link": "__SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/DIY",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "One Stop Market Info"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "This is the most expensive Wall Mirror on One Stop Market. The link is __SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED",
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html"
    }
  },
  {
    "task_id": 50034,
    "sites": [
      "reddit",
      "shopping"
    ],
    "start_url": "__SHOPPING__",
    "start_url_lite": "__REDDIT__/f/science",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "intent": "Find the cheapest Smartwatch and post it on the forum gadgets with the following messages. Title: One Stop Market Info, Body: 'This is the cheapest Smartwatch on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Find the specified item on the specified forum and post it to Reddit.",
    "instantiation_dict": {
      "start_url": "__SHOPPING__",
      "start_url_lite": "__REDDIT__/f/science",
      "price": "cheapest",
      "forum": "gadgets",
      "item": "Smartwatch",
      "link": "__SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/gadgets",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "One Stop Market Info"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "This is the cheapest Smartwatch on One Stop Market. The link is __SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED",
      "string_note": "",
      "reference_answer_raw_annotation": "__SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html"
    }
  },
  {
    "task_id": 50040,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List the common types of skills in Tumbling, which is written in the Gymnastics page on Wikipedia. Post them to a related forum on Reddit. Follow the instructions below when posting:\nTitle: common types of skills in Tumbling, Body: {skill1, skill2, skill3, ...}.",
    "intent": "List the common types of skills in Tumbling, which is written in the Gymnastics page on Wikipedia. Post them to a related forum on Reddit. Follow the instructions below when posting:\nTitle: common types of skills in Tumbling, Body: {skill1, skill2, skill3, ...}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, open the Wikipedia Gymnastics page and list the skills related to Tumbling. Then, post it to a related forum on Reddit.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Gymnastics",
      "forum": "sports",
      "contents": "Round-off, End Skill, Flick, Whip, Double Somersault, Triple Somersault, Twisting Somersault, Combination Somersault, Transition Skill"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/sports",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "common types of skills in Tumbling"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Round-off, End Skill, Flick, Whip, Double Somersault, Triple Somersault, Twisting Somersault, Combination Somersault, Transition Skill"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50050,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
    "intent": "List all the dynasties or kingdoms under the Medieval period in the Sasanian Empire page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {dynasties or kingdoms under the Medieval period in Sasanian Empire}, Body: {kingdom1}, {kingdom2}, {kingdom3}, ...}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "element": "dynasties or kingdoms under the Medieval period",
      "region": "Sasanian Empire",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Sasanian_Empire",
      "answer": "kingdom",
      "forum": "history",
      "contents": "Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, Dabuyids, Bavandids, Masmughans of Damavand, Baduspanids, Justanids, Alid dynasties, Tahirid dynasty, Samanid Empire, Saffarid dynasty, Ghurid dynasty, Sajid dynasty, Sallarid dynasty, Ziyarid dynasty, Ilyasids, Buyid dynasty, Rawadid dynasty, Hasanwayhids, Ghaznavid dynasty, Annazids, Kakuyids, Nasrid dynasty, Shabankara, Seljuk Empire, Khwarazmian dynasty, Eldiguzids, Atabegs of Yazd, Salghurids, Hazaraspids, Pishkinid dynasty, Khorshidi dynasty, Qutlugh-Khanids, Mihrabanids, Kurt dynasty, Ilkhanate Empire, Chobanid dynasty, Muzaffarid dynasty, Jalayirid Sultanate, Sarbadars, Injuids, Afrasiyab dynasty, Mar'ashis, Timurid Empire, Kar-Kiya dynasty, Qara Qoyunlu, Aq Qoyunlu"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/history",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "dynasties or kingdoms under the Medieval period in Sasanian Empire"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, Dabuyids, Bavandids, Masmughans of Damavand, Baduspanids, Justanids, Alid dynasties, Tahirid dynasty, Samanid Empire, Saffarid dynasty, Ghurid dynasty, Sajid dynasty, Sallarid dynasty, Ziyarid dynasty, Ilyasids, Buyid dynasty, Rawadid dynasty, Hasanwayhids, Ghaznavid dynasty, Annazids, Kakuyids, Nasrid dynasty, Shabankara, Seljuk Empire, Khwarazmian dynasty, Eldiguzids, Atabegs of Yazd, Salghurids, Hazaraspids, Pishkinid dynasty, Khorshidi dynasty, Qutlugh-Khanids, Mihrabanids, Kurt dynasty, Ilkhanate Empire, Chobanid dynasty, Muzaffarid dynasty, Jalayirid Sultanate, Sarbadars, Injuids, Afrasiyab dynasty, Mar'ashis, Timurid Empire, Kar-Kiya dynasty, Qara Qoyunlu, Aq Qoyunlu"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50051,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
    "intent": "List all the dynasties, state, or emirates of the Arabian Peninsula in the Umayyad Caliphate page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {dynasties, state, or emirates of the Arabian Peninsula in Umayyad Caliphate}, Body: {dynasties1}, {dynasties2}, {dynasties3}, ...}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "element": "dynasties, state, or emirates of the Arabian Peninsula",
      "region": "Umayyad Caliphate",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Umayyad_Caliphate",
      "answer": "dynasties",
      "forum": "history",
      "contents": "Imamate of Oman, Ziyadids, Yufirids, Ukhaidhirds, Rassids, Qarmatians, Wajihids, Sharifate of Mecca, Sulayhids, Sulaymanids, Uyunids, Zurayids, Nabhanids, Mahdids, Rasulids, Usfurids, Jarwanids, Kathirids, Tahirids, Jabrids, Qasimids, Ya'arubids, Upper Yafa, Muscat and Oman, Rashidids, Qu'aitids, Emirate of Beihan, Idrisids, Mutawakkilite Kingdom"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/history",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "dynasties, state, or emirates of the Arabian Peninsula in Umayyad Caliphate"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Imamate of Oman, Ziyadids, Yufirids, Ukhaidhirds, Rassids, Qarmatians, Wajihids, Sharifate of Mecca, Sulayhids, Sulaymanids, Uyunids, Zurayids, Nabhanids, Mahdids, Rasulids, Usfurids, Jarwanids, Kathirids, Tahirids, Jabrids, Qasimids, Ya'arubids, Upper Yafa, Muscat and Oman, Rashidids, Qu'aitids, Emirate of Beihan, Idrisids, Mutawakkilite Kingdom"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50052,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
    "intent": "List all the Japanese historical periods in the Japan page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {Japanese historical periods in Japan}, Body: {period1}, {period2}, {period3}, ...}.",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "element": "Japanese historical periods",
      "region": "Japan",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/History_of_Japan",
      "answer": "period",
      "forum": "history",
      "contents": "Paleolithic, Jōmon, Yayoi, Kofun, Asuka, Nara, Heian, Kamakura, Kenmu Restoration, Muromachi, Azuchi–Momoyama, Edo, Meiji, Taishō, Shōwa, Heisei, Reiwa"
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/history",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "Japanese historical periods in Japan"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Paleolithic, Jōmon, Yayoi, Kofun, Asuka, Nara, Heian, Kamakura, Kenmu Restoration, Muromachi, Azuchi–Momoyama, Edo, Meiji, Taishō, Shōwa, Heisei, Reiwa"
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50060,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
    "intent": "Take the explanation on CAD in the Electronics page on Wikipedia and post it to the forum technology. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: CAD of Electronics, Body: {the explanation of Electronics}",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Electronics",
      "topic": "Electronics",
      "section": "CAD",
      "forum": "technology",
      "gt_sentence": "Today's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others."
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/technology",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "CAD of Electronics"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Today's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50061,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
    "intent": "Take the explanation on Piezo motors in the Robotics page on Wikipedia and post it to the forum technology. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: Piezo motors of Robotics, Body: {the explanation of Robotics}",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Robotics",
      "topic": "Robotics",
      "section": "Piezo motors",
      "forum": "technology",
      "gt_sentence": "Recent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line. Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size. These motors are already available commercially, and being used on some robots."
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/technology",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "Piezo motors of Robotics"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Recent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line. Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size. These motors are already available commercially, and being used on some robots."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50062,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
    "intent": "Take the explanation on Batting and baserunning in the Baseball page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: Batting and baserunning of Baseball, Body: {the explanation of Baseball}",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Baseball",
      "topic": "Baseball",
      "section": "Batting and baserunning",
      "forum": "sports",
      "gt_sentence": "Several basic offensive tactics come into play with a runner on first base, including the fundamental choice of whether to attempt a steal of second base. The hit and run is sometimes employed, with a skillful contact hitter, the runner takes off with the pitch, drawing the shortstop or second baseman over to second base, creating a gap in the infield for the batter to poke the ball through. The sacrifice bunt, calls for the batter to focus on making soft contact with the ball, so that it rolls a short distance into the infield, allowing the runner to advance into scoring position as the batter is thrown out at first. A batter, particularly one who is a fast runner, may also attempt to bunt for a hit. A sacrifice bunt employed with a runner on third base, aimed at bringing that runner home, is known as a squeeze play. With a runner on third and fewer than two outs, a batter may instead concentrate on hitting a fly ball that, even if it is caught, will be deep enough to allow the runner to tag up and score—a successful batter, in this case, gets credit for a sacrifice fly. In order to increase the chance of advancing a batter to first base via a walk, the manager will sometimes signal a batter who is ahead in the count (i.e., has more balls than strikes) to take, or not swing at, the next pitch. The batter's potential reward of reaching base (via a walk) exceeds the disadvantage if the next pitch is a strike."
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/sports",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "Batting and baserunning of Baseball"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "Several basic offensive tactics come into play with a runner on first base, including the fundamental choice of whether to attempt a steal of second base. The hit and run is sometimes employed, with a skillful contact hitter, the runner takes off with the pitch, drawing the shortstop or second baseman over to second base, creating a gap in the infield for the batter to poke the ball through. The sacrifice bunt, calls for the batter to focus on making soft contact with the ball, so that it rolls a short distance into the infield, allowing the runner to advance into scoring position as the batter is thrown out at first. A batter, particularly one who is a fast runner, may also attempt to bunt for a hit. A sacrifice bunt employed with a runner on third base, aimed at bringing that runner home, is known as a squeeze play. With a runner on third and fewer than two outs, a batter may instead concentrate on hitting a fly ball that, even if it is caught, will be deep enough to allow the runner to tag up and score—a successful batter, in this case, gets credit for a sacrifice fly. In order to increase the chance of advancing a batter to first base via a walk, the manager will sometimes signal a batter who is ahead in the count (i.e., has more balls than strikes) to take, or not swing at, the next pitch. The batter's potential reward of reaching base (via a walk) exceeds the disadvantage if the next pitch is a strike."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50063,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
    "intent": "Take the explanation on World cricket in the 20th century in the Cricket page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: World cricket in the 20th century of Cricket, Body: {the explanation of Cricket}",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Cricket",
      "topic": "Cricket",
      "section": "World cricket in the 20th century",
      "forum": "sports",
      "gt_sentence": "The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott."
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/sports",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "World cricket in the 20th century of Cricket"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50064,
    "sites": [
      "reddit",
      "wikipedia"
    ],
    "start_url": "__REDDIT__",
    "start_url_lite": "",
    "storage_state": "./.auth/reddit_state.json",
    "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
    "intent": "Take the explanation on winter game in the Olympic page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: winter game of Olympic, Body: {the explanation of Olympic}",
    "required_obs": "any",
    "required_wait": true,
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
    "instantiation_dict": {
      "start_url": "__REDDIT__",
      "start_url_lite": "",
      "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Olympic_Games",
      "topic": "Olympic",
      "section": "winter game",
      "forum": "sports",
      "gt_sentence": "The Winter Olympics was created to feature snow and ice sports that were logistically impossible to hold during the Summer Games. Figure skating (in 1908 and 1920) and ice hockey (in 1920) were featured as Olympic events at the Summer Olympics. The IOC desired to expand this list of sports to encompass other winter activities. At the 1921 Olympic Congress in Lausanne, it was decided to hold a winter version of the Olympic Games. A winter sports week (it was actually 11 days) was held in 1924 in Chamonix, France, in connection with the Paris Games held three months later; this event became the first Winter Olympic Games. Although it was intended that the same country host both the Winter and Summer Games in a given year, this idea was quickly abandoned. The IOC mandated that the Winter Games be celebrated every four years in the same year as their summer counterpart. This tradition was upheld through the 1992 Games in Albertville, France; after that, beginning with the 1994 Games, the Winter Olympics were held every four years, two years after each Summer Olympics."
    },
    "eval": {
      "eval_types": [
        "url_match",
        "program_html"
      ],
      "reference_answers": null,
      "reference_url": "__REDDIT__/f/sports",
      "program_html": [
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__title').outerText",
          "required_contents": {
            "exact_match": "winter game of Olympic"
          }
        },
        {
          "url": "func:reddit_get_post_url('__last_url__')",
          "locator": "document.querySelector('.submission__body').outerText",
          "required_contents": {
            "must_include": [
              "The Winter Olympics was created to feature snow and ice sports that were logistically impossible to hold during the Summer Games. Figure skating (in 1908 and 1920) and ice hockey (in 1920) were featured as Olympic events at the Summer Olympics. The IOC desired to expand this list of sports to encompass other winter activities. At the 1921 Olympic Congress in Lausanne, it was decided to hold a winter version of the Olympic Games. A winter sports week (it was actually 11 days) was held in 1924 in Chamonix, France, in connection with the Paris Games held three months later; this event became the first Winter Olympic Games. Although it was intended that the same country host both the Winter and Summer Games in a given year, this idea was quickly abandoned. The IOC mandated that the Winter Games be celebrated every four years in the same year as their summer counterpart. This tradition was upheld through the 1992 Games in Albertville, France; after that, beginning with the 1994 Games, the Winter Olympics were held every four years, two years after each Summer Olympics."
            ]
          }
        }
      ],
      "url_note": "GOLD in PRED"
    }
  },
  {
    "task_id": 50070,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/toothbrushes-accessories.html?product_list_order=price",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Beauty & Personal Care > Oral Care > Toothbrushes & Accessories\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"beauty_personal_care_toothbrushes.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/toothbrushes-accessories.html?product_list_order=price",
      "csv_file_name": "beauty_personal_care_toothbrushes.csv",
      "category": "Beauty & Personal Care > Oral Care > Toothbrushes & Accessories",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09Q8Z9B2M\",\"$0.01\",\"\",\"B09Q8Z9B2M\"\n\"B09QCXXN5M\",\"$0.01\",\"\",\"B09QCXXN5M\"\n\"B09NXQMFGK\",\"$0.10\",\"753014879611\",\"B09NXQMFGK\"\n\"B09MH2BQ4Z\",\"$0.49\",\"\",\"B09MHF3YWQ\"\n\"B09P1DSHYS\",\"$0.49\",\"\",\"B09P1DSHYS\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/beauty_personal_care_toothbrushes.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09Q8Z9B2M\",\"$0.01\",\"\",\"B09Q8Z9B2M\"\n\"B09QCXXN5M\",\"$0.01\",\"\",\"B09QCXXN5M\"\n\"B09NXQMFGK\",\"$0.10\",\"753014879611\",\"B09NXQMFGK\"\n\"B09MH2BQ4Z\",\"$0.49\",\"\",\"B09MHF3YWQ\"\n\"B09P1DSHYS\",\"$0.49\",\"\",\"B09P1DSHYS\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50071,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Clothing, Shoes & Jewelry > Men > Shoes\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"men_shoes.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
      "csv_file_name": "men_shoes.csv",
      "category": "Clothing, Shoes & Jewelry > Men > Shoes",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09J4J94N3\",\"$1.25\",\"\",\"B09J4HL38Z\"\n\"B00AOQ6XRE\",\"$1.47\",\"\",\"B00DOL3PJA\"\n\"B01J4MM3KO\",\"$1.71\",\"\",\"B01J4MM3KO\"\n\"B08SXRCXBM\",\"$2.36\",\"\",\"B08SXRCXBM\"\n\"B09J2GM8CT\",\"$2.66\",\"\",\"B09J2FYGTB\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/men_shoes.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09J4J94N3\",\"$1.25\",\"\",\"B09J4HL38Z\"\n\"B00AOQ6XRE\",\"$1.47\",\"\",\"B00DOL3PJA\"\n\"B01J4MM3KO\",\"$1.71\",\"\",\"B01J4MM3KO\"\n\"B08SXRCXBM\",\"$2.36\",\"\",\"B08SXRCXBM\"\n\"B09J2GM8CT\",\"$2.66\",\"\",\"B09J2FYGTB\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50072,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/office-products/office-furniture-lighting/chairs-sofas.html?product_list_order=price",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Office Products > Office Furniture & Lighting > Chairs & Sofas\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"office_furniture_chairs.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/office-products/office-furniture-lighting/chairs-sofas.html?product_list_order=price",
      "csv_file_name": "office_furniture_chairs.csv",
      "category": "Office Products > Office Furniture & Lighting > Chairs & Sofas",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07ZNNJW9S\",\"$25.21\",\"\",\"\"\n\"B09DPT467Z\",\"$36.99\",\"\",\"\"\n\"B09687YJB7\",\"$37.18\",\"\",\"\"\n\"B07XWYFKRH\",\"$37.45\",\"\",\"\"\n\"B07D9GR9KH\",\"$48.82\",\"\",\"\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/office_furniture_chairs.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07ZNNJW9S\",\"$25.21\",\"\",\"\"\n\"B09DPT467Z\",\"$36.99\",\"\",\"\"\n\"B09687YJB7\",\"$37.18\",\"\",\"\"\n\"B07XWYFKRH\",\"$37.45\",\"\",\"\"\n\"B07D9GR9KH\",\"$48.82\",\"\",\"\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50073,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/electronics/home-audio/speakers.html?product_list_order=price",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Electronics > Home Audio > Speakers\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"home_audio_speakers.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/electronics/home-audio/speakers.html?product_list_order=price",
      "csv_file_name": "home_audio_speakers.csv",
      "category": "Electronics > Home Audio > Speakers",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07QF5YH5D\",\"$5.83\",\"\",\"\"\n\"B0051JS746\",\"$5.84\",\"\",\"\"\n\"B015D7FN1K\",\"$5.99\",\"\",\"\"\n\"B096L1MT9Y\",\"$6.28\",\"\",\"\"\n\"B01CGWXHLI\",\"$6.62\",\"\",\"\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/home_audio_speakers.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07QF5YH5D\",\"$5.83\",\"\",\"\"\n\"B0051JS746\",\"$5.84\",\"\",\"\"\n\"B015D7FN1K\",\"$5.99\",\"\",\"\"\n\"B096L1MT9Y\",\"$6.28\",\"\",\"\"\n\"B01CGWXHLI\",\"$6.62\",\"\",\"\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50074,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/video-games/pc/virtual-reality.html?product_list_order=price",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Video Games > PC > Virtual Reality\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"pc_virtual_reality.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/video-games/pc/virtual-reality.html?product_list_order=price",
      "csv_file_name": "pc_virtual_reality.csv",
      "category": "Video Games > PC > Virtual Reality",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B099RTD42D\",\"$2.39\",\"\",\"\"\n\"B09165PG3J\",\"$7.08\",\"\",\"\"\n\"B08K2TS1P6\",\"$7.99\",\"\",\"\"\n\"B09KN69C4Q\",\"$9.99\",\"\",\"\"\n\"B08RN2KB1L\",\"$12.74\",\"\",\"\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/pc_virtual_reality.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B099RTD42D\",\"$2.39\",\"\",\"\"\n\"B09165PG3J\",\"$7.08\",\"\",\"\"\n\"B08K2TS1P6\",\"$7.99\",\"\",\"\"\n\"B09KN69C4Q\",\"$9.99\",\"\",\"\"\n\"B08RN2KB1L\",\"$12.74\",\"\",\"\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50080,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/beauty-personal-care/salon-spa-equipment.html?price=1100-1200",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather all items from OneStopShop that are in the \"Beauty & Personal Care > Salon & Spa Equipment\" category and have a price between $1,100.00 to $1,199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"beauty_personal_care_salon_spa_equipment_1100_1200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/beauty-personal-care/salon-spa-equipment.html?price=1100-1200",
      "csv_file_name": "beauty_personal_care_salon_spa_equipment_1100_1200.csv",
      "category": "Beauty & Personal Care > Salon & Spa Equipment",
      "price_l": "$1,100.00",
      "price_r": "$1,199.99",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09NKFNG45\",\"$1,146.03\",\"\",\"B09NKFNG45\"\n\"B08RY69JS1\",\"$1,160.83\",\"\",\"\"\n\"B083ZFXCXZ\",\"$1,189.00\",\"880396373908\",\"B083ZFXCXZ\"\n\"B09NQZ94VD\",\"$1,196.67\",\"\",\"B09NQZ94VD\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/beauty_personal_care_salon_spa_equipment_1100_1200.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09NKFNG45\",\"$1,146.03\",\"\",\"B09NKFNG45\"\n\"B08RY69JS1\",\"$1,160.83\",\"\",\"\"\n\"B083ZFXCXZ\",\"$1,189.00\",\"880396373908\",\"B083ZFXCXZ\"\n\"B09NQZ94VD\",\"$1,196.67\",\"\",\"B09NQZ94VD\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50081,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/sports-outdoors/sports.html?price=100-200",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather all items from OneStopShop that are in the \"Sports & Outdoors > Sports\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"sports_outdoors_sports_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/sports-outdoors/sports.html?price=100-200",
      "csv_file_name": "sports_outdoors_sports_100_200.csv",
      "category": "Sports & Outdoors > Sports",
      "price_l": "$100.00",
      "price_r": "$199.99",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B00B2IELIG\",\"$109.99\",\"\",\"\"\n\"B09BNKTZDB\",\"$124.99\",\"\",\"\"\n\"B09HTFXCKN\",\"$135.99\",\"\",\"\"\n\"B004WSL5B4\",\"$169.95\",\"\",\"\"\n\"B0964C84N3\",\"$169.95\",\"\",\"B0964FH235\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/sports_outdoors_sports_100_200.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B00B2IELIG\",\"$109.99\",\"\",\"\"\n\"B09BNKTZDB\",\"$124.99\",\"\",\"\"\n\"B09HTFXCKN\",\"$135.99\",\"\",\"\"\n\"B004WSL5B4\",\"$169.95\",\"\",\"\"\n\"B0964C84N3\",\"$169.95\",\"\",\"B0964FH235\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50082,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/clothing.html?price=400-500",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather all items from OneStopShop that are in the \"Clothing, Shoes & Jewelry > Men > Clothing\" category and have a price between $400.00 to $499.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"clothing_shoes_jewelry_men_clothing_400_500.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/clothing.html?price=400-500",
      "csv_file_name": "clothing_shoes_jewelry_men_clothing_400_500.csv",
      "category": "Clothing, Shoes & Jewelry > Men > Clothing",
      "price_l": "$400.00",
      "price_r": "$499.99",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09R47MDNF\",\"$428.60\",\"\",\"\"\n\"B09QM4VJLM\",\"$431.55\",\"\",\"\"\n\"B09PBM4YL6\",\"$443.35\",\"\",\"\"\n\"B09PB1G4QW\",\"$460.46\",\"\",\"\"\n\"B08LDVH7R7\",\"$479.20\",\"\",\"B08LDY9BHC\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/clothing_shoes_jewelry_men_clothing_400_500.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09R47MDNF\",\"$428.60\",\"\",\"\"\n\"B09QM4VJLM\",\"$431.55\",\"\",\"\"\n\"B09PBM4YL6\",\"$443.35\",\"\",\"\"\n\"B09PB1G4QW\",\"$460.46\",\"\",\"\"\n\"B08LDVH7R7\",\"$479.20\",\"\",\"B08LDY9BHC\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50083,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/electronics/portable-audio-video/radios.html?price=100-200",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather all items from OneStopShop that are in the \"Electronics > Portable Audio & Video > Radios\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"electronics_portable_audio_video_radios_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/electronics/portable-audio-video/radios.html?price=100-200",
      "csv_file_name": "electronics_portable_audio_video_radios_100_200.csv",
      "category": "Electronics > Portable Audio & Video > Radios",
      "price_l": "$100.00",
      "price_r": "$199.99",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B08R1RLYWN\",\"$101.36\",\"\",\"\"\n\"B01J3ZD3WY\",\"$105.00\",\"\",\"\"\n\"B0002QX3YC\",\"$129.99\",\"\",\"\"\n\"B09STGNKYH\",\"$138.99\",\"\",\"\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/electronics_portable_audio_video_radios_100_200.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B08R1RLYWN\",\"$101.36\",\"\",\"\"\n\"B01J3ZD3WY\",\"$105.00\",\"\",\"\"\n\"B0002QX3YC\",\"$129.99\",\"\",\"\"\n\"B09STGNKYH\",\"$138.99\",\"\",\"\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50084,
    "sites": [
      "gitlab",
      "shopping"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html?price=100-200",
    "storage_state": "./.auth/gitlab.shopping_state.json",
    "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "intent": "Gather all items from OneStopShop that are in the \"Cell Phones & Accessories > Accessories > Automobile Accessories\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"cell_phones_accessories_accessories_automobile_accessories_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "long-term",
    "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html?price=100-200",
      "csv_file_name": "cell_phones_accessories_accessories_automobile_accessories_100_200.csv",
      "category": "Cell Phones & Accessories > Accessories > Automobile Accessories",
      "price_l": "$100.00",
      "price_r": "$199.99",
      "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B084PZRSYF\",\"$114.99\",\"\",\"\"\n\"B01CIATFB4\",\"$119.00\",\"\",\"\"\n\"B08GGB73PR\",\"$136.99\",\"\",\"\"\n\"B0155HBNR6\",\"$149.00\",\"\",\"\"\n\"B09NKMX6RY\",\"$149.96\",\"\",\"\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping/-/raw/main/cell_phones_accessories_accessories_automobile_accessories_100_200.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B084PZRSYF\",\"$114.99\",\"\",\"\"\n\"B01CIATFB4\",\"$119.00\",\"\",\"\"\n\"B08GGB73PR\",\"$136.99\",\"\",\"\"\n\"B0155HBNR6\",\"$149.00\",\"\",\"\"\n\"B09NKMX6RY\",\"$149.96\",\"\",\"\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50090,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
    "intent": "Look for the population of the 7 continents on Wikipedia and output the name of the continents in the order of their population (larger first) to readme.md in a new repository named continent_ranking. The output should be in Markdown format.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
      "content": "the population of the 7 continents",
      "output": "the name of the continents in the order of their population (larger first)",
      "repo_name": "continent_ranking",
      "misc": "",
      "answer": "- Asia\n- Africa\n- Europe\n- North America\n- South America\n- Oceania\n- Antarctica",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/continent_ranking/-/raw/main/readme.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "- Asia\n- Africa\n- Europe\n- North America\n- South America\n- Oceania\n- Antarctica"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50091,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Japanese_Nobel_laureates",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
    "intent": "Look for Japanese Nobel Prize winners on Wikipedia and output the names by the category to readme.md in a new repository named Nobel_Prize. The output should be in Markdown format. Put each category in a separate section. Sort the sections alphabetically by their category name. The section title (category name) should be a level 1 header. The winner names in each category should also be in alphabetical order.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Japanese_Nobel_laureates",
      "content": "Japanese Nobel Prize winners",
      "output": "the names by the category",
      "repo_name": "Nobel_Prize",
      "misc": " Put each category in a separate section. Sort the sections alphabetically by their category name. The section title (category name) should be a level 1 header. The winner names in each category should also be in alphabetical order.",
      "answer": "# Chemistry\n- Akira Suzuki\n- Akira Yoshino\n- Ei-ichi Negishi\n- Hideki Shirakawa\n- Kenichi Fukui\n- Koichi Tanaka\n- Osamu Shimomura\n- Ryōji Noyori\n# Literature\n- Kazuo Ishiguro\n- Kenzaburō Ōe\n- Yasunari Kawabata\n# Peace\n- Eisaku Satō\n# Physics\n- Hideki Yukawa\n- Hiroshi Amano\n- Isamu Akasaki\n- Leo Esaki\n- Makoto Kobayashi\n- Masatoshi Koshiba\n- Shuji Nakamura\n- Sin-Itiro Tomonaga\n- Syukuro Manabe\n- Takaaki Kajita\n- Toshihide Maskawa\n- Yoichiro Nambu\n# Physiology or Medicine\n- Satoshi Ōmura\n- Shinya Yamanaka\n- Susumu Tonegawa\n- Tasuku Honjo\n- Yoshinori Ohsumi",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/Nobel_Prize/-/raw/main/readme.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "# Chemistry\n- Akira Suzuki\n- Akira Yoshino\n- Ei-ichi Negishi\n- Hideki Shirakawa\n- Kenichi Fukui\n- Koichi Tanaka\n- Osamu Shimomura\n- Ryōji Noyori\n# Literature\n- Kazuo Ishiguro\n- Kenzaburō Ōe\n- Yasunari Kawabata\n# Peace\n- Eisaku Satō\n# Physics\n- Hideki Yukawa\n- Hiroshi Amano\n- Isamu Akasaki\n- Leo Esaki\n- Makoto Kobayashi\n- Masatoshi Koshiba\n- Shuji Nakamura\n- Sin-Itiro Tomonaga\n- Syukuro Manabe\n- Takaaki Kajita\n- Toshihide Maskawa\n- Yoichiro Nambu\n# Physiology or Medicine\n- Satoshi Ōmura\n- Shinya Yamanaka\n- Susumu Tonegawa\n- Tasuku Honjo\n- Yoshinori Ohsumi"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50092,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Olympic_medalists_in_baseball",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
    "intent": "Look for countries that got a medal for baseball on Wikipedia and output the names of the countries to readme.md in a new repository named olympic_baseball. The output should be in Markdown format. Put each event in a separate section. Sort the sections in chronological order. The section title (host city name) should be a level 1 header. The countries should be in a numbered list.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Olympic_medalists_in_baseball",
      "content": "countries that got a medal for baseball",
      "output": "the names of the countries",
      "repo_name": "olympic_baseball",
      "misc": " Put each event in a separate section. Sort the sections in chronological order. The section title (host city name) should be a level 1 header. The countries should be in a numbered list.",
      "answer": "# Barcelona\n1. Cuba\n2. Chinese Taipei\n3. Japan\n# Atlanta\n1. Cuba\n2. Japan\n3. United States\n# Sydney\n1. United States\n2. Cuba\n3. South Korea\n# Athens\n1. Cuba\n2. Australia\n3. Japan\n# Beijing\n1. South Korea\n2. Cuba\n3. United States\n# Tokyo\n1. Japan\n2. United States\n3. Dominican Republic",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/olympic_baseball/-/raw/main/readme.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "# Barcelona\n1. Cuba\n2. Chinese Taipei\n3. Japan\n# Atlanta\n1. Cuba\n2. Japan\n3. United States\n# Sydney\n1. United States\n2. Cuba\n3. South Korea\n# Athens\n1. Cuba\n2. Australia\n3. Japan\n# Beijing\n1. South Korea\n2. Cuba\n3. United States\n# Tokyo\n1. Japan\n2. United States\n3. Dominican Republic"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50093,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Mercury_(planet)",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
    "intent": "Look for the velocity of rotation on the equator for each of the 8 planets on Wikipedia and output the names of the planets and the velocity to readme.md in a new repository named planet_velocity. The output should be in Markdown format. Output the velocity in m/s with three digits. If the velocity exceeds 1 km/s, output it in km/s instead. Truncate any unnecessary digits if needed. Each item should be formatted as (Planet Name):(number)(unit)",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Mercury_(planet)",
      "content": "the velocity of rotation on the equator for each of the 8 planets",
      "output": "the names of the planets and the velocity",
      "repo_name": "planet_velocity",
      "misc": " Output the velocity in m/s with three digits. If the velocity exceeds 1 km/s, output it in km/s instead. Truncate any unnecessary digits if needed. Each item should be formatted as (Planet Name):(number)(unit)",
      "answer": "- Mercury:3.02m/s\n- Venus:1.81m/s\n- Earth:465m/s\n- Mars:241m/s\n- Jupiter:12.6km/s\n- Saturn:9.87km/s\n- Uranus:2.59km/s\n- Neptune:2.68km/s",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/planet_velocity/-/raw/main/readme.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "- Mercury:3.02m/s\n- Venus:1.81m/s\n- Earth:465m/s\n- Mars:241m/s\n- Jupiter:12.6km/s\n- Saturn:9.87km/s\n- Uranus:2.59km/s\n- Neptune:2.68km/s"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50100,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "intent": "Replace the readme of the Amazon ML Challenge 2021 repository with the first paragraph of the Wikipedia article for Amazon. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
      "readme_url": "__GITLAB__/abisubramanya27/Amazon_ML_Challenge_2021/-/raw/master/README.md",
      "repository": "the Amazon ML Challenge 2021 repository",
      "wiki_item": "Amazon",
      "answer": "Amazon.com, Inc. (/ˈæməzɒn/ AM-ə-zon) is an American multinational technology company which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It has been referred to as \"one of the most influential economic and cultural forces in the world\", and is one of the world's most valuable brands. It is one of the Big Five American information technology companies, alongside Alphabet, Apple, Meta, and Microsoft.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/abisubramanya27/Amazon_ML_Challenge_2021/-/raw/master/README.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "Amazon.com, Inc. (/ˈæməzɒn/ AM-ə-zon) is an American multinational technology company which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It has been referred to as \"one of the most influential economic and cultural forces in the world\", and is one of the world's most valuable brands. It is one of the Big Five American information technology companies, alongside Alphabet, Apple, Meta, and Microsoft."
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50101,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/WTFPL",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "intent": "Replace the readme of my repository with the ‘Do What The F*ck You Want To Public License’ and with a shorter name with the first paragraph of the Wikipedia article for the license. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/WTFPL",
      "readme_url": "__GITLAB__/byteblaze/cloud-to-butt/-/raw/master/README.md",
      "repository": "my repository with the ‘Do What The F*ck You Want To Public License’ and with a shorter name",
      "wiki_item": "the license",
      "answer": "WTFPL is a permissive free software license, compatible with the GNU GPL. As a public domain like license, the WTFPL is essentially the same as dedication to the public domain. It allows redistribution and modification of the work under any terms. The title is an abbreviation of \"Do What The Fuck You Want To Public License\".",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/cloud-to-butt/-/raw/master/README.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "WTFPL is a permissive free software license, compatible with the GNU GPL. As a public domain like license, the WTFPL is essentially the same as dedication to the public domain. It allows redistribution and modification of the work under any terms. The title is an abbreviation of \"Do What The Fuck You Want To Public License\"."
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50102,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/COVID-19",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "intent": "Replace the readme of the repository for a web app to check whether I had contacted the patient of covid-19 or not with the first paragraph of the Wikipedia article for the virus. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/COVID-19",
      "readme_url": "__GITLAB__/yjlou/2019-nCov/-/raw/master/README.md",
      "repository": "the repository for a web app to check whether I had contacted the patient of covid-19 or not",
      "wiki_item": "the virus",
      "answer": "Coronavirus disease 2019 (COVID-19) is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease spread worldwide, leading to the COVID-19 pandemic.",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/yjlou/2019-nCov/-/raw/master/README.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "Coronavirus disease 2019 (COVID-19) is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease spread worldwide, leading to the COVID-19 pandemic."
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50103,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Super_Mario_Bros.",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "intent": "Replace the readme of the repository that attempts to recreate the first level of Super Mario Bros. with the first paragraph of the Wikipedia article for the game. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Super_Mario_Bros.",
      "readme_url": "__GITLAB__/justinmeister/Mario-Level-1/-/raw/master/README.md",
      "repository": "the repository that attempts to recreate the first level of Super Mario Bros.",
      "wiki_item": "the game",
      "answer": "Super Mario Bros. is a platform game developed and published by Nintendo. The successor to the 1983 arcade game Mario Bros. and the first in the Super Mario series, it was released in 1985 for the Famicom in Japan. Following a limited US release for the Nintendo Entertainment System (NES), it was ported to international arcades for the Nintendo Vs. System in early 1986. The NES version received a wide release in North America that year and in PAL regions in 1987.",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/justinmeister/Mario-Level-1/-/raw/master/README.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "Super Mario Bros. is a platform game developed and published by Nintendo. The successor to the 1983 arcade game Mario Bros. and the first in the Super Mario series, it was released in 1985 for the Famicom in Japan. Following a limited US release for the Nintendo Entertainment System (NES), it was ported to international arcades for the Nintendo Vs. System in early 1986. The NES version received a wide release in North America that year and in PAL regions in 1987."
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50104,
    "sites": [
      "gitlab",
      "wikipedia"
    ],
    "start_url": "__WIKIPEDIA__",
    "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Generative_adversarial_network",
    "storage_state": "./.auth/gitlab_state.json",
    "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "intent": "Replace the readme of PyTorch implementations of GANs with the first paragraph of the Wikipedia article for the network. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
    "instantiation_dict": {
      "start_url": "__WIKIPEDIA__",
      "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Generative_adversarial_network",
      "readme_url": "__GITLAB__/eriklindernoren/PyTorch-GAN/-/raw/master/README.md",
      "repository": "PyTorch implementations of GANs",
      "wiki_item": "the network",
      "answer": "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).",
      "difficulty": "medium"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/eriklindernoren/PyTorch-GAN/-/raw/master/README.md",
          "locator": "document.querySelector(\"body > pre\").innerText",
          "required_contents": {
            "must_include": [
              "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss)."
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50110,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"washington_newyork.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "washington_newyork.csv",
      "csv_content": "Name,Email,Phone,State/Province,Customer Since\nWilliam Chang,william.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:44 AM\"\nJessica Chang,jessica.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:26 AM\"\nJane Doe,jane.doe@gmail.com,2125551212,New York,\"Apr 23, 2023 12:13:19 AM\"\nRoberto Lopez,roberto.lopez@hotmail.com,2125551212,New York,\"Apr 23, 2023 12:13:12 AM\"\nJessica Nguyen,jessica.nguyen@gmail.com,2065551212,Washington,\"Apr 23, 2023 12:12:58 AM\"\nKate Jones,kate.jones@gmail.com,2125551212,New York,\"Apr 23, 2023 12:12:51 AM\"\nKatie Wong,katie.wong@hotmail.com,2065551212,Washington,\"Apr 19, 2023 5:46:37 PM\"\nAlex Martin,alex.martin@gmail.com,2125551212,New York,\"Apr 19, 2023 5:46:20 PM\"\nAdam Garcia,gamingpro456@gmail.com,2065555555,Washington,\"Apr 19, 2023 5:46:14 PM\"\nJohn Doe,johndoe123@gmail.com,2125551212,New York,\"Apr 19, 2023 5:45:37 PM\"\nJane Smith,janesmith@gmail.com,2065554321,Washington,\"Apr 19, 2023 5:45:24 PM\"\nJulia Williams,jla_7781@gmail.com,4567890123,New York,\"Apr 19, 2023 5:45:11 PM\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/washington_newyork.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "Name,Email,Phone,State/Province,Customer Since\nWilliam Chang,william.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:44 AM\"\nJessica Chang,jessica.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:26 AM\"\nJane Doe,jane.doe@gmail.com,2125551212,New York,\"Apr 23, 2023 12:13:19 AM\"\nRoberto Lopez,roberto.lopez@hotmail.com,2125551212,New York,\"Apr 23, 2023 12:13:12 AM\"\nJessica Nguyen,jessica.nguyen@gmail.com,2065551212,Washington,\"Apr 23, 2023 12:12:58 AM\"\nKate Jones,kate.jones@gmail.com,2125551212,New York,\"Apr 23, 2023 12:12:51 AM\"\nKatie Wong,katie.wong@hotmail.com,2065551212,Washington,\"Apr 19, 2023 5:46:37 PM\"\nAlex Martin,alex.martin@gmail.com,2125551212,New York,\"Apr 19, 2023 5:46:20 PM\"\nAdam Garcia,gamingpro456@gmail.com,2065555555,Washington,\"Apr 19, 2023 5:46:14 PM\"\nJohn Doe,johndoe123@gmail.com,2125551212,New York,\"Apr 19, 2023 5:45:37 PM\"\nJane Smith,janesmith@gmail.com,2065554321,Washington,\"Apr 19, 2023 5:45:24 PM\"\nJulia Williams,jla_7781@gmail.com,4567890123,New York,\"Apr 19, 2023 5:45:11 PM\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50111,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"california_newjergy.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "california_newjergy.csv",
      "csv_content": "Name,Email,Phone,State/Province,Customer Since\nEmma Lopez,emma.lopez@gmail.com,6505551212,California,\"Apr 23, 2023 12:14:57 AM\"\nNatalie Kim,natalie.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:49 AM\"\nMatthew Kim,matthew.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:19 AM\"\nJulie Nguyen,julie.nguyen@gmail.com,3105551212,California,\"Apr 23, 2023 12:14:15 AM\"\nAmanda Kim,amanda.kim@gmail.com,2015551234,New Jersey,\"Apr 23, 2023 12:13:15 AM\"\nSam Wilson,sam.wilson@yahoo.com,3105551212,California,\"Apr 23, 2023 12:12:47 AM\"\nAlexander Thomas,alexander.thomas@hotmail.com,3235551212,California,\"Apr 19, 2023 5:46:50 PM\"\nJennifer White,jennifer.white@yahoo.com,2137418080,California,\"Apr 19, 2023 5:46:17 PM\"\nAlex Johnson,fitnessjunkie22@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:07 PM\"\nAva Brown,beachlover99@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:01 PM\"\nJane Smith,janesmith456@yahoo.com,3105555555,California,\"Apr 19, 2023 5:45:41 PM\"\nSarah Miller,helloworld@yahoo.com,5107819902,California,\"Apr 19, 2023 5:45:07 PM\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/california_newjergy.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "Name,Email,Phone,State/Province,Customer Since\nEmma Lopez,emma.lopez@gmail.com,6505551212,California,\"Apr 23, 2023 12:14:57 AM\"\nNatalie Kim,natalie.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:49 AM\"\nMatthew Kim,matthew.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:19 AM\"\nJulie Nguyen,julie.nguyen@gmail.com,3105551212,California,\"Apr 23, 2023 12:14:15 AM\"\nAmanda Kim,amanda.kim@gmail.com,2015551234,New Jersey,\"Apr 23, 2023 12:13:15 AM\"\nSam Wilson,sam.wilson@yahoo.com,3105551212,California,\"Apr 23, 2023 12:12:47 AM\"\nAlexander Thomas,alexander.thomas@hotmail.com,3235551212,California,\"Apr 19, 2023 5:46:50 PM\"\nJennifer White,jennifer.white@yahoo.com,2137418080,California,\"Apr 19, 2023 5:46:17 PM\"\nAlex Johnson,fitnessjunkie22@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:07 PM\"\nAva Brown,beachlover99@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:01 PM\"\nJane Smith,janesmith456@yahoo.com,3105555555,California,\"Apr 19, 2023 5:45:41 PM\"\nSarah Miller,helloworld@yahoo.com,5107819902,California,\"Apr 19, 2023 5:45:07 PM\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50112,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"florida_massachusetts.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "florida_massachusetts.csv",
      "csv_content": "Name,Email,Phone,State/Province,Customer Since\nIsabella Santos,isabella.santos@gmail.com,3055551212,Florida,\"Apr 23, 2023 12:14:32 AM\"\nSophia Young,sophia.young@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:14:05 AM\"\nRobert Johnson,robert.johnson@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:36 AM\"\nSamantha Wu,samantha.wu@yahoo.com,3055551212,Florida,\"Apr 23, 2023 12:13:33 AM\"\nEmily Chen,emily.chen@hotmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:05 AM\"\nDavid Lee,david.lee@gmail.com,6175551212,Massachusetts,\"Apr 19, 2023 5:46:30 PM\"\nSophie Taylor,fashionista88@gmail.com,3055555555,Florida,\"Apr 19, 2023 5:46:04 PM\"\nGrace Nguyen,avidreader99@yahoo.com,6175555555,Massachusetts,\"Apr 19, 2023 5:45:51 PM\"\nSamantha Jones,coolcat321@hotmail.com,3055551212,Florida,\"Apr 19, 2023 5:45:44 PM\"\nMary Martin,marym@gmail.com,3059876543,Florida,\"Apr 19, 2023 5:45:17 PM\"\nJane Doe,jane.doe@hotmail.com,4123671901,Florida,\"Apr 19, 2023 5:45:01 PM\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/florida_massachusetts.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "Name,Email,Phone,State/Province,Customer Since\nIsabella Santos,isabella.santos@gmail.com,3055551212,Florida,\"Apr 23, 2023 12:14:32 AM\"\nSophia Young,sophia.young@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:14:05 AM\"\nRobert Johnson,robert.johnson@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:36 AM\"\nSamantha Wu,samantha.wu@yahoo.com,3055551212,Florida,\"Apr 23, 2023 12:13:33 AM\"\nEmily Chen,emily.chen@hotmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:05 AM\"\nDavid Lee,david.lee@gmail.com,6175551212,Massachusetts,\"Apr 19, 2023 5:46:30 PM\"\nSophie Taylor,fashionista88@gmail.com,3055555555,Florida,\"Apr 19, 2023 5:46:04 PM\"\nGrace Nguyen,avidreader99@yahoo.com,6175555555,Massachusetts,\"Apr 19, 2023 5:45:51 PM\"\nSamantha Jones,coolcat321@hotmail.com,3055551212,Florida,\"Apr 19, 2023 5:45:44 PM\"\nMary Martin,marym@gmail.com,3059876543,Florida,\"Apr 19, 2023 5:45:17 PM\"\nJane Doe,jane.doe@hotmail.com,4123671901,Florida,\"Apr 19, 2023 5:45:01 PM\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50113,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"colorado_illinois.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "colorado_illinois.csv",
      "csv_content": "Name,Email,Phone,State/Province,Customer Since\nNathan Chen,nathan.chen@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:14:36 AM\"\nEmily Wilson,emily.wilson@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:14:24 AM\"\nOlivia Jackson,olivia.jackson@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:13:57 AM\"\nJessica Wong,jessica.wong@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:48 AM\"\nJames Kim,james.kim@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:29 AM\"\nMaxwell Baker,maxwell.baker@yahoo.com,3125551212,Illinois,\"Apr 23, 2023 12:13:01 AM\"\nJason Miller,jason.miller@yahoo.com,3035551212,Colorado,\"Apr 19, 2023 5:46:34 PM\"\nMichael Nguyen,michael.nguyen@yahoo.com,3125551212,Illinois,\"Apr 19, 2023 5:46:27 PM\"\nLucy Garcia,artsygal123@hotmail.com,3035555555,Colorado,\"Apr 19, 2023 5:45:54 PM\"\nLily Potter,harrypotterfan1@gmail.com,7735555555,Illinois,\"Apr 19, 2023 5:45:47 PM\"\nJohn Lee,john.lee@yahoo.com,3125556789,Illinois,\"Apr 19, 2023 5:45:21 PM\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/colorado_illinois.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "Name,Email,Phone,State/Province,Customer Since\nNathan Chen,nathan.chen@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:14:36 AM\"\nEmily Wilson,emily.wilson@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:14:24 AM\"\nOlivia Jackson,olivia.jackson@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:13:57 AM\"\nJessica Wong,jessica.wong@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:48 AM\"\nJames Kim,james.kim@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:29 AM\"\nMaxwell Baker,maxwell.baker@yahoo.com,3125551212,Illinois,\"Apr 23, 2023 12:13:01 AM\"\nJason Miller,jason.miller@yahoo.com,3035551212,Colorado,\"Apr 19, 2023 5:46:34 PM\"\nMichael Nguyen,michael.nguyen@yahoo.com,3125551212,Illinois,\"Apr 19, 2023 5:46:27 PM\"\nLucy Garcia,artsygal123@hotmail.com,3035555555,Colorado,\"Apr 19, 2023 5:45:54 PM\"\nLily Potter,harrypotterfan1@gmail.com,7735555555,Illinois,\"Apr 19, 2023 5:45:47 PM\"\nJohn Lee,john.lee@yahoo.com,3125556789,Illinois,\"Apr 19, 2023 5:45:21 PM\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50120,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_oldest_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 oldest approved reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "required_obs": "image",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "top_10_oldest_reviews.csv",
      "status": "the top 10 oldest approved reviews",
      "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:11 PM\",Really perfect for travel,Jamie,4,\"Really perfect for my needs. I travel a ton, so I'll always know what time to give my wife a call back home.\",Joust Duffle Bag\n28,\"Apr 19, 2023, 12:15:11 PM\",I really like the modern look,Bobby,2,\"I really like the modern look of this watch, but I could only get one time zone to work. I hope it has a warranty because I'm sending it back!\",Cruise Dual Analog Watch\n29,\"Apr 19, 2023, 12:15:11 PM\",This watch is so tight,Tommie,2,\"This watch is so tight around my wrist! I don't care if it's adjustable, it cuts off my circulation.\",Cruise Dual Analog Watch\n30,\"Apr 19, 2023, 12:15:11 PM\",My favorite layers,Markus,5,\"This is one of my favorite layers for running in the winter, it keeps me warm but it's not super bulky.\",Cruise Dual Analog Watch\n31,\"Apr 19, 2023, 12:15:11 PM\",Weird looking pocket,Xavier,4,I where it when I'm coaching football so I can run up and down the sidelines and yell without getting to hot. The pocket on the chest is weird looking tho.,Beaumont Summit Kit\n32,\"Apr 19, 2023, 12:15:11 PM\",Perfect layer for the game,Mike,5,\"Perfect layer for wearing to the game, it doesn't shed all over your clothes like a regular hoodie.\",Beaumont Summit Kit\n33,\"Apr 19, 2023, 12:15:11 PM\",The fabric is great,Emory,4,\"the fabric is great, it keeps me warm but it's not bulky like my other hoodies. Runs large, though.\",Hyperion Elements Jacket\n34,\"Apr 19, 2023, 12:15:11 PM\",This jacket isn't keeping me warm,Jon,2,This jacket isn't keeping me warm,Hyperion Elements Jacket\n35,\"Apr 19, 2023, 12:15:11 PM\",I don't feel protected,Homer,2,\"Not sure exactly what \"\"elements\"\" they're talking about here. I don't feel protected from any \"\"elements\"\" in this throw-away.\",Montana Wind Jacket\n36,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Montana Wind Jacket",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_oldest_reviews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:11 PM\",Really perfect for travel,Jamie,4,\"Really perfect for my needs. I travel a ton, so I'll always know what time to give my wife a call back home.\",Joust Duffle Bag\n28,\"Apr 19, 2023, 12:15:11 PM\",I really like the modern look,Bobby,2,\"I really like the modern look of this watch, but I could only get one time zone to work. I hope it has a warranty because I'm sending it back!\",Cruise Dual Analog Watch\n29,\"Apr 19, 2023, 12:15:11 PM\",This watch is so tight,Tommie,2,\"This watch is so tight around my wrist! I don't care if it's adjustable, it cuts off my circulation.\",Cruise Dual Analog Watch\n30,\"Apr 19, 2023, 12:15:11 PM\",My favorite layers,Markus,5,\"This is one of my favorite layers for running in the winter, it keeps me warm but it's not super bulky.\",Cruise Dual Analog Watch\n31,\"Apr 19, 2023, 12:15:11 PM\",Weird looking pocket,Xavier,4,I where it when I'm coaching football so I can run up and down the sidelines and yell without getting to hot. The pocket on the chest is weird looking tho.,Beaumont Summit Kit\n32,\"Apr 19, 2023, 12:15:11 PM\",Perfect layer for the game,Mike,5,\"Perfect layer for wearing to the game, it doesn't shed all over your clothes like a regular hoodie.\",Beaumont Summit Kit\n33,\"Apr 19, 2023, 12:15:11 PM\",The fabric is great,Emory,4,\"the fabric is great, it keeps me warm but it's not bulky like my other hoodies. Runs large, though.\",Hyperion Elements Jacket\n34,\"Apr 19, 2023, 12:15:11 PM\",This jacket isn't keeping me warm,Jon,2,This jacket isn't keeping me warm,Hyperion Elements Jacket\n35,\"Apr 19, 2023, 12:15:11 PM\",I don't feel protected,Homer,2,\"Not sure exactly what \"\"elements\"\" they're talking about here. I don't feel protected from any \"\"elements\"\" in this throw-away.\",Montana Wind Jacket\n36,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Montana Wind Jacket"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50121,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_newest_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 newest approved reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "required_obs": "image",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "top_10_newest_reviews.csv",
      "status": "the top 10 newest approved reviews",
      "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n333,\"Apr 19, 2023, 12:15:20 PM\",Makes me feel so snug! WHOO!,Concepcion,5,Makes me feel so snug! WHOO!,Chloe Compete Tank\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_newest_reviews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "ID,Created,Title,Nickname,Review Star,Review,Product\n333,\"Apr 19, 2023, 12:15:20 PM\",Makes me feel so snug! WHOO!,Concepcion,5,Makes me feel so snug! WHOO!,Chloe Compete Tank\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50122,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_lowest_id_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 approved reviews with the lowest IDs in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "required_obs": "image",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "top_10_lowest_id_reviews.csv",
      "status": "the top 10 approved reviews with the lowest IDs",
      "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Joust Duffle Bag\n2,\"Apr 19, 2023, 12:15:11 PM\",I use it a lot,Filiberto,3,It's a good size and I use it a lot. My only issue with it was I wanted the handles to be longer so I can wear it on my back.,Joust Duffle Bag\n3,\"Apr 19, 2023, 12:15:11 PM\",I've had this thing for really long,Herb,5,\"I've had this thing for a really long time and it barely shows any signs of wear and tear. It's really big, too! I've taken it on day trips as well as short vacations and usually have no trouble finding room for my stuff.\",Fusion Backpack\n4,\"Apr 19, 2023, 12:15:11 PM\",Decent bag,Craig,3,\"Decent bag. I keep my stuff in it for work and the gym. It's nice and roomy. I wish it had a more sophisticated design, though. Kinda looks like it's for kids.\",Fusion Backpack\n5,\"Apr 19, 2023, 12:15:11 PM\",Screwed up my back,Orville,2,\"I can't believe they're claiming these straps are \"\"padded.\"\" Wearing this thing to class for a semester totally screwed up my back, and my shoulders would start to ache after a few minutes where the straps dug in.\",Fusion Backpack\n6,\"Apr 19, 2023, 12:15:11 PM\",Awesome bag,Marty,4,Awesome bag but I found it to be smaller than I thought. I haven't felt any additional strain on my back and I use it all day long for my job.,Crown Summit Backpack\n7,\"Apr 19, 2023, 12:15:11 PM\",The back needs more padding,Chase,3,If the back had more padding I would recommend it for everyone. You can tell the material is strong and not cheap so it's definitely worth it.,Crown Summit Backpack\n8,\"Apr 19, 2023, 12:15:11 PM\",I bought this backpack for my son,Kennith,3,\"I bought this backpack for my son to take to school, but he carries it like a suitcase now! It's also really good for airplane travel.\",Crown Summit Backpack\n9,\"Apr 19, 2023, 12:15:11 PM\",awesome for going back and forth,Gaston,5,\"This is awesome for going back and forth to class. I live off campus and it's a longer walk, but this pack fits comfortably and I can even store my laptop in the main compartment.\",Strive Shoulder Pack\n10,\"Apr 19, 2023, 12:15:11 PM\",comfy and i don't feel like a loser,Issac,4,comfy and i don't feel like a loser carrying it.,Strive Shoulder Pack",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_lowest_id_reviews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Joust Duffle Bag\n2,\"Apr 19, 2023, 12:15:11 PM\",I use it a lot,Filiberto,3,It's a good size and I use it a lot. My only issue with it was I wanted the handles to be longer so I can wear it on my back.,Joust Duffle Bag\n3,\"Apr 19, 2023, 12:15:11 PM\",I've had this thing for really long,Herb,5,\"I've had this thing for a really long time and it barely shows any signs of wear and tear. It's really big, too! I've taken it on day trips as well as short vacations and usually have no trouble finding room for my stuff.\",Fusion Backpack\n4,\"Apr 19, 2023, 12:15:11 PM\",Decent bag,Craig,3,\"Decent bag. I keep my stuff in it for work and the gym. It's nice and roomy. I wish it had a more sophisticated design, though. Kinda looks like it's for kids.\",Fusion Backpack\n5,\"Apr 19, 2023, 12:15:11 PM\",Screwed up my back,Orville,2,\"I can't believe they're claiming these straps are \"\"padded.\"\" Wearing this thing to class for a semester totally screwed up my back, and my shoulders would start to ache after a few minutes where the straps dug in.\",Fusion Backpack\n6,\"Apr 19, 2023, 12:15:11 PM\",Awesome bag,Marty,4,Awesome bag but I found it to be smaller than I thought. I haven't felt any additional strain on my back and I use it all day long for my job.,Crown Summit Backpack\n7,\"Apr 19, 2023, 12:15:11 PM\",The back needs more padding,Chase,3,If the back had more padding I would recommend it for everyone. You can tell the material is strong and not cheap so it's definitely worth it.,Crown Summit Backpack\n8,\"Apr 19, 2023, 12:15:11 PM\",I bought this backpack for my son,Kennith,3,\"I bought this backpack for my son to take to school, but he carries it like a suitcase now! It's also really good for airplane travel.\",Crown Summit Backpack\n9,\"Apr 19, 2023, 12:15:11 PM\",awesome for going back and forth,Gaston,5,\"This is awesome for going back and forth to class. I live off campus and it's a longer walk, but this pack fits comfortably and I can even store my laptop in the main compartment.\",Strive Shoulder Pack\n10,\"Apr 19, 2023, 12:15:11 PM\",comfy and i don't feel like a loser,Issac,4,comfy and i don't feel like a loser carrying it.,Strive Shoulder Pack"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50123,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_highest_id_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 approved reviews with the highest IDs in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "required_obs": "image",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "top_10_highest_id_reviews.csv",
      "status": "the top 10 approved reviews with the highest IDs",
      "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n343,\"Apr 19, 2023, 12:15:20 PM\",Good choice for working out,Elfriede,4,Good choice for working out and stylin' enough to wear when I'm hanging with friends on hot days. Also washes really well! ,Bella Tank\n344,\"Apr 19, 2023, 12:15:20 PM\",I love the look,Yan,3,\"I love the look of this top, but I wasn't too crazy about the fit. The medium was too big in my opinion.\",Zoe Tank\n345,\"Apr 19, 2023, 12:15:20 PM\",Huge arm holes??,Valorie,2,I don't know why the arm holes are so big. It looked ok in the photo but in person they're really wide. It's really comfortable but that bugs me.,Zoe Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_highest_id_reviews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "ID,Created,Title,Nickname,Review Star,Review,Product\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n343,\"Apr 19, 2023, 12:15:20 PM\",Good choice for working out,Elfriede,4,Good choice for working out and stylin' enough to wear when I'm hanging with friends on hot days. Also washes really well! ,Bella Tank\n344,\"Apr 19, 2023, 12:15:20 PM\",I love the look,Yan,3,\"I love the look of this top, but I wasn't too crazy about the fit. The medium was too big in my opinion.\",Zoe Tank\n345,\"Apr 19, 2023, 12:15:20 PM\",Huge arm holes??,Valorie,2,I don't know why the arm holes are so big. It looked ok in the photo but in person they're really wide. It's really comfortable but that bugs me.,Zoe Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50124,
    "sites": [
      "gitlab",
      "shopping_admin"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__SHOPPING_ADMIN__/admin",
    "storage_state": "./.auth/gitlab.shopping_admin_state.json",
    "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"all_pending_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for all the pending reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
    "required_obs": "image",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__SHOPPING_ADMIN__/admin",
      "csv_file_name": "all_pending_reviews.csv",
      "status": "all the pending reviews",
      "csv_content": "ID,Created,Status,Title,Nickname,Review Star,Review,Product\n347,\"Apr 24, 2023, 2:42:23 PM\",Pending,Quite good,Jane Smith,5,\"I recently purchased the Olivia 1/4 Zip Light Jacket and I am extremely satisfied with my purchase! The jacket is incredibly lightweight and comfortable, making it perfect for cool spring mornings or summer evenings. The 1/4 zip feature allows for easy temperature control, and the jacket is versatile enough to be dressed up or down. I also appreciate the attention to detail in the design - the pockets are well-placed and the stitching is sturdy. Overall, I highly recommend the Olivia 1/4 Zip Light Jacket for anyone in need of a comfortable and stylish lightweight jacket!\",Olivia 1/4 Zip Light Jacket\n349,\"Apr 24, 2023, 2:44:16 PM\",Pending,OKish,seam miller,3,\"I have to say, I'm not impressed with the Olivia 1/4 Zip Light Jacket. The color is not as vibrant as it looked online, and the zipper is really hard to use. The jacket is also not very breathable, so I found myself getting really sweaty when I wore it for even a short amount of time. Finally, the pockets are really shallow and not very functional. Overall, I wouldn't recommend this jacket - there are better options out there for the price.\",Olivia 1/4 Zip Light Jacket\n351,\"Apr 24, 2023, 2:49:50 PM\",Pending,won't recommand,Emma,1,\"I was really disappointed with the Olivia 1/4 Zip Light Jacket. The material is extremely thin and flimsy, which makes it not very warm at all. I was hoping for something that would keep me comfortable in the springtime, but this jacket just doesn't cut it. Additionally, the sizing is way off - I ordered my usual size and it was way too tight in the arms and shoulders. I had to return it and won't be buying from this brand again.\",Olivia 1/4 Zip Light Jacket\n352,\"Apr 24, 2023, 2:53:49 PM\",Pending,Good but not perfect,customer,4,\"I recently purchased the Circe Hooded Ice Fleece and overall, I'm quite happy with it. The fleece material is incredibly soft and cozy, and I love the addition of the hood for extra warmth. The fit is true to size and the sleeves are long enough, which is often a problem for me. The only reason I'm not giving it a full 5 stars is because I was hoping the color would be a bit more vibrant - it's a bit muted compared to what I was expecting. But overall, I would definitely recommend the Circe Hooded Ice Fleece for anyone in need of a warm and comfortable layer for outdoor activities.\",Circe Hooded Ice Fleece\n353,\"Apr 24, 2023, 2:55:10 PM\",Pending,Bad!,Hannah Lim,1,\"I was really disappointed with the Circe Hooded Ice Fleece. The material is not very high quality and started pilling after just one wash. The fit was also really strange - the sleeves were too short and the body was too baggy, making me look frumpy. I was hoping this would be a cozy layer for winter walks, but it doesn't keep me very warm either. Finally, the hood is way too big and just falls down over my face. I wouldn't recommend this product - there are much better options out there for the price.\",Circe Hooded Ice Fleece",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/all_pending_reviews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "ID,Created,Status,Title,Nickname,Review Star,Review,Product\n347,\"Apr 24, 2023, 2:42:23 PM\",Pending,Quite good,Jane Smith,5,\"I recently purchased the Olivia 1/4 Zip Light Jacket and I am extremely satisfied with my purchase! The jacket is incredibly lightweight and comfortable, making it perfect for cool spring mornings or summer evenings. The 1/4 zip feature allows for easy temperature control, and the jacket is versatile enough to be dressed up or down. I also appreciate the attention to detail in the design - the pockets are well-placed and the stitching is sturdy. Overall, I highly recommend the Olivia 1/4 Zip Light Jacket for anyone in need of a comfortable and stylish lightweight jacket!\",Olivia 1/4 Zip Light Jacket\n349,\"Apr 24, 2023, 2:44:16 PM\",Pending,OKish,seam miller,3,\"I have to say, I'm not impressed with the Olivia 1/4 Zip Light Jacket. The color is not as vibrant as it looked online, and the zipper is really hard to use. The jacket is also not very breathable, so I found myself getting really sweaty when I wore it for even a short amount of time. Finally, the pockets are really shallow and not very functional. Overall, I wouldn't recommend this jacket - there are better options out there for the price.\",Olivia 1/4 Zip Light Jacket\n351,\"Apr 24, 2023, 2:49:50 PM\",Pending,won't recommand,Emma,1,\"I was really disappointed with the Olivia 1/4 Zip Light Jacket. The material is extremely thin and flimsy, which makes it not very warm at all. I was hoping for something that would keep me comfortable in the springtime, but this jacket just doesn't cut it. Additionally, the sizing is way off - I ordered my usual size and it was way too tight in the arms and shoulders. I had to return it and won't be buying from this brand again.\",Olivia 1/4 Zip Light Jacket\n352,\"Apr 24, 2023, 2:53:49 PM\",Pending,Good but not perfect,customer,4,\"I recently purchased the Circe Hooded Ice Fleece and overall, I'm quite happy with it. The fleece material is incredibly soft and cozy, and I love the addition of the hood for extra warmth. The fit is true to size and the sleeves are long enough, which is often a problem for me. The only reason I'm not giving it a full 5 stars is because I was hoping the color would be a bit more vibrant - it's a bit muted compared to what I was expecting. But overall, I would definitely recommend the Circe Hooded Ice Fleece for anyone in need of a warm and comfortable layer for outdoor activities.\",Circe Hooded Ice Fleece\n353,\"Apr 24, 2023, 2:55:10 PM\",Pending,Bad!,Hannah Lim,1,\"I was really disappointed with the Circe Hooded Ice Fleece. The material is not very high quality and started pilling after just one wash. The fit was also really strange - the sleeves were too short and the body was too baggy, making me look frumpy. I was hoping this would be a cozy layer for winter walks, but it doesn't keep me very warm either. Finally, the hood is way too big and just falls down over my face. I wouldn't recommend this product - there are much better options out there for the price.\",Circe Hooded Ice Fleece"
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50130,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/memes/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"memes\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"memes.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/memes/most_commented?t=all",
      "csv_file_name": "memes.csv",
      "number": "20",
      "subreddit": "memes",
      "csv_content": "\"username\",\"number of comments\"\n\"DrGoosert\",\"197\"\n\"mbhammock\",\"191\"\n\"Lttlefoot\",\"179\"\n\"killingmemesoftly\",\"176\"\n\"Lord_Detleff1\",\"166\"\n\"rohanstan69\",\"164\"\n\"return2ozma\",\"160\"\n\"TurtleBoy29\",\"152\"\n\"Vortex9966\",\"152\"\n\"Civil-Sky-973\",\"149\"\n\"BeerFuelsMyDreams\",\"147\"\n\"Jemaniema\",\"147\"\n\"Looney_forner\",\"147\"\n\"BuddPlug\",\"145\"\n\"velatieren\",\"144\"\n\"Andrevery\",\"140\"\n\"thepositivepandemic\",\"132\"\n\"Better-Intern9170\",\"128\"\n\"Salty-004\",\"128\"\n\"_Cespuglio_\",\"125\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/memes.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"username\",\"number of comments\"\n\"DrGoosert\",\"197\"\n\"mbhammock\",\"191\"\n\"Lttlefoot\",\"179\"\n\"killingmemesoftly\",\"176\"\n\"Lord_Detleff1\",\"166\"\n\"rohanstan69\",\"164\"\n\"return2ozma\",\"160\"\n\"TurtleBoy29\",\"152\"\n\"Vortex9966\",\"152\"\n\"Civil-Sky-973\",\"149\"\n\"BeerFuelsMyDreams\",\"147\"\n\"Jemaniema\",\"147\"\n\"Looney_forner\",\"147\"\n\"BuddPlug\",\"145\"\n\"velatieren\",\"144\"\n\"Andrevery\",\"140\"\n\"thepositivepandemic\",\"132\"\n\"Better-Intern9170\",\"128\"\n\"Salty-004\",\"128\"\n\"_Cespuglio_\",\"125\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50131,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/wallstreetbets/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "intent": "From Reddit, gather 14 users who created most-commented submissions in the subreddit \"wallstreetbets\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"wallstreetbets.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/wallstreetbets/most_commented?t=all",
      "csv_file_name": "wallstreetbets.csv",
      "number": "14",
      "subreddit": "wallstreetbets",
      "csv_content": "\"username\",\"number of comments\"\n\"Johs92\",\"215\"\n\"FI_investor\",\"205\"\n\"postonrddt\",\"205\"\n\"sadafboicry\",\"201\"\n\"putridfries\",\"197\"\n\"whicky1978\",\"195\"\n\"mlamping\",\"194\"\n\"cezapiza\",\"181\"\n\"Mega-Lithium\",\"181\"\n\"jamzkourt\",\"180\"\n\"mat3og\",\"179\"\n\"cyuvlol\",\"175\"\n\"Curiousdude925\",\"171\"\n\"JPowsSecretlover\",\"171\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/wallstreetbets.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"username\",\"number of comments\"\n\"Johs92\",\"215\"\n\"FI_investor\",\"205\"\n\"postonrddt\",\"205\"\n\"sadafboicry\",\"201\"\n\"putridfries\",\"197\"\n\"whicky1978\",\"195\"\n\"mlamping\",\"194\"\n\"cezapiza\",\"181\"\n\"Mega-Lithium\",\"181\"\n\"jamzkourt\",\"180\"\n\"mat3og\",\"179\"\n\"cyuvlol\",\"175\"\n\"Curiousdude925\",\"171\"\n\"JPowsSecretlover\",\"171\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50132,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"worldnews\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"worldnews.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
      "csv_file_name": "worldnews.csv",
      "number": "20",
      "subreddit": "worldnews",
      "csv_content": "\"username\",\"number of comments\"\n\"BubsyFanboy\",\"207\"\n\"BeeBobMC\",\"205\"\n\"SunfireGaren\",\"204\"\n\"Crimbobimbobippitybo\",\"202\"\n\"YoanB\",\"202\"\n\"seebz69\",\"201\"\n\"rentalfloss\",\"197\"\n\"Lahampsink\",\"194\"\n\"khushraho\",\"192\"\n\"calbert1735\",\"190\"\n\"Rifletree\",\"190\"\n\"DutchBlob\",\"189\"\n\"TallAd3975\",\"189\"\n\"yourSAS\",\"189\"\n\"Caratteraccio\",\"188\"\n\"IndependentTHNKR\",\"184\"\n\"loggiews\",\"184\"\n\"OceanBreeze246\",\"183\"\n\"WhoIsJolyonWest\",\"183\"\n\"essential_projection\",\"183\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/worldnews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"username\",\"number of comments\"\n\"BubsyFanboy\",\"207\"\n\"BeeBobMC\",\"205\"\n\"SunfireGaren\",\"204\"\n\"Crimbobimbobippitybo\",\"202\"\n\"YoanB\",\"202\"\n\"seebz69\",\"201\"\n\"rentalfloss\",\"197\"\n\"Lahampsink\",\"194\"\n\"khushraho\",\"192\"\n\"calbert1735\",\"190\"\n\"Rifletree\",\"190\"\n\"DutchBlob\",\"189\"\n\"TallAd3975\",\"189\"\n\"yourSAS\",\"189\"\n\"Caratteraccio\",\"188\"\n\"IndependentTHNKR\",\"184\"\n\"loggiews\",\"184\"\n\"OceanBreeze246\",\"183\"\n\"WhoIsJolyonWest\",\"183\"\n\"essential_projection\",\"183\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50133,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/news/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"news\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"news.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/news/most_commented?t=all",
      "csv_file_name": "news.csv",
      "number": "20",
      "subreddit": "news",
      "csv_content": "\"username\",\"number of comments\"\n\"ChocolateTsar\",\"219\"\n\"PhillipCrawfordJr\",\"219\"\n\"alanzhang34\",\"215\"\n\"flowerhoney10\",\"215\"\n\"iamthyfucker\",\"215\"\n\"thatoneguy889\",\"214\"\n\"Papppi-56\",\"213\"\n\"sovamind\",\"212\"\n\"hoosakiwi\",\"211\"\n\"DragonWriterDB\",\"207\"\n\"Globalist2\",\"207\"\n\"phunky_1\",\"207\"\n\"AsherBaels\",\"206\"\n\"meta_perspective\",\"206\"\n\"Picture-unrelated\",\"206\"\n\"Semper-Fido\",\"206\"\n\"Shaul_Ishtov\",\"206\"\n\"Clem_Doore\",\"205\"\n\"Picture-unrelated\",\"205\"\n\"eastbayted\",\"204\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/news.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"username\",\"number of comments\"\n\"ChocolateTsar\",\"219\"\n\"PhillipCrawfordJr\",\"219\"\n\"alanzhang34\",\"215\"\n\"flowerhoney10\",\"215\"\n\"iamthyfucker\",\"215\"\n\"thatoneguy889\",\"214\"\n\"Papppi-56\",\"213\"\n\"sovamind\",\"212\"\n\"hoosakiwi\",\"211\"\n\"DragonWriterDB\",\"207\"\n\"Globalist2\",\"207\"\n\"phunky_1\",\"207\"\n\"AsherBaels\",\"206\"\n\"meta_perspective\",\"206\"\n\"Picture-unrelated\",\"206\"\n\"Semper-Fido\",\"206\"\n\"Shaul_Ishtov\",\"206\"\n\"Clem_Doore\",\"205\"\n\"Picture-unrelated\",\"205\"\n\"eastbayted\",\"204\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50134,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/movies/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"movies\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"movies.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/movies/most_commented?t=all",
      "csv_file_name": "movies.csv",
      "number": "20",
      "subreddit": "movies",
      "csv_content": "\"username\",\"number of comments\"\n\"Zilla1689\",\"200\"\n\"polywha\",\"199\"\n\"MarvelsGrantMan136\",\"190\"\n\"SquatOnAPitbull\",\"190\"\n\"ProbablyASithLord\",\"189\"\n\"JannTosh17\",\"187\"\n\"JorReno\",\"184\"\n\"peter095837\",\"182\"\n\"fabrizziop17\",\"178\"\n\"ilovemychickens\",\"177\"\n\"I_serve_Anubis\",\"174\"\n\"mywordswillgowithyou\",\"172\"\n\"acharismaticjeweller\",\"171\"\n\"Ok-Impress-2222\",\"171\"\n\"JannTosh12\",\"170\"\n\"Huevos___Rancheros\",\"169\"\n\"Boss452\",\"166\"\n\"Leather-Climate3438\",\"165\"\n\"h2oskid3\",\"164\"\n\"PastMiddleAge\",\"163\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/movies.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"username\",\"number of comments\"\n\"Zilla1689\",\"200\"\n\"polywha\",\"199\"\n\"MarvelsGrantMan136\",\"190\"\n\"SquatOnAPitbull\",\"190\"\n\"ProbablyASithLord\",\"189\"\n\"JannTosh17\",\"187\"\n\"JorReno\",\"184\"\n\"peter095837\",\"182\"\n\"fabrizziop17\",\"178\"\n\"ilovemychickens\",\"177\"\n\"I_serve_Anubis\",\"174\"\n\"mywordswillgowithyou\",\"172\"\n\"acharismaticjeweller\",\"171\"\n\"Ok-Impress-2222\",\"171\"\n\"JannTosh12\",\"170\"\n\"Huevos___Rancheros\",\"169\"\n\"Boss452\",\"166\"\n\"Leather-Climate3438\",\"165\"\n\"h2oskid3\",\"164\"\n\"PastMiddleAge\",\"163\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50140,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/memes/new",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "intent": "From Reddit, gather newest 25 submissions from reddit that are in the \"memes\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"newest_25_memes.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/memes/new",
      "condition": "newest",
      "number": "25",
      "subreddit": "memes",
      "csv_file_name": "newest_25_memes.csv",
      "csv_content": "\"title\",\"votes\"\n\"Guys now really think being a misogynist is cool\",\"5\"\n\"My mom at amusement parks:\",\"5\"\n\"Neverending Therapy\",\"5\"\n\"I wouldn’t put the bag in the microwave personally\",\"4\"\n\"I’m in wrong industry\",\"4\"\n\"Let's be honest\",\"4\"\n\"Mega cringe\",\"4\"\n\"They really dropped the ball with this one\",\"4\"\n\"How many of these do you turn off?\",\"3\"\n\"If you have no other choice\",\"3\"\n\"It do be like that tho\",\"3\"\n\"Love your mom\",\"3\"\n\"The greatest betrayal\",\"3\"\n\"yes Yes YES!\",\"3\"\n\"Glue porridge\",\"2\"\n\"Mostly the truth.\",\"2\"\n\"One of these should be illegal\",\"2\"\n\"Shagadelic, baby\",\"2\"\n\"and i never will\",\"2\"\n\"How many comments will this individual predictions post have in exactly 7 days from now? (Round 2)\",\"1\"\n\"It’s always the dogs!\",\"1\"\n\"PC Gamers In 2023 Be Like Part 2\",\"1\"\n\"Thank you memers, this wouldn’t be possible without you.\",\"1\"\n\"They did nothing wrong\",\"1\"\n\"Let’s goooo baby no more cringe show\",\"0\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/newest_25_memes.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"title\",\"votes\"\n\"Guys now really think being a misogynist is cool\",\"5\"\n\"My mom at amusement parks:\",\"5\"\n\"Neverending Therapy\",\"5\"\n\"I wouldn’t put the bag in the microwave personally\",\"4\"\n\"I’m in wrong industry\",\"4\"\n\"Let's be honest\",\"4\"\n\"Mega cringe\",\"4\"\n\"They really dropped the ball with this one\",\"4\"\n\"How many of these do you turn off?\",\"3\"\n\"If you have no other choice\",\"3\"\n\"It do be like that tho\",\"3\"\n\"Love your mom\",\"3\"\n\"The greatest betrayal\",\"3\"\n\"yes Yes YES!\",\"3\"\n\"Glue porridge\",\"2\"\n\"Mostly the truth.\",\"2\"\n\"One of these should be illegal\",\"2\"\n\"Shagadelic, baby\",\"2\"\n\"and i never will\",\"2\"\n\"How many comments will this individual predictions post have in exactly 7 days from now? (Round 2)\",\"1\"\n\"It’s always the dogs!\",\"1\"\n\"PC Gamers In 2023 Be Like Part 2\",\"1\"\n\"Thank you memers, this wouldn’t be possible without you.\",\"1\"\n\"They did nothing wrong\",\"1\"\n\"Let’s goooo baby no more cringe show\",\"0\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50141,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/wallstreetbets/active",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "intent": "From Reddit, gather most active 25 submissions from reddit that are in the \"wallstreetbets\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_active_25_wallstreetbets.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/wallstreetbets/active",
      "condition": "most active",
      "number": "25",
      "subreddit": "wallstreetbets",
      "csv_file_name": "most_active_25_wallstreetbets.csv",
      "csv_content": "\"title\",\"votes\"\n\"OK analyst\",\"1369\"\n\"\"\"No REALLY, we're doing fine\"\" ~ every bank right now\",\"1329\"\n\"Fuking great year so far\",\"747\"\n\"I shorted the Nasdaq AMA\",\"733\"\n\"Bears to Burry after his tweet yesterday...\",\"247\"\n\"Homie doesn’t know how to take a screenshot, somehow degens his way into 6 figures\",\"220\"\n\"No, I won’t stop buying puts!\",\"206\"\n\"TSLA 0dte YOLO\",\"198\"\n\"Hi friends! I just started trading last year and i wanted to share some hot nsfw loss porn.\",\"118\"\n\"AMC Stock Faces Triple Threat: Conversion, Reverse Split, and Dilution\",\"81\"\n\"Most Anticipated Earnings Releases for the week beginning April 3rd, 2023\",\"74\"\n\"Heard this gem from a 12 year old just now\",\"69\"\n\"OpenAI helped me with my homework so I bought AI ticker Pt. 2\",\"60\"\n\"Thoughts on why Big Tech has been rallying and if it’s sustainable?\",\"45\"\n\"$SCHW YOLO\",\"41\"\n\"Went long QQQ calls today. I feel very dirty.\",\"34\"\n\"End of quarter rally?\",\"24\"\n\"Short Nestle SW\",\"15\"\n\"Hahahaha such a funny meme (totally not a solution to the stock market pretend its a funny meme so that Reddit parent company doesn't ban)\",\"13\"\n\"SPX to 5300 by EOY\",\"12\"\n\"Charles Schwab changing receiver account\",\"7\"\n\"Tired and more scared after today’s rally. Hold or sell?\",\"2\"\n\"Volume Buys Just Went Through The Roof Again On SPY Today - Here Are The Next Waves\",\"2\"\n\"A safe 150% gain\",\"0\"\n\"Beyond Meat?\",\"0\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_active_25_wallstreetbets.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"title\",\"votes\"\n\"OK analyst\",\"1369\"\n\"\"\"No REALLY, we're doing fine\"\" ~ every bank right now\",\"1329\"\n\"Fuking great year so far\",\"747\"\n\"I shorted the Nasdaq AMA\",\"733\"\n\"Bears to Burry after his tweet yesterday...\",\"247\"\n\"Homie doesn’t know how to take a screenshot, somehow degens his way into 6 figures\",\"220\"\n\"No, I won’t stop buying puts!\",\"206\"\n\"TSLA 0dte YOLO\",\"198\"\n\"Hi friends! I just started trading last year and i wanted to share some hot nsfw loss porn.\",\"118\"\n\"AMC Stock Faces Triple Threat: Conversion, Reverse Split, and Dilution\",\"81\"\n\"Most Anticipated Earnings Releases for the week beginning April 3rd, 2023\",\"74\"\n\"Heard this gem from a 12 year old just now\",\"69\"\n\"OpenAI helped me with my homework so I bought AI ticker Pt. 2\",\"60\"\n\"Thoughts on why Big Tech has been rallying and if it’s sustainable?\",\"45\"\n\"$SCHW YOLO\",\"41\"\n\"Went long QQQ calls today. I feel very dirty.\",\"34\"\n\"End of quarter rally?\",\"24\"\n\"Short Nestle SW\",\"15\"\n\"Hahahaha such a funny meme (totally not a solution to the stock market pretend its a funny meme so that Reddit parent company doesn't ban)\",\"13\"\n\"SPX to 5300 by EOY\",\"12\"\n\"Charles Schwab changing receiver account\",\"7\"\n\"Tired and more scared after today’s rally. Hold or sell?\",\"2\"\n\"Volume Buys Just Went Through The Roof Again On SPY Today - Here Are The Next Waves\",\"2\"\n\"A safe 150% gain\",\"0\"\n\"Beyond Meat?\",\"0\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50142,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "intent": "From Reddit, gather most commented for all time 25 submissions from reddit that are in the \"worldnews\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_commented_25_worldnews.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
      "condition": "most commented for all time",
      "number": "25",
      "subreddit": "worldnews",
      "csv_file_name": "most_commented_25_worldnews.csv",
      "csv_content": "\"title\",\"votes\"\n\"Ireland Aims To Legalize Cannabis For Personal Use\",\"10614\"\n\"Brazil's Lula appoints Indigenous ministers to reverse Amazon deforestation\",\"9122\"\n\"Anti-war partisans in Belarus claim to have damaged Russian plane | Belarus\",\"6697\"\n\"Poland has delivered tanks to Ukraine, government announces on war's first anniversary.\",\"6145\"\n\"Dutch Constitution to be amended to ban discrimination based on sexuality or disability\",\"4530\"\n\"Australia uncovers Russian espionage ring, expels spies: Report\",\"4515\"\n\"A Russian graveyard reveals Wagner's prisoner army\",\"3939\"\n\"Iranian author said sentenced to death for giving interview to Israeli TV channel\",\"3825\"\n\"Amazon workers in the U.S. and 30 other countries plan Black Friday protests\",\"3383\"\n\"Chinese ships depart after record-long intrusion into Japanese waters\",\"3109\"\n\"Russia's only LGBTQ+ museum closes down amid 'propaganda' crackdown\",\"2394\"\n\"At least 25 die in Peru when bus plunges off cliff, police say\",\"2308\"\n\"World to face wars over food and water without climate action, EU green deal chief says\",\"2093\"\n\"Ukraine says Iran’s help for Russia should push Israel out of neutral stance\",\"1862\"\n\"Banksy's migrant rescue ship seized by Italy's coast guard in Lampedusa\",\"1832\"\n\"Poland picks U.S. offer for its first nuclear power plant -PM\",\"1764\"\n\"Ozone Hole Continues Shrinking in 2022, NASA and NOAA Scientists Say | Annual Antarctic ozone hole over the South Pole was slightly smaller than last year and generally continued the overall shrinking trend of recent years.\",\"1668\"\n\"Poland chooses US to build its first nuclear power plant\",\"1386\"\n\"Nearly 220 million people in Pakistan without power after countrywide outage | CNN Business\",\"1163\"\n\"Russia Says Ukraine Using Long-Range US Artillery\",\"843\"\n\"German defense minister announces resignation\",\"821\"\n\"For The First Time, Less Than Half Of UK's Population Is Christian: Report\",\"660\"\n\"China calls US debt trap accusation 'irresponsible'\",\"626\"\n\"Russia ready to resume gas supplies to Europe via Yamal-Europe pipeline -Novak\",\"598\"\n\"Canada moves to mandate electric vehicle sales starting in 2026\",\"565\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_commented_25_worldnews.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"title\",\"votes\"\n\"Ireland Aims To Legalize Cannabis For Personal Use\",\"10614\"\n\"Brazil's Lula appoints Indigenous ministers to reverse Amazon deforestation\",\"9122\"\n\"Anti-war partisans in Belarus claim to have damaged Russian plane | Belarus\",\"6697\"\n\"Poland has delivered tanks to Ukraine, government announces on war's first anniversary.\",\"6145\"\n\"Dutch Constitution to be amended to ban discrimination based on sexuality or disability\",\"4530\"\n\"Australia uncovers Russian espionage ring, expels spies: Report\",\"4515\"\n\"A Russian graveyard reveals Wagner's prisoner army\",\"3939\"\n\"Iranian author said sentenced to death for giving interview to Israeli TV channel\",\"3825\"\n\"Amazon workers in the U.S. and 30 other countries plan Black Friday protests\",\"3383\"\n\"Chinese ships depart after record-long intrusion into Japanese waters\",\"3109\"\n\"Russia's only LGBTQ+ museum closes down amid 'propaganda' crackdown\",\"2394\"\n\"At least 25 die in Peru when bus plunges off cliff, police say\",\"2308\"\n\"World to face wars over food and water without climate action, EU green deal chief says\",\"2093\"\n\"Ukraine says Iran’s help for Russia should push Israel out of neutral stance\",\"1862\"\n\"Banksy's migrant rescue ship seized by Italy's coast guard in Lampedusa\",\"1832\"\n\"Poland picks U.S. offer for its first nuclear power plant -PM\",\"1764\"\n\"Ozone Hole Continues Shrinking in 2022, NASA and NOAA Scientists Say | Annual Antarctic ozone hole over the South Pole was slightly smaller than last year and generally continued the overall shrinking trend of recent years.\",\"1668\"\n\"Poland chooses US to build its first nuclear power plant\",\"1386\"\n\"Nearly 220 million people in Pakistan without power after countrywide outage | CNN Business\",\"1163\"\n\"Russia Says Ukraine Using Long-Range US Artillery\",\"843\"\n\"German defense minister announces resignation\",\"821\"\n\"For The First Time, Less Than Half Of UK's Population Is Christian: Report\",\"660\"\n\"China calls US debt trap accusation 'irresponsible'\",\"626\"\n\"Russia ready to resume gas supplies to Europe via Yamal-Europe pipeline -Novak\",\"598\"\n\"Canada moves to mandate electric vehicle sales starting in 2026\",\"565\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50143,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/news/controversial?t=all",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "intent": "From Reddit, gather most controversial for all time 25 submissions from reddit that are in the \"news\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_controversial_25_news.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/news/controversial?t=all",
      "condition": "most controversial for all time",
      "number": "25",
      "subreddit": "news",
      "csv_file_name": "most_controversial_25_news.csv",
      "csv_content": "\"title\",\"votes\"\n\"2 Russians seek asylum after reaching remote Alaskan island\",\"0\"\n\"26-year-old man sentenced to life for the killing of retired St. Louis police captain during George Floyd protests\",\"0\"\n\"A family of 4 is missing after being 'taken against their will' in central California, officials say\",\"0\"\n\"Biden to pardon all prior federal offenses of simple marijuana possession\",\"0\"\n\"Boy tackled by security after running on field at Bucs game\",\"0\"\n\"Defendant to represent himself in Wisconsin parade trial\",\"0\"\n\"Donald Trump files election-related lawsuit against CNN\",\"0\"\n\"Egypt calls for return of Rosetta Stone 200 years after it was deciphered\",\"0\"\n\"Elon Musk unveils humanoid ‘Optimus’ robot at Tesla’s AI Day\",\"0\"\n\"Federal court finds 3rd Iowa ag-gag law unconstitutional\",\"0\"\n\"Jan. 6 defendants held in D.C. jail request transfer to Guantanamo Bay\",\"0\"\n\"Lawyer claims LAPD officer was targeted for being a potential whistleblower\",\"0\"\n\"Los Angeles City Council president issues apology after making racist remarks in leaked audio\",\"0\"\n\"Newark School District adds anti-Israel book to sixth-grade curriculum\",\"0\"\n\"Nury Martinez resigns as president of LA City Council following leaked audio of racist remarks\",\"0\"\n\"NYC Mayor Eric Adams declares state of emergency over influx of migrants | CNN\",\"0\"\n\"Olympia woman facing fines over ‘Black Lives Matter’ sign inside her home\",\"0\"\n\"Pregnancy complications spiked during the pandemic. No one knows exactly why.\",\"0\"\n\"San Antonio police officer fired after shooting teen suspect in McDonald's parking lot\",\"0\"\n\"Supreme Court allows defamation lawsuit against MyPillow CEO Mike Lindell to proceed\",\"0\"\n\"Supreme Court rejects bump stock ban cases\",\"0\"\n\"The Onion defends right to parody in very real supreme court brief supporting local satirist\",\"0\"\n\"U.N. body rejects debate on China's treatment of Uyghur Muslims in blow to West\",\"0\"\n\"Walmart, CVS must face lawsuit over placement of homeopathic products\",\"0\"\n\"Woman at center of Herschel Walker abortion firestorm says she also had a child of his\",\"0\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_controversial_25_news.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"title\",\"votes\"\n\"2 Russians seek asylum after reaching remote Alaskan island\",\"0\"\n\"26-year-old man sentenced to life for the killing of retired St. Louis police captain during George Floyd protests\",\"0\"\n\"A family of 4 is missing after being 'taken against their will' in central California, officials say\",\"0\"\n\"Biden to pardon all prior federal offenses of simple marijuana possession\",\"0\"\n\"Boy tackled by security after running on field at Bucs game\",\"0\"\n\"Defendant to represent himself in Wisconsin parade trial\",\"0\"\n\"Donald Trump files election-related lawsuit against CNN\",\"0\"\n\"Egypt calls for return of Rosetta Stone 200 years after it was deciphered\",\"0\"\n\"Elon Musk unveils humanoid ‘Optimus’ robot at Tesla’s AI Day\",\"0\"\n\"Federal court finds 3rd Iowa ag-gag law unconstitutional\",\"0\"\n\"Jan. 6 defendants held in D.C. jail request transfer to Guantanamo Bay\",\"0\"\n\"Lawyer claims LAPD officer was targeted for being a potential whistleblower\",\"0\"\n\"Los Angeles City Council president issues apology after making racist remarks in leaked audio\",\"0\"\n\"Newark School District adds anti-Israel book to sixth-grade curriculum\",\"0\"\n\"Nury Martinez resigns as president of LA City Council following leaked audio of racist remarks\",\"0\"\n\"NYC Mayor Eric Adams declares state of emergency over influx of migrants | CNN\",\"0\"\n\"Olympia woman facing fines over ‘Black Lives Matter’ sign inside her home\",\"0\"\n\"Pregnancy complications spiked during the pandemic. No one knows exactly why.\",\"0\"\n\"San Antonio police officer fired after shooting teen suspect in McDonald's parking lot\",\"0\"\n\"Supreme Court allows defamation lawsuit against MyPillow CEO Mike Lindell to proceed\",\"0\"\n\"Supreme Court rejects bump stock ban cases\",\"0\"\n\"The Onion defends right to parody in very real supreme court brief supporting local satirist\",\"0\"\n\"U.N. body rejects debate on China's treatment of Uyghur Muslims in blow to West\",\"0\"\n\"Walmart, CVS must face lawsuit over placement of homeopathic products\",\"0\"\n\"Woman at center of Herschel Walker abortion firestorm says she also had a child of his\",\"0\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  },
  {
    "task_id": 50144,
    "sites": [
      "gitlab",
      "reddit"
    ],
    "start_url": "__GITLAB__",
    "start_url_lite": "__REDDIT__/f/movies/active",
    "storage_state": "./.auth/gitlab.reddit_state.json",
    "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "intent": "From Reddit, gather most active 25 submissions from reddit that are in the \"movies\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_active_25_movies.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
    "required_obs": "any",
    "affects_environment": true,
    "type_main": "massive_memory",
    "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
    "instantiation_dict": {
      "start_url": "__GITLAB__",
      "start_url_lite": "__REDDIT__/f/movies/active",
      "condition": "most active",
      "number": "25",
      "subreddit": "movies",
      "csv_file_name": "most_active_25_movies.csv",
      "csv_content": "\"title\",\"votes\"\n\"Martin Scorsese’s ‘Killers of the Flower Moon’ Will Have World Premiere at Cannes Film Festival\",\"2792\"\n\"New 'Spider-Verse' Short Film Coming From Sony Pictures Animation\",\"1589\"\n\"Hollywood’s Covid Protocols Get Expiration Date; Vaccine Mandate Will End\",\"151\"\n\"Favorite director hot streak?\",\"53\"\n\"Who else keeps their movie tickets/stubs for collecting purposes as such?\",\"34\"\n\"Late 90’s-early 2000’s suspense/thrillers\",\"28\"\n\"The LOTR The Return of the King is a great film but the confrontation with the Ghost Army has always puzzled me.\",\"24\"\n\"What are some r/movies tropes?\",\"24\"\n\"'Air' Review - Ben Affleck Returns to Directing with Certified Crowd-Pleaser | SXSW 2023\",\"19\"\n\"What movie trope are you a sucker for?\",\"12\"\n\"Freddy Got Fingered has become my favourite comedy\",\"10\"\n\"What are your top 5 favorite musical moments ever in cinema?\",\"7\"\n\"The Lost World: Jurassic Park; a great film dampened by it's third act?\",\"5\"\n\"Get out - Grandma scene\",\"2\"\n\"Movies with beautiful visuals and music?\",\"2\"\n\"Action movies have lost the plot\",\"0\"\n\"Avatar 2 Ummm did I miss something?\",\"0\"\n\"Brooke Shields' movies are so creepy and inappropriate. Imagine your entire film career being reduced to movies which seemed so exploitative of her.\",\"0\"\n\"Have you completely lost any desire to watch Everything, Everywhere All At Once?\",\"0\"\n\"Hot take: Taxi Driver (in my opinion) is bad\",\"0\"\n\"Rocky Horror or Phantom of the Paradise?\",\"0\"\n\"Thoughts on Tetris?\",\"0\"\n\"What are some weird movie age ratings, like films that don’t deserve this very mature age rating or something like that?\",\"0\"\n\"Which movie has better 2 hour non-stop violence? John Wick 4 or Mad Max: Fury road?\",\"0\"\n\"Why do so few American movies let foreign language speaking characters speak their own language? Why does everything have to be in English...\",\"0\"",
      "difficulty": "hard"
    },
    "eval": {
      "eval_types": [
        "program_html"
      ],
      "reference_answers": {},
      "reference_url": "",
      "program_html": [
        {
          "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_active_25_movies.csv",
          "locator": "document.querySelector('pre').outerText",
          "required_contents": {
            "must_include": [
              "\"title\",\"votes\"\n\"Martin Scorsese’s ‘Killers of the Flower Moon’ Will Have World Premiere at Cannes Film Festival\",\"2792\"\n\"New 'Spider-Verse' Short Film Coming From Sony Pictures Animation\",\"1589\"\n\"Hollywood’s Covid Protocols Get Expiration Date; Vaccine Mandate Will End\",\"151\"\n\"Favorite director hot streak?\",\"53\"\n\"Who else keeps their movie tickets/stubs for collecting purposes as such?\",\"34\"\n\"Late 90’s-early 2000’s suspense/thrillers\",\"28\"\n\"The LOTR The Return of the King is a great film but the confrontation with the Ghost Army has always puzzled me.\",\"24\"\n\"What are some r/movies tropes?\",\"24\"\n\"'Air' Review - Ben Affleck Returns to Directing with Certified Crowd-Pleaser | SXSW 2023\",\"19\"\n\"What movie trope are you a sucker for?\",\"12\"\n\"Freddy Got Fingered has become my favourite comedy\",\"10\"\n\"What are your top 5 favorite musical moments ever in cinema?\",\"7\"\n\"The Lost World: Jurassic Park; a great film dampened by it's third act?\",\"5\"\n\"Get out - Grandma scene\",\"2\"\n\"Movies with beautiful visuals and music?\",\"2\"\n\"Action movies have lost the plot\",\"0\"\n\"Avatar 2 Ummm did I miss something?\",\"0\"\n\"Brooke Shields' movies are so creepy and inappropriate. Imagine your entire film career being reduced to movies which seemed so exploitative of her.\",\"0\"\n\"Have you completely lost any desire to watch Everything, Everywhere All At Once?\",\"0\"\n\"Hot take: Taxi Driver (in my opinion) is bad\",\"0\"\n\"Rocky Horror or Phantom of the Paradise?\",\"0\"\n\"Thoughts on Tetris?\",\"0\"\n\"What are some weird movie age ratings, like films that don’t deserve this very mature age rating or something like that?\",\"0\"\n\"Which movie has better 2 hour non-stop violence? John Wick 4 or Mad Max: Fury road?\",\"0\"\n\"Why do so few American movies let foreign language speaking characters speak their own language? Why does everything have to be in English...\",\"0\""
            ]
          }
        }
      ],
      "string_note": ""
    }
  }
]