logging: True
verbose: 1
debug: False
logdir: "AgentOccam-Trajectories_gemini-2.5-pro-exp-03-25/shopping_admin/auto"
logname: "AgentOccam"
max_steps: 50
agent:
  type: "AgentOccam"
  others:
    max_steps: 50
    logname: "AgentOccam"
    logging: True
    verbose: 1
    debug: False
  actor:
    debug: 0
    verbose: 1
    number: 1
    model: "gemini-2.5-pro-preview-03-25"
    documented_interaction_elements: ["url", "plan", "reason", "observation summary", "retained element ids", "observation highlight"]
    online_interaction_elements: []
    input: ["step", "objective", "previous plans", "interaction history", "current observation"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["auto"]
      auto: True
    output: ["interaction history summary", "observation description", "reason", "action", "observation highlight"]
    planning_command: ["branch", "prune"]
    tips: True
    navigation_command: ["click", "type", "stop", "note", "go_back"]
    play: ["step", "objective", "previous plans", "observation description", "reason", "action"]
    trash: ["objective", "step", "url", "instruction", "online input", "response"]
  critic:
    mode: false
    debug: 0
    verbose: 1
    model: "gemini-2.5-pro-exp-03-25"
    documented_interaction_elements: []
    online_interaction_elements: []
    character: "normal"
    input: ["objective", "previous plans", "interaction history", "step", "current observation"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["text"]
    output: ["observation description", "mistakes"]
    trash: ["instruction", "online input", "response"]
  judge:
    mode: false
    debug: 0
    verbose: 1
    model: "gemini-2.5-pro-exp-03-25"
    documented_interaction_elements: []
    online_interaction_elements: []
    strict: false
    input: ["objective", "previous plans", "interaction history", "step", "current observation", "action choices"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["text"]
    output: ["plan progress assessment", "action assessment", "action selection"]
    trash: ["instruction", "online input", "response"]
env:
  fullpage: true
  prune: true
  max_browser_rows: 500
  relative_task_dir: "new_tasks/shopping_admin"
  headless: True
  task_ids: [10000, 10001, 10002, 10003, 10004, 10010, 10011, 10012, 10013, 10014, 10020, 10021, 10022, 10023, 10024, 10030, 10031, 10032, 10033, 10034, 10040, 10041, 10042, 10043, 10044, 10050, 10051, 10052, 10053, 10054, 10060, 10061, 10062, 10063, 10064, 10070, 10071, 10072, 10073, 10074, 10080, 10081, 10082, 10083, 10084, 10090, 10091, 10092, 10093, 10094, 10100, 10110, 10111, 10120, 10121, 10122, 10123, 10124, 10130, 10131, 10132, 10140, 10141, 10142, 10143, 10144, 10150, 10151, 10152, 10153, 10160, 10161, 10162, 10163, 10164, 10170, 10171, 10172, 10173, 10174, 10180, 10181, 10182, 10183, 10190, 10191, 10192, 10193, 10200, 10201, 10202, 10210, 10211, 10212, 10213, 10214, 10220, 10221, 10222, 10223, 10224, 10230, 10231, 10232, 10233, 10234, 10240, 10241, 10242, 10243, 10244, 10245, 10250, 10251, 10252, 10253, 10254, 10260, 10261, 10262, 10263, 10264, 10270, 10271, 10272, 10273, 10274, 10280, 10281, 10282, 10283, 10284]