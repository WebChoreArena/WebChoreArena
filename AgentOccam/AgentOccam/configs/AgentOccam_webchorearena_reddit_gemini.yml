logging: True
verbose: 1
debug: False
logdir: "AgentOccam-Trajectories_gemini-2.5-pro-exp-03-25/reddit/auto"
logname: "AgentOccam"
max_steps: 50
agent:
  type: "AgentOccam"
  others:
    max_steps: 50
    logname: "AgentOccam"
    logging: True
    verbose: 1
    debug: False
  actor:
    debug: 0
    verbose: 1
    number: 1
    model: "gemini-2.5-pro-preview-03-25"
    documented_interaction_elements: ["url", "plan", "reason", "observation summary", "retained element ids", "observation highlight"]
    online_interaction_elements: []
    input: ["step", "objective", "previous plans", "interaction history", "current observation"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["auto"]
      auto: True
    output: ["interaction history summary", "observation description", "reason", "action", "observation highlight"]
    planning_command: ["branch", "prune"]
    tips: True
    navigation_command: ["click", "type", "stop", "note", "go_back"]
    play: ["step", "objective", "previous plans", "observation description", "reason", "action"]
    trash: ["objective", "step", "url", "instruction", "online input", "response"]
  critic:
    mode: false
    debug: 0
    verbose: 1
    model: "gemini-2.5-pro-exp-03-25"
    documented_interaction_elements: []
    online_interaction_elements: []
    character: "normal"
    input: ["objective", "previous plans", "interaction history", "step", "current observation"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["text"]
    output: ["observation description", "mistakes"]
    trash: ["instruction", "online input", "response"]
  judge:
    mode: false
    debug: 0
    verbose: 1
    model: "gemini-2.5-pro-exp-03-25"
    documented_interaction_elements: []
    online_interaction_elements: []
    strict: false
    input: ["objective", "previous plans", "interaction history", "step", "current observation", "action choices"]
    interaction_history:
      verbose: True
      type: ["text"]
      step_num: "all"
    current_observation:
      type: ["text"]
    output: ["plan progress assessment", "action assessment", "action selection"]
    trash: ["instruction", "online input", "response"]
env:
  fullpage: true
  prune: true
  max_browser_rows: 500
  relative_task_dir: "new_tasks/reddit"
  headless: True
  task_ids: [30000, 30001, 30010, 30020, 30021, 30022, 30023, 30024, 30030, 30031, 30032, 30033, 30034, 30040, 30041, 30042, 30043, 30050, 30051, 30052, 30053, 30054, 30060, 30061, 30062, 30063, 30070, 30071, 30072, 30073, 30074, 30080, 30081, 30082, 30083, 30084, 30090, 30091, 30092, 30093, 30094, 30100, 30101, 30102, 30103, 30104, 30110, 30111, 30112, 30113, 30114, 30120, 30121, 30122, 30123, 30124, 30130, 30131, 30132, 30133, 30134, 30140, 30141, 30142, 30143, 30144, 30150, 30151, 30152, 30153, 30154, 30160, 30161, 30162, 30163, 30164, 30170, 30171, 30172, 30173, 30174, 30180, 30181, 30182, 30183, 30184, 30190, 30191, 30192, 30193, 30194]