[
    {
        "task_id": 50000,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__GITLAB__/explore/projects",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "intent": "Sort all the repositories on GitLab by \"Updated date\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__GITLAB__/explore/projects",
            "category": "Updated date",
            "forum": "deeplearning",
            "contents": "solarized-prism-theme: 7, gimmiethat.space: 3, dotfiles: 553, timeit: 22, cloud-to-butt: 29",
            "checkpoint1": "solarized-prism-theme, gimmiethat.space, dotfiles, timeit, cloud-to-butt",
            "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__inner').outerText",
                    "required_contents": {
                        "must_include": [
                            "solarized-prism-theme: 7, gimmiethat.space: 3, dotfiles: 553, timeit: 22, cloud-to-butt: 29"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50001,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__GITLAB__/explore/projects",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "intent": "Sort all the repositories on GitLab by \"Name\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__GITLAB__/explore/projects",
            "category": "Name",
            "forum": "deeplearning",
            "contents": "2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2320, abisubramanya27: 17 |OR| 2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2,320, abisubramanya27: 17",
            "checkpoint1": "2019-nCov, a11y-syntax-highlighting, a11y-webring.club, a11yproject.com, abisubramanya27",
            "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__inner').outerText",
                    "required_contents": {
                        "must_include": [
                            "2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2320, abisubramanya27: 17 |OR| 2019-nCov: 344, a11y-syntax-highlighting: 48, a11y-webring.club: 235, a11yproject.com: 2,320, abisubramanya27: 17"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50002,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__GITLAB__/explore/projects",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "intent": "Sort all the repositories on GitLab by \"Most stars\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"deeplearning\" forum in the following format: \"repository name1: the number of commits, repository name2: the number of commits, ...\". Write the repository names in the order they appear after sorting. Note that each repository is titled in the format \"user name / repository name\", so extract and provide only the repository name. Also, the target repositories are not limited to your personal projects.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Sort all the repositories on GitLab by \"{{category}}\" and find top 5 repositories. Then, post a summary of the 5 repository names and their number of commits on Reddit's \"{{forum}}\" forum.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__GITLAB__/explore/projects",
            "category": "Most stars",
            "forum": "deeplearning",
            "contents": "AndroidSlidingUpPanel: 361, create-react-app: 2800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1097 |OR| AndroidSlidingUpPanel: 361, create-react-app: 2,800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1,097",
            "checkpoint1": "AndroidSlidingUpPanel, create-react-app, ffmpeg-python, PHP_XLSXWriter, AndroidAsync",
            "checkpoint_info": "checkpoint1: The title of top-5 repositories.",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__inner').outerText",
                    "required_contents": {
                        "must_include": [
                            "AndroidSlidingUpPanel: 361, create-react-app: 2800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1097 |OR| AndroidSlidingUpPanel: 361, create-react-app: 2,800, ffmpeg-python: 458, PHP_XLSXWriter: 180, AndroidAsync: 1,097"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50010,
        "sites": [
            "reddit",
            "gitlab"
        ],
        "start_url": "__REDDIT__/",
        "start_url_lite": "__REDDIT__/",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "intent": "Find user Akilesh Kannan's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Akilesh Kannan's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
        "instantiation_dict": {
            "start_url": "__REDDIT__/",
            "start_url_lite": "__REDDIT__/",
            "user": "Akilesh Kannan",
            "forum": "deeplearning",
            "content": "empathy-prompts: __GITLAB__/aklsh/empathy-prompts, CacheEval: __GITLAB__/aklsh/CacheEval, nvidia-patch: __GITLAB__/aklsh/nvidia-patch, SimCache: __GITLAB__/aklsh/SimCache, viewgrades-scraper: __GITLAB__/aklsh/viewgrades-scraper, dots: __GITLAB__/aklsh/dots",
            "checkpoint1": "empathy-prompts, CacheEval, nvidia-patch, SimCache, viewgrades-scraper, dots",
            "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "user Akilesh Kannan's personal projects"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "empathy-prompts: __GITLAB__/aklsh/empathy-prompts, CacheEval: __GITLAB__/aklsh/CacheEval, nvidia-patch: __GITLAB__/aklsh/nvidia-patch, SimCache: __GITLAB__/aklsh/SimCache, viewgrades-scraper: __GITLAB__/aklsh/viewgrades-scraper, dots: __GITLAB__/aklsh/dots"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50011,
        "sites": [
            "reddit",
            "gitlab"
        ],
        "start_url": "__REDDIT__/",
        "start_url_lite": "__REDDIT__/",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "intent": "Find user Meta's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Meta's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
        "instantiation_dict": {
            "start_url": "__REDDIT__/",
            "start_url_lite": "__REDDIT__/",
            "user": "Meta",
            "forum": "deeplearning",
            "content": "create-react-app: __GITLAB__/facebook/create-react-app, buck: __GITLAB__/facebook/buck",
            "checkpoint1": "create-react-app, buck",
            "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "user Meta's personal projects"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "create-react-app: __GITLAB__/facebook/create-react-app, buck: __GITLAB__/facebook/buck"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50012,
        "sites": [
            "reddit",
            "gitlab"
        ],
        "start_url": "__REDDIT__/",
        "start_url_lite": "__REDDIT__/",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "intent": "Find user First Contributions's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser First Contributions's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
        "instantiation_dict": {
            "start_url": "__REDDIT__/",
            "start_url_lite": "__REDDIT__/",
            "user": "First Contributions",
            "forum": "deeplearning",
            "content": "first-contributions: __GITLAB__/firstcontributions/first-contributions, frontend: __GITLAB__/firstcontributions/frontend",
            "checkpoint1": "first-contributions, frontend",
            "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "user First Contributions's personal projects"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "first-contributions: __GITLAB__/firstcontributions/first-contributions, frontend: __GITLAB__/firstcontributions/frontend"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50013,
        "sites": [
            "reddit",
            "gitlab"
        ],
        "start_url": "__REDDIT__/",
        "start_url_lite": "__REDDIT__/",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "intent": "Find user Roshan Jossy's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Roshan Jossy's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
        "instantiation_dict": {
            "start_url": "__REDDIT__/",
            "start_url_lite": "__REDDIT__/",
            "user": "Roshan Jossy",
            "forum": "deeplearning",
            "content": "timeit: __GITLAB__/Roshanjossey/timeit, dot-files: __GITLAB__/Roshanjossey/dot-files, ultimate-voting-app: __GITLAB__/Roshanjossey/ultimate-voting-app",
            "checkpoint1": "timeit, dot-files, ultimate-voting-app",
            "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "user Roshan Jossy's personal projects"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "timeit: __GITLAB__/Roshanjossey/timeit, dot-files: __GITLAB__/Roshanjossey/dot-files, ultimate-voting-app: __GITLAB__/Roshanjossey/ultimate-voting-app"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50014,
        "sites": [
            "reddit",
            "gitlab"
        ],
        "start_url": "__REDDIT__/",
        "start_url_lite": "__REDDIT__/",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.\n\nTitle should be:\nuser {{user}}'s personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "intent": "Find user Convex Eggtart's personal projects on GitLab and post each repository's name and its link in the deeplearning forum.\n\nTitle should be:\nuser Convex Eggtart's personal projects\n\nBody should contain the repositories using the following format:\n\n<repository_name_1>: <repository_link_1>, <repository_name_2>: <repository_link_2>, <repository_name_3>: <repository_link_3>, ...\n\nRepositories must be listed in the same order they appear on the user's personal projects page. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find user {{user}}'s personal projects on GitLab and post each repository's name and its link in the {{forum}} forum.",
        "instantiation_dict": {
            "start_url": "__REDDIT__/",
            "start_url_lite": "__REDDIT__/",
            "user": "Convex Eggtart",
            "forum": "deeplearning",
            "content": "chatgpt: __GITLAB__/convexegg/chatgpt, super_awesome_robot: __GITLAB__/convexegg/super_awesome_robot |OR| Chatgpt: __GITLAB__/convexegg/chatgpt, Super_Awesome_Robot: __GITLAB__/convexegg/super_awesome_robot",
            "checkpoint1": "Chatgpt, Super_Awesome_Robot",
            "checkpoint_info": "checkpoint1: The title of the user \"{{user}}\"'s personal projects on GitLab",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/deeplearning",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "user Convex Eggtart's personal projects"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "chatgpt: __GITLAB__/convexegg/chatgpt, super_awesome_robot: __GITLAB__/convexegg/super_awesome_robot |OR| Chatgpt: __GITLAB__/convexegg/chatgpt, Super_Awesome_Robot: __GITLAB__/convexegg/super_awesome_robot"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50020,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__SHOPPING__/samsung-galaxy-note-9-128gb-lavender-purple-unlocked-renewed.html",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "intent": "Please compare the following two items by their SKU codes: B08N3J7GJ8 and B07H8PXT7K, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum gadgets on Reddit.\n\nTitle should be:\nComparison of item sku B08N3J7GJ8 and item sku B07H8PXT7K\n\nBody should follow this format:\n\nItem1: B08N3J7GJ8, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B07H8PXT7K, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__SHOPPING__/samsung-galaxy-note-9-128gb-lavender-purple-unlocked-renewed.html",
            "item1": "B08N3J7GJ8",
            "item2": "B07H8PXT7K",
            "forum": "gadgets",
            "price1": "$590.01",
            "price2": "$277.78",
            "review_score1": "67%",
            "review_score2": "50%"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/gadgets",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Item1: B08N3J7GJ8, Price1: $590.01, Positive reviews percentage1: 67%, Item2: B07H8PXT7K, Price2: $277.78, Positive reviews percentage2: 50%"
                        ]
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "must_include": [
                            "Comparison of item sku B08N3J7GJ8 and item sku B07H8PXT7K"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50021,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__SHOPPING__/minnetonka-tamson-men-s-suede-slippers.html",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "intent": "Please compare the following two items by their SKU codes: B0976WN9JY and B07VPGT4YR, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum BuyItForLife on Reddit.\n\nTitle should be:\nComparison of item sku B0976WN9JY and item sku B07VPGT4YR\n\nBody should follow this format:\n\nItem1: B0976WN9JY, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B07VPGT4YR, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__SHOPPING__/minnetonka-tamson-men-s-suede-slippers.html",
            "item1": "B0976WN9JY",
            "item2": "B07VPGT4YR",
            "forum": "BuyItForLife",
            "price1": "$74.95",
            "price2": "$24.99",
            "review_score1": "60%",
            "review_score2": "75%"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/BuyItForLife",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Item1: B0976WN9JY, Price1: $74.95, Positive reviews percentage1: 60%, Item2: B07VPGT4YR, Price2: $24.99, Positive reviews percentage2: 75%"
                        ]
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "must_include": [
                            "Comparison of item sku B0976WN9JY and item sku B07VPGT4YR"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50022,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B00W9EPK3W",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "intent": "Please compare the following two items by their SKU codes: B00W9EPK3W and B091FT6ZJC, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum Art on Reddit.\n\nTitle should be:\nComparison of item sku B00W9EPK3W and item sku B091FT6ZJC\n\nBody should follow this format:\n\nItem1: B00W9EPK3W, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B091FT6ZJC, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B00W9EPK3W",
            "item1": "B00W9EPK3W",
            "item2": "B091FT6ZJC",
            "forum": "Art",
            "price1": "$14.99",
            "price2": "$15.99",
            "review_score1": "92%",
            "review_score2": "80%"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/Art",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Item1: B00W9EPK3W, Price1: $14.99, Positive reviews percentage1: 92%, Item2: B091FT6ZJC, Price2: $15.99, Positive reviews percentage2: 80%"
                        ]
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "must_include": [
                            "Comparison of item sku B00W9EPK3W and item sku B091FT6ZJC"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50023,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__SHOPPING__/vizio-d40f-g9-40-inch-1080p-full-array-led-smartcast-hdtv-renewed.html",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "intent": "Please compare the following two items by their SKU codes: B07M8RM5HQ and B0773WWKHH, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum television on Reddit.\n\nTitle should be:\nComparison of item sku B07M8RM5HQ and item sku B0773WWKHH\n\nBody should follow this format:\n\nItem1: B07M8RM5HQ, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B0773WWKHH, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__SHOPPING__/vizio-d40f-g9-40-inch-1080p-full-array-led-smartcast-hdtv-renewed.html",
            "item1": "B07M8RM5HQ",
            "item2": "B0773WWKHH",
            "forum": "television",
            "price1": "$308.95",
            "price2": "$299.99",
            "review_score1": "50%",
            "review_score2": "33%"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/television",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Item1: B07M8RM5HQ, Price1: $308.95, Positive reviews percentage1: 50%, Item2: B0773WWKHH, Price2: $299.99, Positive reviews percentage2: 33%"
                        ]
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "must_include": [
                            "Comparison of item sku B07M8RM5HQ and item sku B0773WWKHH"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50024,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B097F5LT5K",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Please compare the following two items by their SKU codes: {{item1}} and {{item2}}, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum {{forum}} on Reddit.\n\nTitle should be:\nComparison of item sku {{item1}} and item sku {{item2}}\n\nBody should follow this format:\n\nItem1: {{item1}}, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: {{item2}}, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "intent": "Please compare the following two items by their SKU codes: B097F5LT5K and B089ZPBQY3, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Note: a rating of 3 stars or higher corresponds to a score of 60 or above.\n\nThen, post your comparison in the forum headphones on Reddit.\n\nTitle should be:\nComparison of item sku B097F5LT5K and item sku B089ZPBQY3\n\nBody should follow this format:\n\nItem1: B097F5LT5K, Price1: $<price1>, Positive reviews percentage1: <percentage1>%, Item 2: B089ZPBQY3, Price2: $<price2>, Positive reviews percentage2: <percentage2>%\n\n(Round the percentage of positive reviews to the nearest whole number and format it like 'Positive reviews: 87%')",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Compare two items by their SKU codes, focusing on their prices and the percentage of positive rating reviews (3 stars or higher). Then, post your comparison in the forum {{forum}} on Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__SHOPPING__/catalogsearch/result/?q=B097F5LT5K",
            "item1": "B097F5LT5K",
            "item2": "B089ZPBQY3",
            "forum": "headphones",
            "price1": "$29.95",
            "price2": "$54.99",
            "review_score1": "92%",
            "review_score2": "100%"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/headphones",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Item1: B097F5LT5K, Price1: $29.95, Positive reviews percentage1: 92%, Item2: B089ZPBQY3, Price2: $54.99, Positive reviews percentage2: 100%"
                        ]
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "must_include": [
                            "Comparison of item sku B097F5LT5K and item sku B089ZPBQY3"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50030,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__REDDIT__/f/science",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "intent": "Find the most expensive headphone and post it on the forum Music with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive headphone on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find the specified item on the specified forum and post it to Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__REDDIT__/f/science",
            "price": "most expensive",
            "forum": "Music",
            "item": "headphone",
            "link": "__SHOPPING__/hedd-phone-one-headphone.html"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/Music",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "One Stop Market Info"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "This is the most expensive headphone on One Stop Market. The link is __SHOPPING__/hedd-phone-one-headphone.html."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED",
            "string_note": "",
            "reference_answer_raw_annotation": "__SHOPPING__/hedd-phone-one-headphone.html"
        }
    },
    {
        "task_id": 50031,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__REDDIT__/f/science",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "intent": "Find the cheapest Case for iPhone and post it on the forum iphone with the following messages. Title: One Stop Market Info, Body: 'This is the cheapest Case for iPhone on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find the specified item on the specified forum and post it to Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__REDDIT__/f/science",
            "price": "cheapest",
            "forum": "iphone",
            "item": "Case for iPhone",
            "link": "__SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/iphone",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "One Stop Market Info"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "This is the cheapest Case for iPhone on One Stop Market. The link is __SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED",
            "string_note": "",
            "reference_answer_raw_annotation": "__SHOPPING__/cinderella-hard-shell-case-for-iphone-5-5s-retail-packaging.html"
        }
    },
    {
        "task_id": 50032,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__REDDIT__/f/science",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "intent": "Find the most expensive Record Player and post it on the forum Music with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive Record Player on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find the specified item on the specified forum and post it to Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__REDDIT__/f/science",
            "price": "most expensive",
            "forum": "Music",
            "item": "Record Player",
            "link": "__SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/Music",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "One Stop Market Info"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "This is the most expensive Record Player on One Stop Market. The link is __SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED",
            "string_note": "",
            "reference_answer_raw_annotation": "__SHOPPING__/wsmla-big-horn-antique-gramophone-wireless-turntable-hi-fi-system-bookshelf-speakers-vinyl-record-player-color-white.html"
        }
    },
    {
        "task_id": 50033,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__REDDIT__/f/science",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "intent": "Find the most expensive Wall Mirror and post it on the forum DIY with the following messages. Title: One Stop Market Info, Body: 'This is the most expensive Wall Mirror on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find the specified item on the specified forum and post it to Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__REDDIT__/f/science",
            "price": "most expensive",
            "forum": "DIY",
            "item": "Wall Mirror",
            "link": "__SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/DIY",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "One Stop Market Info"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "This is the most expensive Wall Mirror on One Stop Market. The link is __SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED",
            "string_note": "",
            "reference_answer_raw_annotation": "__SHOPPING__/wall-decorations-decorative-mirror-european-and-american-round-wooden-sun-flower-wall-mirror-hallway-entrance-living-room-bathroom-wall-hanging-mirror-70cm.html"
        }
    },
    {
        "task_id": 50034,
        "sites": [
            "reddit",
            "shopping"
        ],
        "start_url": "__SHOPPING__",
        "start_url_lite": "__REDDIT__/f/science",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Find the {{price}} {{item}} and post it on the forum {{forum}} with the following messages. Title: One Stop Market Info, Body: 'This is the {{price}} {{item}} on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "intent": "Find the cheapest Smartwatch and post it on the forum gadgets with the following messages. Title: One Stop Market Info, Body: 'This is the cheapest Smartwatch on One Stop Market. The link is ${link for the item}.'. Leave the URL field blank.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Find the specified item on the specified forum and post it to Reddit.",
        "instantiation_dict": {
            "start_url": "__SHOPPING__",
            "start_url_lite": "__REDDIT__/f/science",
            "price": "cheapest",
            "forum": "gadgets",
            "item": "Smartwatch",
            "link": "__SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/gadgets",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "One Stop Market Info"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "This is the cheapest Smartwatch on One Stop Market. The link is __SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED",
            "string_note": "",
            "reference_answer_raw_annotation": "__SHOPPING__/padgene-bluetooth-smartwatch-touchscreen-wrist-smart-phone-watch-sports-fitness-tracker-with-sim-sd-card-slot-camera-pedometer-compatible-with-android-smartphone-for-kids-men-women.html"
        }
    },
    {
        "task_id": 50040,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "List the common types of skills in Tumbling, which is written in the Gymnastics page on Wikipedia. Post them to a related forum on Reddit. Follow the instructions below when posting:\nTitle: common types of skills in Tumbling, Body: {skill1, skill2, skill3, ...}.",
        "intent": "List the common types of skills in Tumbling, which is written in the Gymnastics page on Wikipedia. Post them to a related forum on Reddit. Follow the instructions below when posting:\nTitle: common types of skills in Tumbling, Body: {skill1, skill2, skill3, ...}.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, open the Wikipedia Gymnastics page and list the skills related to Tumbling. Then, post it to a related forum on Reddit.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "__REDDIT__/user/MarvelsGrantMan136/submissions",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Gymnastics",
            "forum": "sports",
            "contents": "Round-off, End Skill, Flick, Whip, Double Somersault, Triple Somersault, Twisting Somersault, Combination Somersault, Transition Skill"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/sports",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "common types of skills in Tumbling"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Round-off, End Skill, Flick, Whip, Double Somersault, Triple Somersault, Twisting Somersault, Combination Somersault, Transition Skill"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50050,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
        "intent": "List all the dynasties or kingdoms under the Medieval period in the Sasanian Empire page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {dynasties or kingdoms under the Medieval period in Sasanian Empire}, Body: {kingdom1}, {kingdom2}, {kingdom3}, ...}.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "element": "dynasties or kingdoms under the Medieval period",
            "region": "Sasanian Empire",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Sasanian_Empire",
            "answer": "kingdom",
            "forum": "history",
            "contents": "Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, Dabuyids, Bavandids, Masmughans of Damavand, Baduspanids, Justanids, Alid dynasties, Tahirid dynasty, Samanid Empire, Saffarid dynasty, Ghurid dynasty, Sajid dynasty, Sallarid dynasty, Ziyarid dynasty, Ilyasids, Buyid dynasty, Rawadid dynasty, Hasanwayhids, Ghaznavid dynasty, Annazids, Kakuyids, Nasrid dynasty, Shabankara, Seljuk Empire, Khwarazmian dynasty, Eldiguzids, Atabegs of Yazd, Salghurids, Hazaraspids, Pishkinid dynasty, Khorshidi dynasty, Qutlugh-Khanids, Mihrabanids, Kurt dynasty, Ilkhanate Empire, Chobanid dynasty, Muzaffarid dynasty, Jalayirid Sultanate, Sarbadars, Injuids, Afrasiyab dynasty, Mar'ashis, Timurid Empire, Kar-Kiya dynasty, Qara Qoyunlu, Aq Qoyunlu"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/history",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "dynasties or kingdoms under the Medieval period in Sasanian Empire"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Rashidun Caliphate, Umayyad Caliphate, Abbasid Caliphate, Dabuyids, Bavandids, Masmughans of Damavand, Baduspanids, Justanids, Alid dynasties, Tahirid dynasty, Samanid Empire, Saffarid dynasty, Ghurid dynasty, Sajid dynasty, Sallarid dynasty, Ziyarid dynasty, Ilyasids, Buyid dynasty, Rawadid dynasty, Hasanwayhids, Ghaznavid dynasty, Annazids, Kakuyids, Nasrid dynasty, Shabankara, Seljuk Empire, Khwarazmian dynasty, Eldiguzids, Atabegs of Yazd, Salghurids, Hazaraspids, Pishkinid dynasty, Khorshidi dynasty, Qutlugh-Khanids, Mihrabanids, Kurt dynasty, Ilkhanate Empire, Chobanid dynasty, Muzaffarid dynasty, Jalayirid Sultanate, Sarbadars, Injuids, Afrasiyab dynasty, Mar'ashis, Timurid Empire, Kar-Kiya dynasty, Qara Qoyunlu, Aq Qoyunlu"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50051,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
        "intent": "List all the dynasties, state, or emirates of the Arabian Peninsula in the Umayyad Caliphate page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {dynasties, state, or emirates of the Arabian Peninsula in Umayyad Caliphate}, Body: {dynasties1}, {dynasties2}, {dynasties3}, ...}.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "element": "dynasties, state, or emirates of the Arabian Peninsula",
            "region": "Umayyad Caliphate",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Umayyad_Caliphate",
            "answer": "dynasties",
            "forum": "history",
            "contents": "Imamate of Oman, Ziyadids, Yufirids, Ukhaidhirds, Rassids, Qarmatians, Wajihids, Sharifate of Mecca, Sulayhids, Sulaymanids, Uyunids, Zurayids, Nabhanids, Mahdids, Rasulids, Usfurids, Jarwanids, Kathirids, Tahirids, Jabrids, Qasimids, Ya'arubids, Upper Yafa, Muscat and Oman, Rashidids, Qu'aitids, Emirate of Beihan, Idrisids, Mutawakkilite Kingdom"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/history",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "dynasties, state, or emirates of the Arabian Peninsula in Umayyad Caliphate"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Imamate of Oman, Ziyadids, Yufirids, Ukhaidhirds, Rassids, Qarmatians, Wajihids, Sharifate of Mecca, Sulayhids, Sulaymanids, Uyunids, Zurayids, Nabhanids, Mahdids, Rasulids, Usfurids, Jarwanids, Kathirids, Tahirids, Jabrids, Qasimids, Ya'arubids, Upper Yafa, Muscat and Oman, Rashidids, Qu'aitids, Emirate of Beihan, Idrisids, Mutawakkilite Kingdom"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50052,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "List all the {{element}} in the {{region}} page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {{{element}} in {{region}}}, Body: {{{answer}}1}, {{{answer}}2}, {{{answer}}3}, ...}.",
        "intent": "List all the Japanese historical periods in the Japan page on Wikipedia. Post it to a related Reddit forum. Follow the instructions below when posting:\nTitle: {Japanese historical periods in Japan}, Body: {period1}, {period2}, {period3}, ...}.",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, list all the {{element}} in the {{region}} page on Wikipedia. Then, post it to a related Reddit forum. Follow the instructions when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "element": "Japanese historical periods",
            "region": "Japan",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/History_of_Japan",
            "answer": "period",
            "forum": "history",
            "contents": "Paleolithic, Jmon, Yayoi, Kofun, Asuka, Nara, Heian, Kamakura, Kenmu Restoration, Muromachi, AzuchiMomoyama, Edo, Meiji, Taish, Shwa, Heisei, Reiwa"
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/history",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "Japanese historical periods in Japan"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Paleolithic, Jmon, Yayoi, Kofun, Asuka, Nara, Heian, Kamakura, Kenmu Restoration, Muromachi, AzuchiMomoyama, Edo, Meiji, Taish, Shwa, Heisei, Reiwa"
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50060,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
        "intent": "Take the explanation on CAD in the Electronics page on Wikipedia and post it to the forum technology. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: CAD of Electronics, Body: {the explanation of Electronics}",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Electronics",
            "topic": "Electronics",
            "section": "CAD",
            "forum": "technology",
            "gt_sentence": "Today's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others."
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/technology",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "CAD of Electronics"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Today's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50061,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
        "intent": "Take the explanation on Piezo motors in the Robotics page on Wikipedia and post it to the forum technology. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: Piezo motors of Robotics, Body: {the explanation of Robotics}",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Robotics",
            "topic": "Robotics",
            "section": "Piezo motors",
            "forum": "technology",
            "gt_sentence": "Recent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line. Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size. These motors are already available commercially, and being used on some robots."
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/technology",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "Piezo motors of Robotics"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Recent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line. Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size. These motors are already available commercially, and being used on some robots."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50062,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
        "intent": "Take the explanation on Batting and baserunning in the Baseball page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: Batting and baserunning of Baseball, Body: {the explanation of Baseball}",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Baseball",
            "topic": "Baseball",
            "section": "Batting and baserunning",
            "forum": "sports",
            "gt_sentence": "Several basic offensive tactics come into play with a runner on first base, including the fundamental choice of whether to attempt a steal of second base. The hit and run is sometimes employed, with a skillful contact hitter, the runner takes off with the pitch, drawing the shortstop or second baseman over to second base, creating a gap in the infield for the batter to poke the ball through. The sacrifice bunt, calls for the batter to focus on making soft contact with the ball, so that it rolls a short distance into the infield, allowing the runner to advance into scoring position as the batter is thrown out at first. A batter, particularly one who is a fast runner, may also attempt to bunt for a hit. A sacrifice bunt employed with a runner on third base, aimed at bringing that runner home, is known as a squeeze play. With a runner on third and fewer than two outs, a batter may instead concentrate on hitting a fly ball that, even if it is caught, will be deep enough to allow the runner to tag up and scorea successful batter, in this case, gets credit for a sacrifice fly. In order to increase the chance of advancing a batter to first base via a walk, the manager will sometimes signal a batter who is ahead in the count (i.e., has more balls than strikes) to take, or not swing at, the next pitch. The batter's potential reward of reaching base (via a walk) exceeds the disadvantage if the next pitch is a strike."
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/sports",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "Batting and baserunning of Baseball"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "Several basic offensive tactics come into play with a runner on first base, including the fundamental choice of whether to attempt a steal of second base. The hit and run is sometimes employed, with a skillful contact hitter, the runner takes off with the pitch, drawing the shortstop or second baseman over to second base, creating a gap in the infield for the batter to poke the ball through. The sacrifice bunt, calls for the batter to focus on making soft contact with the ball, so that it rolls a short distance into the infield, allowing the runner to advance into scoring position as the batter is thrown out at first. A batter, particularly one who is a fast runner, may also attempt to bunt for a hit. A sacrifice bunt employed with a runner on third base, aimed at bringing that runner home, is known as a squeeze play. With a runner on third and fewer than two outs, a batter may instead concentrate on hitting a fly ball that, even if it is caught, will be deep enough to allow the runner to tag up and scorea successful batter, in this case, gets credit for a sacrifice fly. In order to increase the chance of advancing a batter to first base via a walk, the manager will sometimes signal a batter who is ahead in the count (i.e., has more balls than strikes) to take, or not swing at, the next pitch. The batter's potential reward of reaching base (via a walk) exceeds the disadvantage if the next pitch is a strike."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50063,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
        "intent": "Take the explanation on World cricket in the 20th century in the Cricket page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: World cricket in the 20th century of Cricket, Body: {the explanation of Cricket}",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Cricket",
            "topic": "Cricket",
            "section": "World cricket in the 20th century",
            "forum": "sports",
            "gt_sentence": "The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott."
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/sports",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "World cricket in the 20th century of Cricket"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. Test cricket continued to expand during the 20th century with the addition of the West Indies (1928), New Zealand (1930) and India (1932) before the Second World War and then Pakistan (1952), Sri Lanka (1982), Zimbabwe (1992), Bangladesh (2000), Ireland and Afghanistan (both 2018) in the post-war period. South Africa was banned from international cricket from 1970 to 1992 as part of the apartheid boycott."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50064,
        "sites": [
            "reddit",
            "wikipedia"
        ],
        "start_url": "__REDDIT__",
        "start_url_lite": "",
        "storage_state": "./.auth/reddit_state.json",
        "intent_template": "Take the explanation on {{section}} in the {{topic}} page on Wikipedia and post it to the forum {{forum}}. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: {{section}} of {{topic}}, Body: {the explanation of {{topic}}}",
        "intent": "Take the explanation on winter game in the Olympic page on Wikipedia and post it to the forum sports. Take the explanation word for word. Also, remove citations (e.g., [1]). Follow the instructions below when posting:\nTitle: winter game of Olympic, Body: {the explanation of Olympic}",
        "required_obs": "any",
        "required_wait": true,
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, get the {{section}} of {{topic}} on Wikipedia and post it to Reddit's {{forum}}. Follow the rules when posting.",
        "instantiation_dict": {
            "start_url": "__REDDIT__",
            "start_url_lite": "",
            "wiki_url": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Olympic_Games",
            "topic": "Olympic",
            "section": "winter game",
            "forum": "sports",
            "gt_sentence": "The Winter Olympics was created to feature snow and ice sports that were logistically impossible to hold during the Summer Games. Figure skating (in 1908 and 1920) and ice hockey (in 1920) were featured as Olympic events at the Summer Olympics. The IOC desired to expand this list of sports to encompass other winter activities. At the 1921 Olympic Congress in Lausanne, it was decided to hold a winter version of the Olympic Games. A winter sports week (it was actually 11 days) was held in 1924 in Chamonix, France, in connection with the Paris Games held three months later; this event became the first Winter Olympic Games. Although it was intended that the same country host both the Winter and Summer Games in a given year, this idea was quickly abandoned. The IOC mandated that the Winter Games be celebrated every four years in the same year as their summer counterpart. This tradition was upheld through the 1992 Games in Albertville, France; after that, beginning with the 1994 Games, the Winter Olympics were held every four years, two years after each Summer Olympics."
        },
        "eval": {
            "eval_types": [
                "url_match",
                "program_html"
            ],
            "reference_answers": null,
            "reference_url": "__REDDIT__/f/sports",
            "program_html": [
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__title').outerText",
                    "required_contents": {
                        "exact_match": "winter game of Olympic"
                    }
                },
                {
                    "url": "func:reddit_get_post_url('__last_url__')",
                    "locator": "document.querySelector('.submission__body').outerText",
                    "required_contents": {
                        "must_include": [
                            "The Winter Olympics was created to feature snow and ice sports that were logistically impossible to hold during the Summer Games. Figure skating (in 1908 and 1920) and ice hockey (in 1920) were featured as Olympic events at the Summer Olympics. The IOC desired to expand this list of sports to encompass other winter activities. At the 1921 Olympic Congress in Lausanne, it was decided to hold a winter version of the Olympic Games. A winter sports week (it was actually 11 days) was held in 1924 in Chamonix, France, in connection with the Paris Games held three months later; this event became the first Winter Olympic Games. Although it was intended that the same country host both the Winter and Summer Games in a given year, this idea was quickly abandoned. The IOC mandated that the Winter Games be celebrated every four years in the same year as their summer counterpart. This tradition was upheld through the 1992 Games in Albertville, France; after that, beginning with the 1994 Games, the Winter Olympics were held every four years, two years after each Summer Olympics."
                        ]
                    }
                }
            ],
            "url_note": "GOLD in PRED"
        }
    },
    {
        "task_id": 50070,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/toothbrushes-accessories.html?product_list_order=price",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Beauty & Personal Care > Oral Care > Toothbrushes & Accessories\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"beauty_personal_care_toothbrushes.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/beauty-personal-care/oral-care/toothbrushes-accessories.html?product_list_order=price",
            "csv_file_name": "beauty_personal_care_toothbrushes.csv",
            "category": "Beauty & Personal Care > Oral Care > Toothbrushes & Accessories",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09Q8Z9B2M\",\"$0.01\",\"\",\"B09Q8Z9B2M\"\n\"B09QCXXN5M\",\"$0.01\",\"\",\"B09QCXXN5M\"\n\"B09NXQMFGK\",\"$0.10\",\"753014879611\",\"B09NXQMFGK\"\n\"B09MH2BQ4Z\",\"$0.49\",\"\",\"B09MHF3YWQ\"\n\"B09P1DSHYS\",\"$0.49\",\"\",\"B09P1DSHYS\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/beauty_personal_care_toothbrushes.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09Q8Z9B2M\",\"$0.01\",\"\",\"B09Q8Z9B2M\"\n\"B09QCXXN5M\",\"$0.01\",\"\",\"B09QCXXN5M\"\n\"B09NXQMFGK\",\"$0.10\",\"753014879611\",\"B09NXQMFGK\"\n\"B09MH2BQ4Z\",\"$0.49\",\"\",\"B09MHF3YWQ\"\n\"B09P1DSHYS\",\"$0.49\",\"\",\"B09P1DSHYS\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50071,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Clothing, Shoes & Jewelry > Men > Shoes\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"men_shoes.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/shoes.html?product_list_order=price",
            "csv_file_name": "men_shoes.csv",
            "category": "Clothing, Shoes & Jewelry > Men > Shoes",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09J4J94N3\",\"$1.25\",\"\",\"B09J4HL38Z\"\n\"B00AOQ6XRE\",\"$1.47\",\"\",\"B00DOL3PJA\"\n\"B01J4MM3KO\",\"$1.71\",\"\",\"B01J4MM3KO\"\n\"B08SXRCXBM\",\"$2.36\",\"\",\"B08SXRCXBM\"\n\"B09J2GM8CT\",\"$2.66\",\"\",\"B09J2FYGTB\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/men_shoes.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09J4J94N3\",\"$1.25\",\"\",\"B09J4HL38Z\"\n\"B00AOQ6XRE\",\"$1.47\",\"\",\"B00DOL3PJA\"\n\"B01J4MM3KO\",\"$1.71\",\"\",\"B01J4MM3KO\"\n\"B08SXRCXBM\",\"$2.36\",\"\",\"B08SXRCXBM\"\n\"B09J2GM8CT\",\"$2.66\",\"\",\"B09J2FYGTB\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50072,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/office-products/office-furniture-lighting/chairs-sofas.html?product_list_order=price",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Office Products > Office Furniture & Lighting > Chairs & Sofas\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"office_furniture_chairs.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/office-products/office-furniture-lighting/chairs-sofas.html?product_list_order=price",
            "csv_file_name": "office_furniture_chairs.csv",
            "category": "Office Products > Office Furniture & Lighting > Chairs & Sofas",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07ZNNJW9S\",\"$25.21\",\"\",\"\"\n\"B09DPT467Z\",\"$36.99\",\"\",\"\"\n\"B09687YJB7\",\"$37.18\",\"\",\"\"\n\"B07XWYFKRH\",\"$37.45\",\"\",\"\"\n\"B07D9GR9KH\",\"$48.82\",\"\",\"\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/office_furniture_chairs.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07ZNNJW9S\",\"$25.21\",\"\",\"\"\n\"B09DPT467Z\",\"$36.99\",\"\",\"\"\n\"B09687YJB7\",\"$37.18\",\"\",\"\"\n\"B07XWYFKRH\",\"$37.45\",\"\",\"\"\n\"B07D9GR9KH\",\"$48.82\",\"\",\"\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50073,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/electronics/home-audio/speakers.html?product_list_order=price",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Electronics > Home Audio > Speakers\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"home_audio_speakers.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/electronics/home-audio/speakers.html?product_list_order=price",
            "csv_file_name": "home_audio_speakers.csv",
            "category": "Electronics > Home Audio > Speakers",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07QF5YH5D\",\"$5.83\",\"\",\"\"\n\"B0051JS746\",\"$5.84\",\"\",\"\"\n\"B015D7FN1K\",\"$5.99\",\"\",\"\"\n\"B096L1MT9Y\",\"$6.28\",\"\",\"\"\n\"B01CGWXHLI\",\"$6.62\",\"\",\"\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/home_audio_speakers.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B07QF5YH5D\",\"$5.83\",\"\",\"\"\n\"B0051JS746\",\"$5.84\",\"\",\"\"\n\"B015D7FN1K\",\"$5.99\",\"\",\"\"\n\"B096L1MT9Y\",\"$6.28\",\"\",\"\"\n\"B01CGWXHLI\",\"$6.62\",\"\",\"\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50074,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/video-games/pc/virtual-reality.html?product_list_order=price",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather the 5 lowest-priced items from OneStopShop that are in the \"{{category}}\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather the 5 lowest-priced items from OneStopShop that are in the \"Video Games > PC > Virtual Reality\" category. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"pc_virtual_reality.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category. Then, sort the items by price and select the 5 lowest-priced items.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/video-games/pc/virtual-reality.html?product_list_order=price",
            "csv_file_name": "pc_virtual_reality.csv",
            "category": "Video Games > PC > Virtual Reality",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B099RTD42D\",\"$2.39\",\"\",\"\"\n\"B09165PG3J\",\"$7.08\",\"\",\"\"\n\"B08K2TS1P6\",\"$7.99\",\"\",\"\"\n\"B09KN69C4Q\",\"$9.99\",\"\",\"\"\n\"B08RN2KB1L\",\"$12.74\",\"\",\"\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/pc_virtual_reality.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B099RTD42D\",\"$2.39\",\"\",\"\"\n\"B09165PG3J\",\"$7.08\",\"\",\"\"\n\"B08K2TS1P6\",\"$7.99\",\"\",\"\"\n\"B09KN69C4Q\",\"$9.99\",\"\",\"\"\n\"B08RN2KB1L\",\"$12.74\",\"\",\"\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50080,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/beauty-personal-care/salon-spa-equipment.html?price=1100-1200",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather all items from OneStopShop that are in the \"Beauty & Personal Care > Salon & Spa Equipment\" category and have a price between $1,100.00 to $1,199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"beauty_personal_care_salon_spa_equipment_1100_1200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/beauty-personal-care/salon-spa-equipment.html?price=1100-1200",
            "csv_file_name": "beauty_personal_care_salon_spa_equipment_1100_1200.csv",
            "category": "Beauty & Personal Care > Salon & Spa Equipment",
            "price_l": "$1,100.00",
            "price_r": "$1,199.99",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09NKFNG45\",\"$1,146.03\",\"\",\"B09NKFNG45\"\n\"B08RY69JS1\",\"$1,160.83\",\"\",\"\"\n\"B083ZFXCXZ\",\"$1,189.00\",\"880396373908\",\"B083ZFXCXZ\"\n\"B09NQZ94VD\",\"$1,196.67\",\"\",\"B09NQZ94VD\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/beauty_personal_care_salon_spa_equipment_1100_1200.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09NKFNG45\",\"$1,146.03\",\"\",\"B09NKFNG45\"\n\"B08RY69JS1\",\"$1,160.83\",\"\",\"\"\n\"B083ZFXCXZ\",\"$1,189.00\",\"880396373908\",\"B083ZFXCXZ\"\n\"B09NQZ94VD\",\"$1,196.67\",\"\",\"B09NQZ94VD\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50081,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/sports-outdoors/sports.html?price=100-200",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather all items from OneStopShop that are in the \"Sports & Outdoors > Sports\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"sports_outdoors_sports_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/sports-outdoors/sports.html?price=100-200",
            "csv_file_name": "sports_outdoors_sports_100_200.csv",
            "category": "Sports & Outdoors > Sports",
            "price_l": "$100.00",
            "price_r": "$199.99",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B00B2IELIG\",\"$109.99\",\"\",\"\"\n\"B09BNKTZDB\",\"$124.99\",\"\",\"\"\n\"B09HTFXCKN\",\"$135.99\",\"\",\"\"\n\"B004WSL5B4\",\"$169.95\",\"\",\"\"\n\"B0964C84N3\",\"$169.95\",\"\",\"B0964FH235\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/sports_outdoors_sports_100_200.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B00B2IELIG\",\"$109.99\",\"\",\"\"\n\"B09BNKTZDB\",\"$124.99\",\"\",\"\"\n\"B09HTFXCKN\",\"$135.99\",\"\",\"\"\n\"B004WSL5B4\",\"$169.95\",\"\",\"\"\n\"B0964C84N3\",\"$169.95\",\"\",\"B0964FH235\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50082,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/clothing.html?price=400-500",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather all items from OneStopShop that are in the \"Clothing, Shoes & Jewelry > Men > Clothing\" category and have a price between $400.00 to $499.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"clothing_shoes_jewelry_men_clothing_400_500.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/clothing-shoes-jewelry/men/clothing.html?price=400-500",
            "csv_file_name": "clothing_shoes_jewelry_men_clothing_400_500.csv",
            "category": "Clothing, Shoes & Jewelry > Men > Clothing",
            "price_l": "$400.00",
            "price_r": "$499.99",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09R47MDNF\",\"$428.60\",\"\",\"\"\n\"B09QM4VJLM\",\"$431.55\",\"\",\"\"\n\"B09PBM4YL6\",\"$443.35\",\"\",\"\"\n\"B09PB1G4QW\",\"$460.46\",\"\",\"\"\n\"B08LDVH7R7\",\"$479.20\",\"\",\"B08LDY9BHC\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/clothing_shoes_jewelry_men_clothing_400_500.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B09R47MDNF\",\"$428.60\",\"\",\"\"\n\"B09QM4VJLM\",\"$431.55\",\"\",\"\"\n\"B09PBM4YL6\",\"$443.35\",\"\",\"\"\n\"B09PB1G4QW\",\"$460.46\",\"\",\"\"\n\"B08LDVH7R7\",\"$479.20\",\"\",\"B08LDY9BHC\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50083,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/electronics/portable-audio-video/radios.html?price=100-200",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather all items from OneStopShop that are in the \"Electronics > Portable Audio & Video > Radios\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"electronics_portable_audio_video_radios_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/electronics/portable-audio-video/radios.html?price=100-200",
            "csv_file_name": "electronics_portable_audio_video_radios_100_200.csv",
            "category": "Electronics > Portable Audio & Video > Radios",
            "price_l": "$100.00",
            "price_r": "$199.99",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B08R1RLYWN\",\"$101.36\",\"\",\"\"\n\"B01J3ZD3WY\",\"$105.00\",\"\",\"\"\n\"B0002QX3YC\",\"$129.99\",\"\",\"\"\n\"B09STGNKYH\",\"$138.99\",\"\",\"\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/electronics_portable_audio_video_radios_100_200.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B08R1RLYWN\",\"$101.36\",\"\",\"\"\n\"B01J3ZD3WY\",\"$105.00\",\"\",\"\"\n\"B0002QX3YC\",\"$129.99\",\"\",\"\"\n\"B09STGNKYH\",\"$138.99\",\"\",\"\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50084,
        "sites": [
            "gitlab",
            "shopping"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html?price=100-200",
        "storage_state": "./.auth/gitlab.shopping_state.json",
        "intent_template": "Gather all items from OneStopShop that are in the \"{{category}}\" category and have a price between {{price_l}} to {{price_r}}. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "intent": "Gather all items from OneStopShop that are in the \"Cell Phones & Accessories > Accessories > Automobile Accessories\" category and have a price between $100.00 to $199.99. Then, create a repository named \"byteblaze/shopping\" (if it does not already exist), and create a CSV file named \"cell_phones_accessories_accessories_automobile_accessories_100_200.csv\" within this repository. Each row in the CSV file should include the gathered item's SKU, price, UPC (if exist), and ASIN (if exist), and all fields must be enclosed in double quotation marks. Leave fields empty by using \"\" when the UPC or ASIN does not exist. The first row must be a header with the field names \"SKU\", \"price\", \"UPC\", and \"ASIN\". All prices must be formatted to exactly two decimal places and must include a \"$\" symbol. The items in the CSV file must be sorted primarily in ascending order by price, and secondarily in ascending order by SKU when prices are equal. An example of the CSV format is as follows:\n\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"ABCD0003\",\"$2,015.00\",\"EFGH1002\",\"\"\n\"ABCD0001\",\"$2,430.00\",\"\",\"IJKL2002\"\n\"ABCD0002\",\"$2,430.00\",\"EFGH1001\",\"IJKL2001\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "long-term",
        "description": "Access the OneStopShop website and filter the items in the specified category with prices in the given range.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING__/cell-phones-accessories/accessories/automobile-accessories.html?price=100-200",
            "csv_file_name": "cell_phones_accessories_accessories_automobile_accessories_100_200.csv",
            "category": "Cell Phones & Accessories > Accessories > Automobile Accessories",
            "price_l": "$100.00",
            "price_r": "$199.99",
            "csv_content": "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B084PZRSYF\",\"$114.99\",\"\",\"\"\n\"B01CIATFB4\",\"$119.00\",\"\",\"\"\n\"B08GGB73PR\",\"$136.99\",\"\",\"\"\n\"B0155HBNR6\",\"$149.00\",\"\",\"\"\n\"B09NKMX6RY\",\"$149.96\",\"\",\"\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping/-/raw/main/cell_phones_accessories_accessories_automobile_accessories_100_200.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"SKU\",\"price\",\"UPC\",\"ASIN\"\n\"B084PZRSYF\",\"$114.99\",\"\",\"\"\n\"B01CIATFB4\",\"$119.00\",\"\",\"\"\n\"B08GGB73PR\",\"$136.99\",\"\",\"\"\n\"B0155HBNR6\",\"$149.00\",\"\",\"\"\n\"B09NKMX6RY\",\"$149.96\",\"\",\"\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50090,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
        "intent": "Look for the population of the 7 continents on Wikipedia and output the name of the continents in the order of their population (larger first) to readme.md in a new repository named continent_ranking. The output should be in Markdown format.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
            "content": "the population of the 7 continents",
            "output": "the name of the continents in the order of their population (larger first)",
            "repo_name": "continent_ranking",
            "misc": "",
            "answer": "- Asia\n- Africa\n- Europe\n- North America\n- South America\n- Oceania\n- Antarctica",
            "difficulty": "medium"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/continent_ranking/-/raw/main/readme.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "- Asia\n- Africa\n- Europe\n- North America\n- South America\n- Oceania\n- Antarctica"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50091,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Japanese_Nobel_laureates",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
        "intent": "Look for Japanese Nobel Prize winners on Wikipedia and output the names by the category to readme.md in a new repository named Nobel_Prize. The output should be in Markdown format. Put each category in a separate section. Sort the sections alphabetically by their category name. The section title (category name) should be a level 1 header. The winner names in each category should also be in alphabetical order.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Japanese_Nobel_laureates",
            "content": "Japanese Nobel Prize winners",
            "output": "the names by the category",
            "repo_name": "Nobel_Prize",
            "misc": " Put each category in a separate section. Sort the sections alphabetically by their category name. The section title (category name) should be a level 1 header. The winner names in each category should also be in alphabetical order.",
            "answer": "# Chemistry\n- Akira Suzuki\n- Akira Yoshino\n- Ei-ichi Negishi\n- Hideki Shirakawa\n- Kenichi Fukui\n- Koichi Tanaka\n- Osamu Shimomura\n- Ryji Noyori\n# Literature\n- Kazuo Ishiguro\n- Kenzabur e\n- Yasunari Kawabata\n# Peace\n- Eisaku Sat\n# Physics\n- Hideki Yukawa\n- Hiroshi Amano\n- Isamu Akasaki\n- Leo Esaki\n- Makoto Kobayashi\n- Masatoshi Koshiba\n- Shuji Nakamura\n- Sin-Itiro Tomonaga\n- Syukuro Manabe\n- Takaaki Kajita\n- Toshihide Maskawa\n- Yoichiro Nambu\n# Physiology or Medicine\n- Satoshi mura\n- Shinya Yamanaka\n- Susumu Tonegawa\n- Tasuku Honjo\n- Yoshinori Ohsumi",
            "difficulty": "medium"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/Nobel_Prize/-/raw/main/readme.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "# Chemistry\n- Akira Suzuki\n- Akira Yoshino\n- Ei-ichi Negishi\n- Hideki Shirakawa\n- Kenichi Fukui\n- Koichi Tanaka\n- Osamu Shimomura\n- Ryji Noyori\n# Literature\n- Kazuo Ishiguro\n- Kenzabur e\n- Yasunari Kawabata\n# Peace\n- Eisaku Sat\n# Physics\n- Hideki Yukawa\n- Hiroshi Amano\n- Isamu Akasaki\n- Leo Esaki\n- Makoto Kobayashi\n- Masatoshi Koshiba\n- Shuji Nakamura\n- Sin-Itiro Tomonaga\n- Syukuro Manabe\n- Takaaki Kajita\n- Toshihide Maskawa\n- Yoichiro Nambu\n# Physiology or Medicine\n- Satoshi mura\n- Shinya Yamanaka\n- Susumu Tonegawa\n- Tasuku Honjo\n- Yoshinori Ohsumi"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50092,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Olympic_medalists_in_baseball",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
        "intent": "Look for countries that got a medal for baseball on Wikipedia and output the names of the countries to readme.md in a new repository named olympic_baseball. The output should be in Markdown format. Put each event in a separate section. Sort the sections in chronological order. The section title (host city name) should be a level 1 header. The countries should be in a numbered list.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/List_of_Olympic_medalists_in_baseball",
            "content": "countries that got a medal for baseball",
            "output": "the names of the countries",
            "repo_name": "olympic_baseball",
            "misc": " Put each event in a separate section. Sort the sections in chronological order. The section title (host city name) should be a level 1 header. The countries should be in a numbered list.",
            "answer": "# Barcelona\n1. Cuba\n2. Chinese Taipei\n3. Japan\n# Atlanta\n1. Cuba\n2. Japan\n3. United States\n# Sydney\n1. United States\n2. Cuba\n3. South Korea\n# Athens\n1. Cuba\n2. Australia\n3. Japan\n# Beijing\n1. South Korea\n2. Cuba\n3. United States\n# Tokyo\n1. Japan\n2. United States\n3. Dominican Republic",
            "difficulty": "medium"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/olympic_baseball/-/raw/main/readme.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "# Barcelona\n1. Cuba\n2. Chinese Taipei\n3. Japan\n# Atlanta\n1. Cuba\n2. Japan\n3. United States\n# Sydney\n1. United States\n2. Cuba\n3. South Korea\n# Athens\n1. Cuba\n2. Australia\n3. Japan\n# Beijing\n1. South Korea\n2. Cuba\n3. United States\n# Tokyo\n1. Japan\n2. United States\n3. Dominican Republic"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50093,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Mercury_(planet)",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Look for {{content}} on Wikipedia and output {{output}} to readme.md in a new repository named {{repo_name}}. The output should be in Markdown format.{{misc}}",
        "intent": "Look for the velocity of rotation on the equator for each of the 8 planets on Wikipedia and output the names of the planets and the velocity to readme.md in a new repository named planet_velocity. The output should be in Markdown format. Output the velocity in m/s with three digits. If the velocity exceeds 1 km/s, output it in km/s instead. Truncate any unnecessary digits if needed. Each item should be formatted as (Planet Name):(number)(unit)",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article from the description. It should then create a new repository in GitLab, create a readme, and output the information from Wikipedia to the readme in Markdown.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Mercury_(planet)",
            "content": "the velocity of rotation on the equator for each of the 8 planets",
            "output": "the names of the planets and the velocity",
            "repo_name": "planet_velocity",
            "misc": " Output the velocity in m/s with three digits. If the velocity exceeds 1 km/s, output it in km/s instead. Truncate any unnecessary digits if needed. Each item should be formatted as (Planet Name):(number)(unit)",
            "answer": "- Mercury:3.02m/s\n- Venus:1.81m/s\n- Earth:465m/s\n- Mars:241m/s\n- Jupiter:12.6km/s\n- Saturn:9.87km/s\n- Uranus:2.59km/s\n- Neptune:2.68km/s",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/planet_velocity/-/raw/main/readme.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "- Mercury:3.02m/s\n- Venus:1.81m/s\n- Earth:465m/s\n- Mars:241m/s\n- Jupiter:12.6km/s\n- Saturn:9.87km/s\n- Uranus:2.59km/s\n- Neptune:2.68km/s"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50100,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "intent": "Replace the readme of the Amazon ML Challenge 2021 repository with the first paragraph of the Wikipedia article for Amazon. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Amazon_(company)",
            "readme_url": "__GITLAB__/abisubramanya27/Amazon_ML_Challenge_2021/-/raw/master/README.md",
            "repository": "the Amazon ML Challenge 2021 repository",
            "wiki_item": "Amazon",
            "answer": "Amazon.com, Inc. (/mzn/ AM--zon) is an American multinational technology company which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It has been referred to as \"one of the most influential economic and cultural forces in the world\", and is one of the world's most valuable brands. It is one of the Big Five American information technology companies, alongside Alphabet, Apple, Meta, and Microsoft.",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/abisubramanya27/Amazon_ML_Challenge_2021/-/raw/master/README.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "Amazon.com, Inc. (/mzn/ AM--zon) is an American multinational technology company which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It has been referred to as \"one of the most influential economic and cultural forces in the world\", and is one of the world's most valuable brands. It is one of the Big Five American information technology companies, alongside Alphabet, Apple, Meta, and Microsoft."
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50101,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/WTFPL",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "intent": "Replace the readme of my repository with the Do What The F*ck You Want To Public License and with a shorter name with the first paragraph of the Wikipedia article for the license. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/WTFPL",
            "readme_url": "__GITLAB__/byteblaze/cloud-to-butt/-/raw/master/README.md",
            "repository": "my repository with the Do What The F*ck You Want To Public License and with a shorter name",
            "wiki_item": "the license",
            "answer": "WTFPL is a permissive free software license, compatible with the GNU GPL. As a public domain like license, the WTFPL is essentially the same as dedication to the public domain. It allows redistribution and modification of the work under any terms. The title is an abbreviation of \"Do What The Fuck You Want To Public License\".",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/cloud-to-butt/-/raw/master/README.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "WTFPL is a permissive free software license, compatible with the GNU GPL. As a public domain like license, the WTFPL is essentially the same as dedication to the public domain. It allows redistribution and modification of the work under any terms. The title is an abbreviation of \"Do What The Fuck You Want To Public License\"."
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50102,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/COVID-19",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "intent": "Replace the readme of the repository for a web app to check whether I had contacted the patient of covid-19 or not with the first paragraph of the Wikipedia article for the virus. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/COVID-19",
            "readme_url": "__GITLAB__/yjlou/2019-nCov/-/raw/master/README.md",
            "repository": "the repository for a web app to check whether I had contacted the patient of covid-19 or not",
            "wiki_item": "the virus",
            "answer": "Coronavirus disease 2019 (COVID-19) is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease spread worldwide, leading to the COVID-19 pandemic.",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/yjlou/2019-nCov/-/raw/master/README.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "Coronavirus disease 2019 (COVID-19) is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease spread worldwide, leading to the COVID-19 pandemic."
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50103,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Super_Mario_Bros.",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "intent": "Replace the readme of the repository that attempts to recreate the first level of Super Mario Bros. with the first paragraph of the Wikipedia article for the game. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Super_Mario_Bros.",
            "readme_url": "__GITLAB__/justinmeister/Mario-Level-1/-/raw/master/README.md",
            "repository": "the repository that attempts to recreate the first level of Super Mario Bros.",
            "wiki_item": "the game",
            "answer": "Super Mario Bros. is a platform game developed and published by Nintendo. The successor to the 1983 arcade game Mario Bros. and the first in the Super Mario series, it was released in 1985 for the Famicom in Japan. Following a limited US release for the Nintendo Entertainment System (NES), it was ported to international arcades for the Nintendo Vs. System in early 1986. The NES version received a wide release in North America that year and in PAL regions in 1987.",
            "difficulty": "medium"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/justinmeister/Mario-Level-1/-/raw/master/README.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "Super Mario Bros. is a platform game developed and published by Nintendo. The successor to the 1983 arcade game Mario Bros. and the first in the Super Mario series, it was released in 1985 for the Famicom in Japan. Following a limited US release for the Nintendo Entertainment System (NES), it was ported to international arcades for the Nintendo Vs. System in early 1986. The NES version received a wide release in North America that year and in PAL regions in 1987."
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50104,
        "sites": [
            "gitlab",
            "wikipedia"
        ],
        "start_url": "__WIKIPEDIA__",
        "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Generative_adversarial_network",
        "storage_state": "./.auth/gitlab_state.json",
        "intent_template": "Replace the readme of {{repository}} with the first paragraph of the Wikipedia article for {{wiki_item}}. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "intent": "Replace the readme of PyTorch implementations of GANs with the first paragraph of the Wikipedia article for the network. Add the readme file with README.md as the name if the it does not exist. Do not include any citation marks.",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "The agent must search for the appropriate Wikipedia article by choosing the suitable search keyword based on the description of the repository. It should then search for the repository in GitLab, create a readme if necessary, and replace the content of the readme with the first paragraph of the article.",
        "instantiation_dict": {
            "start_url": "__WIKIPEDIA__",
            "start_url_lite": "http://172.16.2.7:8888/wikipedia_en_all_maxi_2022-05/A/Generative_adversarial_network",
            "readme_url": "__GITLAB__/eriklindernoren/PyTorch-GAN/-/raw/master/README.md",
            "repository": "PyTorch implementations of GANs",
            "wiki_item": "the network",
            "answer": "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).",
            "difficulty": "medium"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/eriklindernoren/PyTorch-GAN/-/raw/master/README.md",
                    "locator": "document.querySelector(\"body > pre\").innerText",
                    "required_contents": {
                        "must_include": [
                            "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss)."
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50110,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"washington_newyork.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "washington_newyork.csv",
            "csv_content": "Name,Email,Phone,State/Province,Customer Since\nWilliam Chang,william.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:44 AM\"\nJessica Chang,jessica.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:26 AM\"\nJane Doe,jane.doe@gmail.com,2125551212,New York,\"Apr 23, 2023 12:13:19 AM\"\nRoberto Lopez,roberto.lopez@hotmail.com,2125551212,New York,\"Apr 23, 2023 12:13:12 AM\"\nJessica Nguyen,jessica.nguyen@gmail.com,2065551212,Washington,\"Apr 23, 2023 12:12:58 AM\"\nKate Jones,kate.jones@gmail.com,2125551212,New York,\"Apr 23, 2023 12:12:51 AM\"\nKatie Wong,katie.wong@hotmail.com,2065551212,Washington,\"Apr 19, 2023 5:46:37 PM\"\nAlex Martin,alex.martin@gmail.com,2125551212,New York,\"Apr 19, 2023 5:46:20 PM\"\nAdam Garcia,gamingpro456@gmail.com,2065555555,Washington,\"Apr 19, 2023 5:46:14 PM\"\nJohn Doe,johndoe123@gmail.com,2125551212,New York,\"Apr 19, 2023 5:45:37 PM\"\nJane Smith,janesmith@gmail.com,2065554321,Washington,\"Apr 19, 2023 5:45:24 PM\"\nJulia Williams,jla_7781@gmail.com,4567890123,New York,\"Apr 19, 2023 5:45:11 PM\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/washington_newyork.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "Name,Email,Phone,State/Province,Customer Since\nWilliam Chang,william.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:44 AM\"\nJessica Chang,jessica.chang@hotmail.com,2065551212,Washington,\"Apr 23, 2023 12:13:26 AM\"\nJane Doe,jane.doe@gmail.com,2125551212,New York,\"Apr 23, 2023 12:13:19 AM\"\nRoberto Lopez,roberto.lopez@hotmail.com,2125551212,New York,\"Apr 23, 2023 12:13:12 AM\"\nJessica Nguyen,jessica.nguyen@gmail.com,2065551212,Washington,\"Apr 23, 2023 12:12:58 AM\"\nKate Jones,kate.jones@gmail.com,2125551212,New York,\"Apr 23, 2023 12:12:51 AM\"\nKatie Wong,katie.wong@hotmail.com,2065551212,Washington,\"Apr 19, 2023 5:46:37 PM\"\nAlex Martin,alex.martin@gmail.com,2125551212,New York,\"Apr 19, 2023 5:46:20 PM\"\nAdam Garcia,gamingpro456@gmail.com,2065555555,Washington,\"Apr 19, 2023 5:46:14 PM\"\nJohn Doe,johndoe123@gmail.com,2125551212,New York,\"Apr 19, 2023 5:45:37 PM\"\nJane Smith,janesmith@gmail.com,2065554321,Washington,\"Apr 19, 2023 5:45:24 PM\"\nJulia Williams,jla_7781@gmail.com,4567890123,New York,\"Apr 19, 2023 5:45:11 PM\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50111,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"california_newjergy.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "california_newjergy.csv",
            "csv_content": "Name,Email,Phone,State/Province,Customer Since\nEmma Lopez,emma.lopez@gmail.com,6505551212,California,\"Apr 23, 2023 12:14:57 AM\"\nNatalie Kim,natalie.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:49 AM\"\nMatthew Kim,matthew.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:19 AM\"\nJulie Nguyen,julie.nguyen@gmail.com,3105551212,California,\"Apr 23, 2023 12:14:15 AM\"\nAmanda Kim,amanda.kim@gmail.com,2015551234,New Jersey,\"Apr 23, 2023 12:13:15 AM\"\nSam Wilson,sam.wilson@yahoo.com,3105551212,California,\"Apr 23, 2023 12:12:47 AM\"\nAlexander Thomas,alexander.thomas@hotmail.com,3235551212,California,\"Apr 19, 2023 5:46:50 PM\"\nJennifer White,jennifer.white@yahoo.com,2137418080,California,\"Apr 19, 2023 5:46:17 PM\"\nAlex Johnson,fitnessjunkie22@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:07 PM\"\nAva Brown,beachlover99@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:01 PM\"\nJane Smith,janesmith456@yahoo.com,3105555555,California,\"Apr 19, 2023 5:45:41 PM\"\nSarah Miller,helloworld@yahoo.com,5107819902,California,\"Apr 19, 2023 5:45:07 PM\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/california_newjergy.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "Name,Email,Phone,State/Province,Customer Since\nEmma Lopez,emma.lopez@gmail.com,6505551212,California,\"Apr 23, 2023 12:14:57 AM\"\nNatalie Kim,natalie.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:49 AM\"\nMatthew Kim,matthew.kim@gmail.com,2015551212,New Jersey,\"Apr 23, 2023 12:14:19 AM\"\nJulie Nguyen,julie.nguyen@gmail.com,3105551212,California,\"Apr 23, 2023 12:14:15 AM\"\nAmanda Kim,amanda.kim@gmail.com,2015551234,New Jersey,\"Apr 23, 2023 12:13:15 AM\"\nSam Wilson,sam.wilson@yahoo.com,3105551212,California,\"Apr 23, 2023 12:12:47 AM\"\nAlexander Thomas,alexander.thomas@hotmail.com,3235551212,California,\"Apr 19, 2023 5:46:50 PM\"\nJennifer White,jennifer.white@yahoo.com,2137418080,California,\"Apr 19, 2023 5:46:17 PM\"\nAlex Johnson,fitnessjunkie22@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:07 PM\"\nAva Brown,beachlover99@yahoo.com,3105555555,California,\"Apr 19, 2023 5:46:01 PM\"\nJane Smith,janesmith456@yahoo.com,3105555555,California,\"Apr 19, 2023 5:45:41 PM\"\nSarah Miller,helloworld@yahoo.com,5107819902,California,\"Apr 19, 2023 5:45:07 PM\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50112,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"florida_massachusetts.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "florida_massachusetts.csv",
            "csv_content": "Name,Email,Phone,State/Province,Customer Since\nIsabella Santos,isabella.santos@gmail.com,3055551212,Florida,\"Apr 23, 2023 12:14:32 AM\"\nSophia Young,sophia.young@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:14:05 AM\"\nRobert Johnson,robert.johnson@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:36 AM\"\nSamantha Wu,samantha.wu@yahoo.com,3055551212,Florida,\"Apr 23, 2023 12:13:33 AM\"\nEmily Chen,emily.chen@hotmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:05 AM\"\nDavid Lee,david.lee@gmail.com,6175551212,Massachusetts,\"Apr 19, 2023 5:46:30 PM\"\nSophie Taylor,fashionista88@gmail.com,3055555555,Florida,\"Apr 19, 2023 5:46:04 PM\"\nGrace Nguyen,avidreader99@yahoo.com,6175555555,Massachusetts,\"Apr 19, 2023 5:45:51 PM\"\nSamantha Jones,coolcat321@hotmail.com,3055551212,Florida,\"Apr 19, 2023 5:45:44 PM\"\nMary Martin,marym@gmail.com,3059876543,Florida,\"Apr 19, 2023 5:45:17 PM\"\nJane Doe,jane.doe@hotmail.com,4123671901,Florida,\"Apr 19, 2023 5:45:01 PM\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/florida_massachusetts.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "Name,Email,Phone,State/Province,Customer Since\nIsabella Santos,isabella.santos@gmail.com,3055551212,Florida,\"Apr 23, 2023 12:14:32 AM\"\nSophia Young,sophia.young@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:14:05 AM\"\nRobert Johnson,robert.johnson@gmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:36 AM\"\nSamantha Wu,samantha.wu@yahoo.com,3055551212,Florida,\"Apr 23, 2023 12:13:33 AM\"\nEmily Chen,emily.chen@hotmail.com,6175551212,Massachusetts,\"Apr 23, 2023 12:13:05 AM\"\nDavid Lee,david.lee@gmail.com,6175551212,Massachusetts,\"Apr 19, 2023 5:46:30 PM\"\nSophie Taylor,fashionista88@gmail.com,3055555555,Florida,\"Apr 19, 2023 5:46:04 PM\"\nGrace Nguyen,avidreader99@yahoo.com,6175555555,Massachusetts,\"Apr 19, 2023 5:45:51 PM\"\nSamantha Jones,coolcat321@hotmail.com,3055551212,Florida,\"Apr 19, 2023 5:45:44 PM\"\nMary Martin,marym@gmail.com,3059876543,Florida,\"Apr 19, 2023 5:45:17 PM\"\nJane Doe,jane.doe@hotmail.com,4123671901,Florida,\"Apr 19, 2023 5:45:01 PM\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50113,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "intent": "Create a repository named \"byteblaze/shopping_admin_2\" (if it does not already exist). Within it, create a CSV file named \"colorado_illinois.csv\" that contains the customer information of customers living in {{state1}} and {{state2}}. You can get the customer information in Merchant Admin Portal and the customer information in CSV file must include \"Name\", \"Email\", \"Phone\", \"State/Province\", and \"Customer Since\". If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) The first row must be a header with the field names: Name,Email,Phone,State/Province,Customer Since. Sort the items in the CSV file by 'Customer Since', from newest to oldest. An example of the CSV format is as follows:\nName,Email,Phone,State/Province,Customer Since\nJon Smith,jon.smith@hotmail.com,2014270278,Washington,\"Apr 23, 2023 12:13:44 AM\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal and retrieve customer information for customers living in the specified states. Then, log in to GitLab and create a repository and CSV file.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "colorado_illinois.csv",
            "csv_content": "Name,Email,Phone,State/Province,Customer Since\nNathan Chen,nathan.chen@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:14:36 AM\"\nEmily Wilson,emily.wilson@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:14:24 AM\"\nOlivia Jackson,olivia.jackson@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:13:57 AM\"\nJessica Wong,jessica.wong@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:48 AM\"\nJames Kim,james.kim@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:29 AM\"\nMaxwell Baker,maxwell.baker@yahoo.com,3125551212,Illinois,\"Apr 23, 2023 12:13:01 AM\"\nJason Miller,jason.miller@yahoo.com,3035551212,Colorado,\"Apr 19, 2023 5:46:34 PM\"\nMichael Nguyen,michael.nguyen@yahoo.com,3125551212,Illinois,\"Apr 19, 2023 5:46:27 PM\"\nLucy Garcia,artsygal123@hotmail.com,3035555555,Colorado,\"Apr 19, 2023 5:45:54 PM\"\nLily Potter,harrypotterfan1@gmail.com,7735555555,Illinois,\"Apr 19, 2023 5:45:47 PM\"\nJohn Lee,john.lee@yahoo.com,3125556789,Illinois,\"Apr 19, 2023 5:45:21 PM\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_2/-/raw/main/colorado_illinois.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "Name,Email,Phone,State/Province,Customer Since\nNathan Chen,nathan.chen@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:14:36 AM\"\nEmily Wilson,emily.wilson@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:14:24 AM\"\nOlivia Jackson,olivia.jackson@gmail.com,3035551212,Colorado,\"Apr 23, 2023 12:13:57 AM\"\nJessica Wong,jessica.wong@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:48 AM\"\nJames Kim,james.kim@gmail.com,3125551212,Illinois,\"Apr 23, 2023 12:13:29 AM\"\nMaxwell Baker,maxwell.baker@yahoo.com,3125551212,Illinois,\"Apr 23, 2023 12:13:01 AM\"\nJason Miller,jason.miller@yahoo.com,3035551212,Colorado,\"Apr 19, 2023 5:46:34 PM\"\nMichael Nguyen,michael.nguyen@yahoo.com,3125551212,Illinois,\"Apr 19, 2023 5:46:27 PM\"\nLucy Garcia,artsygal123@hotmail.com,3035555555,Colorado,\"Apr 19, 2023 5:45:54 PM\"\nLily Potter,harrypotterfan1@gmail.com,7735555555,Illinois,\"Apr 19, 2023 5:45:47 PM\"\nJohn Lee,john.lee@yahoo.com,3125556789,Illinois,\"Apr 19, 2023 5:45:21 PM\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50120,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_oldest_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 oldest approved reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "required_obs": "image",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "top_10_oldest_reviews.csv",
            "status": "the top 10 oldest approved reviews",
            "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:11 PM\",Really perfect for travel,Jamie,4,\"Really perfect for my needs. I travel a ton, so I'll always know what time to give my wife a call back home.\",Joust Duffle Bag\n28,\"Apr 19, 2023, 12:15:11 PM\",I really like the modern look,Bobby,2,\"I really like the modern look of this watch, but I could only get one time zone to work. I hope it has a warranty because I'm sending it back!\",Cruise Dual Analog Watch\n29,\"Apr 19, 2023, 12:15:11 PM\",This watch is so tight,Tommie,2,\"This watch is so tight around my wrist! I don't care if it's adjustable, it cuts off my circulation.\",Cruise Dual Analog Watch\n30,\"Apr 19, 2023, 12:15:11 PM\",My favorite layers,Markus,5,\"This is one of my favorite layers for running in the winter, it keeps me warm but it's not super bulky.\",Cruise Dual Analog Watch\n31,\"Apr 19, 2023, 12:15:11 PM\",Weird looking pocket,Xavier,4,I where it when I'm coaching football so I can run up and down the sidelines and yell without getting to hot. The pocket on the chest is weird looking tho.,Beaumont Summit Kit\n32,\"Apr 19, 2023, 12:15:11 PM\",Perfect layer for the game,Mike,5,\"Perfect layer for wearing to the game, it doesn't shed all over your clothes like a regular hoodie.\",Beaumont Summit Kit\n33,\"Apr 19, 2023, 12:15:11 PM\",The fabric is great,Emory,4,\"the fabric is great, it keeps me warm but it's not bulky like my other hoodies. Runs large, though.\",Hyperion Elements Jacket\n34,\"Apr 19, 2023, 12:15:11 PM\",This jacket isn't keeping me warm,Jon,2,This jacket isn't keeping me warm,Hyperion Elements Jacket\n35,\"Apr 19, 2023, 12:15:11 PM\",I don't feel protected,Homer,2,\"Not sure exactly what \"\"elements\"\" they're talking about here. I don't feel protected from any \"\"elements\"\" in this throw-away.\",Montana Wind Jacket\n36,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Montana Wind Jacket",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_oldest_reviews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:11 PM\",Really perfect for travel,Jamie,4,\"Really perfect for my needs. I travel a ton, so I'll always know what time to give my wife a call back home.\",Joust Duffle Bag\n28,\"Apr 19, 2023, 12:15:11 PM\",I really like the modern look,Bobby,2,\"I really like the modern look of this watch, but I could only get one time zone to work. I hope it has a warranty because I'm sending it back!\",Cruise Dual Analog Watch\n29,\"Apr 19, 2023, 12:15:11 PM\",This watch is so tight,Tommie,2,\"This watch is so tight around my wrist! I don't care if it's adjustable, it cuts off my circulation.\",Cruise Dual Analog Watch\n30,\"Apr 19, 2023, 12:15:11 PM\",My favorite layers,Markus,5,\"This is one of my favorite layers for running in the winter, it keeps me warm but it's not super bulky.\",Cruise Dual Analog Watch\n31,\"Apr 19, 2023, 12:15:11 PM\",Weird looking pocket,Xavier,4,I where it when I'm coaching football so I can run up and down the sidelines and yell without getting to hot. The pocket on the chest is weird looking tho.,Beaumont Summit Kit\n32,\"Apr 19, 2023, 12:15:11 PM\",Perfect layer for the game,Mike,5,\"Perfect layer for wearing to the game, it doesn't shed all over your clothes like a regular hoodie.\",Beaumont Summit Kit\n33,\"Apr 19, 2023, 12:15:11 PM\",The fabric is great,Emory,4,\"the fabric is great, it keeps me warm but it's not bulky like my other hoodies. Runs large, though.\",Hyperion Elements Jacket\n34,\"Apr 19, 2023, 12:15:11 PM\",This jacket isn't keeping me warm,Jon,2,This jacket isn't keeping me warm,Hyperion Elements Jacket\n35,\"Apr 19, 2023, 12:15:11 PM\",I don't feel protected,Homer,2,\"Not sure exactly what \"\"elements\"\" they're talking about here. I don't feel protected from any \"\"elements\"\" in this throw-away.\",Montana Wind Jacket\n36,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Montana Wind Jacket"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50121,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_newest_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 newest approved reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "required_obs": "image",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "top_10_newest_reviews.csv",
            "status": "the top 10 newest approved reviews",
            "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n333,\"Apr 19, 2023, 12:15:20 PM\",Makes me feel so snug! WHOO!,Concepcion,5,Makes me feel so snug! WHOO!,Chloe Compete Tank\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_newest_reviews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "ID,Created,Title,Nickname,Review Star,Review,Product\n333,\"Apr 19, 2023, 12:15:20 PM\",Makes me feel so snug! WHOO!,Concepcion,5,Makes me feel so snug! WHOO!,Chloe Compete Tank\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50122,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_lowest_id_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 approved reviews with the lowest IDs in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "required_obs": "image",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "top_10_lowest_id_reviews.csv",
            "status": "the top 10 approved reviews with the lowest IDs",
            "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Joust Duffle Bag\n2,\"Apr 19, 2023, 12:15:11 PM\",I use it a lot,Filiberto,3,It's a good size and I use it a lot. My only issue with it was I wanted the handles to be longer so I can wear it on my back.,Joust Duffle Bag\n3,\"Apr 19, 2023, 12:15:11 PM\",I've had this thing for really long,Herb,5,\"I've had this thing for a really long time and it barely shows any signs of wear and tear. It's really big, too! I've taken it on day trips as well as short vacations and usually have no trouble finding room for my stuff.\",Fusion Backpack\n4,\"Apr 19, 2023, 12:15:11 PM\",Decent bag,Craig,3,\"Decent bag. I keep my stuff in it for work and the gym. It's nice and roomy. I wish it had a more sophisticated design, though. Kinda looks like it's for kids.\",Fusion Backpack\n5,\"Apr 19, 2023, 12:15:11 PM\",Screwed up my back,Orville,2,\"I can't believe they're claiming these straps are \"\"padded.\"\" Wearing this thing to class for a semester totally screwed up my back, and my shoulders would start to ache after a few minutes where the straps dug in.\",Fusion Backpack\n6,\"Apr 19, 2023, 12:15:11 PM\",Awesome bag,Marty,4,Awesome bag but I found it to be smaller than I thought. I haven't felt any additional strain on my back and I use it all day long for my job.,Crown Summit Backpack\n7,\"Apr 19, 2023, 12:15:11 PM\",The back needs more padding,Chase,3,If the back had more padding I would recommend it for everyone. You can tell the material is strong and not cheap so it's definitely worth it.,Crown Summit Backpack\n8,\"Apr 19, 2023, 12:15:11 PM\",I bought this backpack for my son,Kennith,3,\"I bought this backpack for my son to take to school, but he carries it like a suitcase now! It's also really good for airplane travel.\",Crown Summit Backpack\n9,\"Apr 19, 2023, 12:15:11 PM\",awesome for going back and forth,Gaston,5,\"This is awesome for going back and forth to class. I live off campus and it's a longer walk, but this pack fits comfortably and I can even store my laptop in the main compartment.\",Strive Shoulder Pack\n10,\"Apr 19, 2023, 12:15:11 PM\",comfy and i don't feel like a loser,Issac,4,comfy and i don't feel like a loser carrying it.,Strive Shoulder Pack",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_lowest_id_reviews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "ID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 19, 2023, 12:15:10 PM\",I prefer more compartments,Chi,2,\"I prefer more compartments. If you don't mind putting everything in one space, it's fine. Good for the gym.\",Joust Duffle Bag\n2,\"Apr 19, 2023, 12:15:11 PM\",I use it a lot,Filiberto,3,It's a good size and I use it a lot. My only issue with it was I wanted the handles to be longer so I can wear it on my back.,Joust Duffle Bag\n3,\"Apr 19, 2023, 12:15:11 PM\",I've had this thing for really long,Herb,5,\"I've had this thing for a really long time and it barely shows any signs of wear and tear. It's really big, too! I've taken it on day trips as well as short vacations and usually have no trouble finding room for my stuff.\",Fusion Backpack\n4,\"Apr 19, 2023, 12:15:11 PM\",Decent bag,Craig,3,\"Decent bag. I keep my stuff in it for work and the gym. It's nice and roomy. I wish it had a more sophisticated design, though. Kinda looks like it's for kids.\",Fusion Backpack\n5,\"Apr 19, 2023, 12:15:11 PM\",Screwed up my back,Orville,2,\"I can't believe they're claiming these straps are \"\"padded.\"\" Wearing this thing to class for a semester totally screwed up my back, and my shoulders would start to ache after a few minutes where the straps dug in.\",Fusion Backpack\n6,\"Apr 19, 2023, 12:15:11 PM\",Awesome bag,Marty,4,Awesome bag but I found it to be smaller than I thought. I haven't felt any additional strain on my back and I use it all day long for my job.,Crown Summit Backpack\n7,\"Apr 19, 2023, 12:15:11 PM\",The back needs more padding,Chase,3,If the back had more padding I would recommend it for everyone. You can tell the material is strong and not cheap so it's definitely worth it.,Crown Summit Backpack\n8,\"Apr 19, 2023, 12:15:11 PM\",I bought this backpack for my son,Kennith,3,\"I bought this backpack for my son to take to school, but he carries it like a suitcase now! It's also really good for airplane travel.\",Crown Summit Backpack\n9,\"Apr 19, 2023, 12:15:11 PM\",awesome for going back and forth,Gaston,5,\"This is awesome for going back and forth to class. I live off campus and it's a longer walk, but this pack fits comfortably and I can even store my laptop in the main compartment.\",Strive Shoulder Pack\n10,\"Apr 19, 2023, 12:15:11 PM\",comfy and i don't feel like a loser,Issac,4,comfy and i don't feel like a loser carrying it.,Strive Shoulder Pack"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50123,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"top_10_highest_id_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for the top 10 approved reviews with the highest IDs in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "required_obs": "image",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "top_10_highest_id_reviews.csv",
            "status": "the top 10 approved reviews with the highest IDs",
            "csv_content": "ID,Created,Title,Nickname,Review Star,Review,Product\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n343,\"Apr 19, 2023, 12:15:20 PM\",Good choice for working out,Elfriede,4,Good choice for working out and stylin' enough to wear when I'm hanging with friends on hot days. Also washes really well! ,Bella Tank\n344,\"Apr 19, 2023, 12:15:20 PM\",I love the look,Yan,3,\"I love the look of this top, but I wasn't too crazy about the fit. The medium was too big in my opinion.\",Zoe Tank\n345,\"Apr 19, 2023, 12:15:20 PM\",Huge arm holes??,Valorie,2,I don't know why the arm holes are so big. It looked ok in the photo but in person they're really wide. It's really comfortable but that bugs me.,Zoe Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/top_10_highest_id_reviews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "ID,Created,Title,Nickname,Review Star,Review,Product\n334,\"Apr 19, 2023, 12:15:20 PM\",Could be flirtier.,Emerald,4,Could be flirtier.,Chloe Compete Tank\n335,\"Apr 19, 2023, 12:15:20 PM\",Not for non-petite,Teofila,2,Watch out if you're shapely like me - this tiny thing makes it hard to breath! ,Chloe Compete Tank\n336,\"Apr 19, 2023, 12:15:20 PM\",one of my favorites,Elza,4,I do a lot of different exercises and this tank - I have 2 of them - is one of my favorites. It's really soft and stays drier than other tops I've had.,Maya Tunic\n337,\"Apr 19, 2023, 12:15:20 PM\",Zero support/modesty,Shaunte,2,I would never wear this bra to anything but a low impact class like yoga. There's zero support and absolutely no modesty. Was hoping for better!,Antonia Racer Tank\n338,\"Apr 19, 2023, 12:15:20 PM\",Not for high impact,Merrie,3,\"Definitely not good for anything high-impact, but it's very stylish for yoga or something else low impact.\",Antonia Racer Tank\n339,\"Apr 19, 2023, 12:15:20 PM\",A regular or me,Pearl,4,This is in regular rotation at the gym. Its colorful and looks kinda cute under my exercise tanks.,Antonia Racer Tank\n340,\"Apr 19, 2023, 12:15:20 PM\",Great fit - love the v-neck design!,Thalia,4,Great fit - love the v-neck design!,Breathe-Easy Tank\n341,\"Apr 19, 2023, 12:15:20 PM\",The seams bother me,Carma,3,Some of the seams bother me during certain workouts but otherwise very comfortable,Breathe-Easy Tank\n342,\"Apr 19, 2023, 12:15:20 PM\",A sweet n sporty look for the gym,Maryanna,4,Always a sweet n sporty look for the gym! Keeps me cool and the seams don't rub up against me like some of my other tanks.,Bella Tank\n343,\"Apr 19, 2023, 12:15:20 PM\",Good choice for working out,Elfriede,4,Good choice for working out and stylin' enough to wear when I'm hanging with friends on hot days. Also washes really well! ,Bella Tank\n344,\"Apr 19, 2023, 12:15:20 PM\",I love the look,Yan,3,\"I love the look of this top, but I wasn't too crazy about the fit. The medium was too big in my opinion.\",Zoe Tank\n345,\"Apr 19, 2023, 12:15:20 PM\",Huge arm holes??,Valorie,2,I don't know why the arm holes are so big. It looked ok in the photo but in person they're really wide. It's really comfortable but that bugs me.,Zoe Tank\n346,\"Apr 19, 2023, 12:15:20 PM\",Super cute!!! I love it,Mikkel,3,Super cute!!!  I love it and want more colors. I really like running in this tank because it's not too tight.,Zoe Tank"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50124,
        "sites": [
            "gitlab",
            "shopping_admin"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__SHOPPING_ADMIN__/admin",
        "storage_state": "./.auth/gitlab.shopping_admin_state.json",
        "intent_template": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"{{csv_file_name}}\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for {{status}} in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "intent": "Create a repository named \"byteblaze/shopping_admin_1\" (if it does not already exist). Within it, create a CSV file named \"all_pending_reviews.csv\" that contains the IDs, Created Dates, Review Titles, Nicknames, Review Star, Review, and Product for all the pending reviews in Merchant Admin Portal. Each row in the CSV file should include the gathered information. If a field contains a comma (`,`), the entire field must be enclosed in double quotation marks, e.g., \"Apr 27, 2021, 10:12:10 PM\". (If a comma is not included, it must not be enclosed in double quotation marks.) You need to write the full sentences of Reviews. The first row must be a header with the field names: ID,Created,Title,Nickname,Review Star,Review,Product. The items in the CSV file must be sorted primarily in ascending order by ID. An example of the CSV format is as follows:\nID,Created,Title,Nickname,Review Star,Review,Product\n1,\"Apr 27, 2021, 10:12:10 PM\",I like this item,3,\"Really, I love this.\",Body Soap",
        "required_obs": "image",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "First, access the Shopping Admin Portal. Then, go to the reviews page and get {{status}}. Finally, create a CSV file and save it in the GitLab repository.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__SHOPPING_ADMIN__/admin",
            "csv_file_name": "all_pending_reviews.csv",
            "status": "all the pending reviews",
            "csv_content": "ID,Created,Status,Title,Nickname,Review Star,Review,Product\n347,\"Apr 24, 2023, 2:42:23 PM\",Pending,Quite good,Jane Smith,5,\"I recently purchased the Olivia 1/4 Zip Light Jacket and I am extremely satisfied with my purchase! The jacket is incredibly lightweight and comfortable, making it perfect for cool spring mornings or summer evenings. The 1/4 zip feature allows for easy temperature control, and the jacket is versatile enough to be dressed up or down. I also appreciate the attention to detail in the design - the pockets are well-placed and the stitching is sturdy. Overall, I highly recommend the Olivia 1/4 Zip Light Jacket for anyone in need of a comfortable and stylish lightweight jacket!\",Olivia 1/4 Zip Light Jacket\n349,\"Apr 24, 2023, 2:44:16 PM\",Pending,OKish,seam miller,3,\"I have to say, I'm not impressed with the Olivia 1/4 Zip Light Jacket. The color is not as vibrant as it looked online, and the zipper is really hard to use. The jacket is also not very breathable, so I found myself getting really sweaty when I wore it for even a short amount of time. Finally, the pockets are really shallow and not very functional. Overall, I wouldn't recommend this jacket - there are better options out there for the price.\",Olivia 1/4 Zip Light Jacket\n351,\"Apr 24, 2023, 2:49:50 PM\",Pending,won't recommand,Emma,1,\"I was really disappointed with the Olivia 1/4 Zip Light Jacket. The material is extremely thin and flimsy, which makes it not very warm at all. I was hoping for something that would keep me comfortable in the springtime, but this jacket just doesn't cut it. Additionally, the sizing is way off - I ordered my usual size and it was way too tight in the arms and shoulders. I had to return it and won't be buying from this brand again.\",Olivia 1/4 Zip Light Jacket\n352,\"Apr 24, 2023, 2:53:49 PM\",Pending,Good but not perfect,customer,4,\"I recently purchased the Circe Hooded Ice Fleece and overall, I'm quite happy with it. The fleece material is incredibly soft and cozy, and I love the addition of the hood for extra warmth. The fit is true to size and the sleeves are long enough, which is often a problem for me. The only reason I'm not giving it a full 5 stars is because I was hoping the color would be a bit more vibrant - it's a bit muted compared to what I was expecting. But overall, I would definitely recommend the Circe Hooded Ice Fleece for anyone in need of a warm and comfortable layer for outdoor activities.\",Circe Hooded Ice Fleece\n353,\"Apr 24, 2023, 2:55:10 PM\",Pending,Bad!,Hannah Lim,1,\"I was really disappointed with the Circe Hooded Ice Fleece. The material is not very high quality and started pilling after just one wash. The fit was also really strange - the sleeves were too short and the body was too baggy, making me look frumpy. I was hoping this would be a cozy layer for winter walks, but it doesn't keep me very warm either. Finally, the hood is way too big and just falls down over my face. I wouldn't recommend this product - there are much better options out there for the price.\",Circe Hooded Ice Fleece",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/shopping_admin_1/-/raw/main/all_pending_reviews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "ID,Created,Status,Title,Nickname,Review Star,Review,Product\n347,\"Apr 24, 2023, 2:42:23 PM\",Pending,Quite good,Jane Smith,5,\"I recently purchased the Olivia 1/4 Zip Light Jacket and I am extremely satisfied with my purchase! The jacket is incredibly lightweight and comfortable, making it perfect for cool spring mornings or summer evenings. The 1/4 zip feature allows for easy temperature control, and the jacket is versatile enough to be dressed up or down. I also appreciate the attention to detail in the design - the pockets are well-placed and the stitching is sturdy. Overall, I highly recommend the Olivia 1/4 Zip Light Jacket for anyone in need of a comfortable and stylish lightweight jacket!\",Olivia 1/4 Zip Light Jacket\n349,\"Apr 24, 2023, 2:44:16 PM\",Pending,OKish,seam miller,3,\"I have to say, I'm not impressed with the Olivia 1/4 Zip Light Jacket. The color is not as vibrant as it looked online, and the zipper is really hard to use. The jacket is also not very breathable, so I found myself getting really sweaty when I wore it for even a short amount of time. Finally, the pockets are really shallow and not very functional. Overall, I wouldn't recommend this jacket - there are better options out there for the price.\",Olivia 1/4 Zip Light Jacket\n351,\"Apr 24, 2023, 2:49:50 PM\",Pending,won't recommand,Emma,1,\"I was really disappointed with the Olivia 1/4 Zip Light Jacket. The material is extremely thin and flimsy, which makes it not very warm at all. I was hoping for something that would keep me comfortable in the springtime, but this jacket just doesn't cut it. Additionally, the sizing is way off - I ordered my usual size and it was way too tight in the arms and shoulders. I had to return it and won't be buying from this brand again.\",Olivia 1/4 Zip Light Jacket\n352,\"Apr 24, 2023, 2:53:49 PM\",Pending,Good but not perfect,customer,4,\"I recently purchased the Circe Hooded Ice Fleece and overall, I'm quite happy with it. The fleece material is incredibly soft and cozy, and I love the addition of the hood for extra warmth. The fit is true to size and the sleeves are long enough, which is often a problem for me. The only reason I'm not giving it a full 5 stars is because I was hoping the color would be a bit more vibrant - it's a bit muted compared to what I was expecting. But overall, I would definitely recommend the Circe Hooded Ice Fleece for anyone in need of a warm and comfortable layer for outdoor activities.\",Circe Hooded Ice Fleece\n353,\"Apr 24, 2023, 2:55:10 PM\",Pending,Bad!,Hannah Lim,1,\"I was really disappointed with the Circe Hooded Ice Fleece. The material is not very high quality and started pilling after just one wash. The fit was also really strange - the sleeves were too short and the body was too baggy, making me look frumpy. I was hoping this would be a cozy layer for winter walks, but it doesn't keep me very warm either. Finally, the hood is way too big and just falls down over my face. I wouldn't recommend this product - there are much better options out there for the price.\",Circe Hooded Ice Fleece"
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50130,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/memes/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"memes\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"memes.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/memes/most_commented?t=all",
            "csv_file_name": "memes.csv",
            "number": "20",
            "subreddit": "memes",
            "csv_content": "\"username\",\"number of comments\"\n\"DrGoosert\",\"197\"\n\"mbhammock\",\"191\"\n\"Lttlefoot\",\"179\"\n\"killingmemesoftly\",\"176\"\n\"Lord_Detleff1\",\"166\"\n\"rohanstan69\",\"164\"\n\"return2ozma\",\"160\"\n\"TurtleBoy29\",\"152\"\n\"Vortex9966\",\"152\"\n\"Civil-Sky-973\",\"149\"\n\"BeerFuelsMyDreams\",\"147\"\n\"Jemaniema\",\"147\"\n\"Looney_forner\",\"147\"\n\"BuddPlug\",\"145\"\n\"velatieren\",\"144\"\n\"Andrevery\",\"140\"\n\"thepositivepandemic\",\"132\"\n\"Better-Intern9170\",\"128\"\n\"Salty-004\",\"128\"\n\"_Cespuglio_\",\"125\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/memes.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"username\",\"number of comments\"\n\"DrGoosert\",\"197\"\n\"mbhammock\",\"191\"\n\"Lttlefoot\",\"179\"\n\"killingmemesoftly\",\"176\"\n\"Lord_Detleff1\",\"166\"\n\"rohanstan69\",\"164\"\n\"return2ozma\",\"160\"\n\"TurtleBoy29\",\"152\"\n\"Vortex9966\",\"152\"\n\"Civil-Sky-973\",\"149\"\n\"BeerFuelsMyDreams\",\"147\"\n\"Jemaniema\",\"147\"\n\"Looney_forner\",\"147\"\n\"BuddPlug\",\"145\"\n\"velatieren\",\"144\"\n\"Andrevery\",\"140\"\n\"thepositivepandemic\",\"132\"\n\"Better-Intern9170\",\"128\"\n\"Salty-004\",\"128\"\n\"_Cespuglio_\",\"125\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50131,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/wallstreetbets/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "intent": "From Reddit, gather 14 users who created most-commented submissions in the subreddit \"wallstreetbets\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"wallstreetbets.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/wallstreetbets/most_commented?t=all",
            "csv_file_name": "wallstreetbets.csv",
            "number": "14",
            "subreddit": "wallstreetbets",
            "csv_content": "\"username\",\"number of comments\"\n\"Johs92\",\"215\"\n\"FI_investor\",\"205\"\n\"postonrddt\",\"205\"\n\"sadafboicry\",\"201\"\n\"putridfries\",\"197\"\n\"whicky1978\",\"195\"\n\"mlamping\",\"194\"\n\"cezapiza\",\"181\"\n\"Mega-Lithium\",\"181\"\n\"jamzkourt\",\"180\"\n\"mat3og\",\"179\"\n\"cyuvlol\",\"175\"\n\"Curiousdude925\",\"171\"\n\"JPowsSecretlover\",\"171\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/wallstreetbets.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"username\",\"number of comments\"\n\"Johs92\",\"215\"\n\"FI_investor\",\"205\"\n\"postonrddt\",\"205\"\n\"sadafboicry\",\"201\"\n\"putridfries\",\"197\"\n\"whicky1978\",\"195\"\n\"mlamping\",\"194\"\n\"cezapiza\",\"181\"\n\"Mega-Lithium\",\"181\"\n\"jamzkourt\",\"180\"\n\"mat3og\",\"179\"\n\"cyuvlol\",\"175\"\n\"Curiousdude925\",\"171\"\n\"JPowsSecretlover\",\"171\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50132,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"worldnews\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"worldnews.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
            "csv_file_name": "worldnews.csv",
            "number": "20",
            "subreddit": "worldnews",
            "csv_content": "\"username\",\"number of comments\"\n\"BubsyFanboy\",\"207\"\n\"BeeBobMC\",\"205\"\n\"SunfireGaren\",\"204\"\n\"Crimbobimbobippitybo\",\"202\"\n\"YoanB\",\"202\"\n\"seebz69\",\"201\"\n\"rentalfloss\",\"197\"\n\"Lahampsink\",\"194\"\n\"khushraho\",\"192\"\n\"calbert1735\",\"190\"\n\"Rifletree\",\"190\"\n\"DutchBlob\",\"189\"\n\"TallAd3975\",\"189\"\n\"yourSAS\",\"189\"\n\"Caratteraccio\",\"188\"\n\"IndependentTHNKR\",\"184\"\n\"loggiews\",\"184\"\n\"OceanBreeze246\",\"183\"\n\"WhoIsJolyonWest\",\"183\"\n\"essential_projection\",\"183\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/worldnews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"username\",\"number of comments\"\n\"BubsyFanboy\",\"207\"\n\"BeeBobMC\",\"205\"\n\"SunfireGaren\",\"204\"\n\"Crimbobimbobippitybo\",\"202\"\n\"YoanB\",\"202\"\n\"seebz69\",\"201\"\n\"rentalfloss\",\"197\"\n\"Lahampsink\",\"194\"\n\"khushraho\",\"192\"\n\"calbert1735\",\"190\"\n\"Rifletree\",\"190\"\n\"DutchBlob\",\"189\"\n\"TallAd3975\",\"189\"\n\"yourSAS\",\"189\"\n\"Caratteraccio\",\"188\"\n\"IndependentTHNKR\",\"184\"\n\"loggiews\",\"184\"\n\"OceanBreeze246\",\"183\"\n\"WhoIsJolyonWest\",\"183\"\n\"essential_projection\",\"183\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50133,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/news/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"news\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"news.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/news/most_commented?t=all",
            "csv_file_name": "news.csv",
            "number": "20",
            "subreddit": "news",
            "csv_content": "\"username\",\"number of comments\"\n\"ChocolateTsar\",\"219\"\n\"PhillipCrawfordJr\",\"219\"\n\"alanzhang34\",\"215\"\n\"flowerhoney10\",\"215\"\n\"iamthyfucker\",\"215\"\n\"thatoneguy889\",\"214\"\n\"Papppi-56\",\"213\"\n\"sovamind\",\"212\"\n\"hoosakiwi\",\"211\"\n\"DragonWriterDB\",\"207\"\n\"Globalist2\",\"207\"\n\"phunky_1\",\"207\"\n\"AsherBaels\",\"206\"\n\"meta_perspective\",\"206\"\n\"Picture-unrelated\",\"206\"\n\"Semper-Fido\",\"206\"\n\"Shaul_Ishtov\",\"206\"\n\"Clem_Doore\",\"205\"\n\"Picture-unrelated\",\"205\"\n\"eastbayted\",\"204\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/news.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"username\",\"number of comments\"\n\"ChocolateTsar\",\"219\"\n\"PhillipCrawfordJr\",\"219\"\n\"alanzhang34\",\"215\"\n\"flowerhoney10\",\"215\"\n\"iamthyfucker\",\"215\"\n\"thatoneguy889\",\"214\"\n\"Papppi-56\",\"213\"\n\"sovamind\",\"212\"\n\"hoosakiwi\",\"211\"\n\"DragonWriterDB\",\"207\"\n\"Globalist2\",\"207\"\n\"phunky_1\",\"207\"\n\"AsherBaels\",\"206\"\n\"meta_perspective\",\"206\"\n\"Picture-unrelated\",\"206\"\n\"Semper-Fido\",\"206\"\n\"Shaul_Ishtov\",\"206\"\n\"Clem_Doore\",\"205\"\n\"Picture-unrelated\",\"205\"\n\"eastbayted\",\"204\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50134,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/movies/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{number}} users who created most-commented submissions in the subreddit \"{{subreddit}}\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "intent": "From Reddit, gather 20 users who created most-commented submissions in the subreddit \"movies\". Use \"All time\" time span when searching for most commented submissions. When the user is \"[deleted]\", skip that user and find another user. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"movies.csv\" within this repository. Each row in the CSV file should include the gathered username and number of comments, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"username\" and \"number of comments\". The items in the CSV file must be sorted primarily in descending order by the number of comments, and secondarily in ascending order by username when the number of comments are equal. An example of the CSV format is as follows:\n\"username\",\"number of comments\"\n\"user1\",\"131\"\n\"user2\",\"125\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and sort by the number of comments. Gather the specified number of users who created the most commented submissions, excluding deleted users. Create a CSV file in the specified repository with the gathered data.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/movies/most_commented?t=all",
            "csv_file_name": "movies.csv",
            "number": "20",
            "subreddit": "movies",
            "csv_content": "\"username\",\"number of comments\"\n\"Zilla1689\",\"200\"\n\"polywha\",\"199\"\n\"MarvelsGrantMan136\",\"190\"\n\"SquatOnAPitbull\",\"190\"\n\"ProbablyASithLord\",\"189\"\n\"JannTosh17\",\"187\"\n\"JorReno\",\"184\"\n\"peter095837\",\"182\"\n\"fabrizziop17\",\"178\"\n\"ilovemychickens\",\"177\"\n\"I_serve_Anubis\",\"174\"\n\"mywordswillgowithyou\",\"172\"\n\"acharismaticjeweller\",\"171\"\n\"Ok-Impress-2222\",\"171\"\n\"JannTosh12\",\"170\"\n\"Huevos___Rancheros\",\"169\"\n\"Boss452\",\"166\"\n\"Leather-Climate3438\",\"165\"\n\"h2oskid3\",\"164\"\n\"PastMiddleAge\",\"163\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/movies.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"username\",\"number of comments\"\n\"Zilla1689\",\"200\"\n\"polywha\",\"199\"\n\"MarvelsGrantMan136\",\"190\"\n\"SquatOnAPitbull\",\"190\"\n\"ProbablyASithLord\",\"189\"\n\"JannTosh17\",\"187\"\n\"JorReno\",\"184\"\n\"peter095837\",\"182\"\n\"fabrizziop17\",\"178\"\n\"ilovemychickens\",\"177\"\n\"I_serve_Anubis\",\"174\"\n\"mywordswillgowithyou\",\"172\"\n\"acharismaticjeweller\",\"171\"\n\"Ok-Impress-2222\",\"171\"\n\"JannTosh12\",\"170\"\n\"Huevos___Rancheros\",\"169\"\n\"Boss452\",\"166\"\n\"Leather-Climate3438\",\"165\"\n\"h2oskid3\",\"164\"\n\"PastMiddleAge\",\"163\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50140,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/memes/new",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "intent": "From Reddit, gather newest 25 submissions from reddit that are in the \"memes\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"newest_25_memes.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/memes/new",
            "condition": "newest",
            "number": "25",
            "subreddit": "memes",
            "csv_file_name": "newest_25_memes.csv",
            "csv_content": "\"title\",\"votes\"\n\"Guys now really think being a misogynist is cool\",\"5\"\n\"My mom at amusement parks:\",\"5\"\n\"Neverending Therapy\",\"5\"\n\"I wouldnt put the bag in the microwave personally\",\"4\"\n\"Im in wrong industry\",\"4\"\n\"Let's be honest\",\"4\"\n\"Mega cringe\",\"4\"\n\"They really dropped the ball with this one\",\"4\"\n\"How many of these do you turn off?\",\"3\"\n\"If you have no other choice\",\"3\"\n\"It do be like that tho\",\"3\"\n\"Love your mom\",\"3\"\n\"The greatest betrayal\",\"3\"\n\"yes Yes YES!\",\"3\"\n\"Glue porridge\",\"2\"\n\"Mostly the truth.\",\"2\"\n\"One of these should be illegal\",\"2\"\n\"Shagadelic, baby\",\"2\"\n\"and i never will\",\"2\"\n\"How many comments will this individual predictions post have in exactly 7 days from now? (Round 2)\",\"1\"\n\"Its always the dogs!\",\"1\"\n\"PC Gamers In 2023 Be Like Part 2\",\"1\"\n\"Thank you memers, this wouldnt be possible without you.\",\"1\"\n\"They did nothing wrong\",\"1\"\n\"Lets goooo baby no more cringe show\",\"0\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/newest_25_memes.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"title\",\"votes\"\n\"Guys now really think being a misogynist is cool\",\"5\"\n\"My mom at amusement parks:\",\"5\"\n\"Neverending Therapy\",\"5\"\n\"I wouldnt put the bag in the microwave personally\",\"4\"\n\"Im in wrong industry\",\"4\"\n\"Let's be honest\",\"4\"\n\"Mega cringe\",\"4\"\n\"They really dropped the ball with this one\",\"4\"\n\"How many of these do you turn off?\",\"3\"\n\"If you have no other choice\",\"3\"\n\"It do be like that tho\",\"3\"\n\"Love your mom\",\"3\"\n\"The greatest betrayal\",\"3\"\n\"yes Yes YES!\",\"3\"\n\"Glue porridge\",\"2\"\n\"Mostly the truth.\",\"2\"\n\"One of these should be illegal\",\"2\"\n\"Shagadelic, baby\",\"2\"\n\"and i never will\",\"2\"\n\"How many comments will this individual predictions post have in exactly 7 days from now? (Round 2)\",\"1\"\n\"Its always the dogs!\",\"1\"\n\"PC Gamers In 2023 Be Like Part 2\",\"1\"\n\"Thank you memers, this wouldnt be possible without you.\",\"1\"\n\"They did nothing wrong\",\"1\"\n\"Lets goooo baby no more cringe show\",\"0\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50141,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/wallstreetbets/active",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "intent": "From Reddit, gather most active 25 submissions from reddit that are in the \"wallstreetbets\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_active_25_wallstreetbets.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/wallstreetbets/active",
            "condition": "most active",
            "number": "25",
            "subreddit": "wallstreetbets",
            "csv_file_name": "most_active_25_wallstreetbets.csv",
            "csv_content": "\"title\",\"votes\"\n\"OK analyst\",\"1369\"\n\"\"\"No REALLY, we're doing fine\"\" ~ every bank right now\",\"1329\"\n\"Fuking great year so far\",\"747\"\n\"I shorted the Nasdaq AMA\",\"733\"\n\"Bears to Burry after his tweet yesterday...\",\"247\"\n\"Homie doesnt know how to take a screenshot, somehow degens his way into 6 figures\",\"220\"\n\"No, I wont stop buying puts!\",\"206\"\n\"TSLA 0dte YOLO\",\"198\"\n\"Hi friends! I just started trading last year and i wanted to share some hot nsfw loss porn.\",\"118\"\n\"AMC Stock Faces Triple Threat: Conversion, Reverse Split, and Dilution\",\"81\"\n\"Most Anticipated Earnings Releases for the week beginning April 3rd, 2023\",\"74\"\n\"Heard this gem from a 12 year old just now\",\"69\"\n\"OpenAI helped me with my homework so I bought AI ticker Pt. 2\",\"60\"\n\"Thoughts on why Big Tech has been rallying and if its sustainable?\",\"45\"\n\"$SCHW YOLO\",\"41\"\n\"Went long QQQ calls today. I feel very dirty.\",\"34\"\n\"End of quarter rally?\",\"24\"\n\"Short Nestle SW\",\"15\"\n\"Hahahaha such a funny meme (totally not a solution to the stock market pretend its a funny meme so that Reddit parent company doesn't ban)\",\"13\"\n\"SPX to 5300 by EOY\",\"12\"\n\"Charles Schwab changing receiver account\",\"7\"\n\"Tired and more scared after todays rally. Hold or sell?\",\"2\"\n\"Volume Buys Just Went Through The Roof Again On SPY Today - Here Are The Next Waves\",\"2\"\n\"A safe 150% gain\",\"0\"\n\"Beyond Meat?\",\"0\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_active_25_wallstreetbets.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"title\",\"votes\"\n\"OK analyst\",\"1369\"\n\"\"\"No REALLY, we're doing fine\"\" ~ every bank right now\",\"1329\"\n\"Fuking great year so far\",\"747\"\n\"I shorted the Nasdaq AMA\",\"733\"\n\"Bears to Burry after his tweet yesterday...\",\"247\"\n\"Homie doesnt know how to take a screenshot, somehow degens his way into 6 figures\",\"220\"\n\"No, I wont stop buying puts!\",\"206\"\n\"TSLA 0dte YOLO\",\"198\"\n\"Hi friends! I just started trading last year and i wanted to share some hot nsfw loss porn.\",\"118\"\n\"AMC Stock Faces Triple Threat: Conversion, Reverse Split, and Dilution\",\"81\"\n\"Most Anticipated Earnings Releases for the week beginning April 3rd, 2023\",\"74\"\n\"Heard this gem from a 12 year old just now\",\"69\"\n\"OpenAI helped me with my homework so I bought AI ticker Pt. 2\",\"60\"\n\"Thoughts on why Big Tech has been rallying and if its sustainable?\",\"45\"\n\"$SCHW YOLO\",\"41\"\n\"Went long QQQ calls today. I feel very dirty.\",\"34\"\n\"End of quarter rally?\",\"24\"\n\"Short Nestle SW\",\"15\"\n\"Hahahaha such a funny meme (totally not a solution to the stock market pretend its a funny meme so that Reddit parent company doesn't ban)\",\"13\"\n\"SPX to 5300 by EOY\",\"12\"\n\"Charles Schwab changing receiver account\",\"7\"\n\"Tired and more scared after todays rally. Hold or sell?\",\"2\"\n\"Volume Buys Just Went Through The Roof Again On SPY Today - Here Are The Next Waves\",\"2\"\n\"A safe 150% gain\",\"0\"\n\"Beyond Meat?\",\"0\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50142,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "intent": "From Reddit, gather most commented for all time 25 submissions from reddit that are in the \"worldnews\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_commented_25_worldnews.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/worldnews/most_commented?t=all",
            "condition": "most commented for all time",
            "number": "25",
            "subreddit": "worldnews",
            "csv_file_name": "most_commented_25_worldnews.csv",
            "csv_content": "\"title\",\"votes\"\n\"Ireland Aims To Legalize Cannabis For Personal Use\",\"10614\"\n\"Brazil's Lula appoints Indigenous ministers to reverse Amazon deforestation\",\"9122\"\n\"Anti-war partisans in Belarus claim to have damaged Russian plane | Belarus\",\"6697\"\n\"Poland has delivered tanks to Ukraine, government announces on war's first anniversary.\",\"6145\"\n\"Dutch Constitution to be amended to ban discrimination based on sexuality or disability\",\"4530\"\n\"Australia uncovers Russian espionage ring, expels spies: Report\",\"4515\"\n\"A Russian graveyard reveals Wagner's prisoner army\",\"3939\"\n\"Iranian author said sentenced to death for giving interview to Israeli TV channel\",\"3825\"\n\"Amazon workers in the U.S. and 30 other countries plan Black Friday protests\",\"3383\"\n\"Chinese ships depart after record-long intrusion into Japanese waters\",\"3109\"\n\"Russia's only LGBTQ+ museum closes down amid 'propaganda' crackdown\",\"2394\"\n\"At least 25 die in Peru when bus plunges off cliff, police say\",\"2308\"\n\"World to face wars over food and water without climate action, EU green deal chief says\",\"2093\"\n\"Ukraine says Irans help for Russia should push Israel out of neutral stance\",\"1862\"\n\"Banksy's migrant rescue ship seized by Italy's coast guard in Lampedusa\",\"1832\"\n\"Poland picks U.S. offer for its first nuclear power plant -PM\",\"1764\"\n\"Ozone Hole Continues Shrinking in 2022, NASA and NOAA Scientists Say | Annual Antarctic ozone hole over the South Pole was slightly smaller than last year and generally continued the overall shrinking trend of recent years.\",\"1668\"\n\"Poland chooses US to build its first nuclear power plant\",\"1386\"\n\"Nearly 220 million people in Pakistan without power after countrywide outage | CNN Business\",\"1163\"\n\"Russia Says Ukraine Using Long-Range US Artillery\",\"843\"\n\"German defense minister announces resignation\",\"821\"\n\"For The First Time, Less Than Half Of UK's Population Is Christian: Report\",\"660\"\n\"China calls US debt trap accusation 'irresponsible'\",\"626\"\n\"Russia ready to resume gas supplies to Europe via Yamal-Europe pipeline -Novak\",\"598\"\n\"Canada moves to mandate electric vehicle sales starting in 2026\",\"565\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_commented_25_worldnews.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"title\",\"votes\"\n\"Ireland Aims To Legalize Cannabis For Personal Use\",\"10614\"\n\"Brazil's Lula appoints Indigenous ministers to reverse Amazon deforestation\",\"9122\"\n\"Anti-war partisans in Belarus claim to have damaged Russian plane | Belarus\",\"6697\"\n\"Poland has delivered tanks to Ukraine, government announces on war's first anniversary.\",\"6145\"\n\"Dutch Constitution to be amended to ban discrimination based on sexuality or disability\",\"4530\"\n\"Australia uncovers Russian espionage ring, expels spies: Report\",\"4515\"\n\"A Russian graveyard reveals Wagner's prisoner army\",\"3939\"\n\"Iranian author said sentenced to death for giving interview to Israeli TV channel\",\"3825\"\n\"Amazon workers in the U.S. and 30 other countries plan Black Friday protests\",\"3383\"\n\"Chinese ships depart after record-long intrusion into Japanese waters\",\"3109\"\n\"Russia's only LGBTQ+ museum closes down amid 'propaganda' crackdown\",\"2394\"\n\"At least 25 die in Peru when bus plunges off cliff, police say\",\"2308\"\n\"World to face wars over food and water without climate action, EU green deal chief says\",\"2093\"\n\"Ukraine says Irans help for Russia should push Israel out of neutral stance\",\"1862\"\n\"Banksy's migrant rescue ship seized by Italy's coast guard in Lampedusa\",\"1832\"\n\"Poland picks U.S. offer for its first nuclear power plant -PM\",\"1764\"\n\"Ozone Hole Continues Shrinking in 2022, NASA and NOAA Scientists Say | Annual Antarctic ozone hole over the South Pole was slightly smaller than last year and generally continued the overall shrinking trend of recent years.\",\"1668\"\n\"Poland chooses US to build its first nuclear power plant\",\"1386\"\n\"Nearly 220 million people in Pakistan without power after countrywide outage | CNN Business\",\"1163\"\n\"Russia Says Ukraine Using Long-Range US Artillery\",\"843\"\n\"German defense minister announces resignation\",\"821\"\n\"For The First Time, Less Than Half Of UK's Population Is Christian: Report\",\"660\"\n\"China calls US debt trap accusation 'irresponsible'\",\"626\"\n\"Russia ready to resume gas supplies to Europe via Yamal-Europe pipeline -Novak\",\"598\"\n\"Canada moves to mandate electric vehicle sales starting in 2026\",\"565\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50143,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/news/controversial?t=all",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "intent": "From Reddit, gather most controversial for all time 25 submissions from reddit that are in the \"news\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_controversial_25_news.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/news/controversial?t=all",
            "condition": "most controversial for all time",
            "number": "25",
            "subreddit": "news",
            "csv_file_name": "most_controversial_25_news.csv",
            "csv_content": "\"title\",\"votes\"\n\"2 Russians seek asylum after reaching remote Alaskan island\",\"0\"\n\"26-year-old man sentenced to life for the killing of retired St. Louis police captain during George Floyd protests\",\"0\"\n\"A family of 4 is missing after being 'taken against their will' in central California, officials say\",\"0\"\n\"Biden to pardon all prior federal offenses of simple marijuana possession\",\"0\"\n\"Boy tackled by security after running on field at Bucs game\",\"0\"\n\"Defendant to represent himself in Wisconsin parade trial\",\"0\"\n\"Donald Trump files election-related lawsuit against CNN\",\"0\"\n\"Egypt calls for return of Rosetta Stone 200 years after it was deciphered\",\"0\"\n\"Elon Musk unveils humanoid Optimus robot at Teslas AI Day\",\"0\"\n\"Federal court finds 3rd Iowa ag-gag law unconstitutional\",\"0\"\n\"Jan. 6 defendants held in D.C. jail request transfer to Guantanamo Bay\",\"0\"\n\"Lawyer claims LAPD officer was targeted for being a potential whistleblower\",\"0\"\n\"Los Angeles City Council president issues apology after making racist remarks in leaked audio\",\"0\"\n\"Newark School District adds anti-Israel book to sixth-grade curriculum\",\"0\"\n\"Nury Martinez resigns as president of LA City Council following leaked audio of racist remarks\",\"0\"\n\"NYC Mayor Eric Adams declares state of emergency over influx of migrants | CNN\",\"0\"\n\"Olympia woman facing fines over Black Lives Matter sign inside her home\",\"0\"\n\"Pregnancy complications spiked during the pandemic. No one knows exactly why.\",\"0\"\n\"San Antonio police officer fired after shooting teen suspect in McDonald's parking lot\",\"0\"\n\"Supreme Court allows defamation lawsuit against MyPillow CEO Mike Lindell to proceed\",\"0\"\n\"Supreme Court rejects bump stock ban cases\",\"0\"\n\"The Onion defends right to parody in very real supreme court brief supporting local satirist\",\"0\"\n\"U.N. body rejects debate on China's treatment of Uyghur Muslims in blow to West\",\"0\"\n\"Walmart, CVS must face lawsuit over placement of homeopathic products\",\"0\"\n\"Woman at center of Herschel Walker abortion firestorm says she also had a child of his\",\"0\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_controversial_25_news.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"title\",\"votes\"\n\"2 Russians seek asylum after reaching remote Alaskan island\",\"0\"\n\"26-year-old man sentenced to life for the killing of retired St. Louis police captain during George Floyd protests\",\"0\"\n\"A family of 4 is missing after being 'taken against their will' in central California, officials say\",\"0\"\n\"Biden to pardon all prior federal offenses of simple marijuana possession\",\"0\"\n\"Boy tackled by security after running on field at Bucs game\",\"0\"\n\"Defendant to represent himself in Wisconsin parade trial\",\"0\"\n\"Donald Trump files election-related lawsuit against CNN\",\"0\"\n\"Egypt calls for return of Rosetta Stone 200 years after it was deciphered\",\"0\"\n\"Elon Musk unveils humanoid Optimus robot at Teslas AI Day\",\"0\"\n\"Federal court finds 3rd Iowa ag-gag law unconstitutional\",\"0\"\n\"Jan. 6 defendants held in D.C. jail request transfer to Guantanamo Bay\",\"0\"\n\"Lawyer claims LAPD officer was targeted for being a potential whistleblower\",\"0\"\n\"Los Angeles City Council president issues apology after making racist remarks in leaked audio\",\"0\"\n\"Newark School District adds anti-Israel book to sixth-grade curriculum\",\"0\"\n\"Nury Martinez resigns as president of LA City Council following leaked audio of racist remarks\",\"0\"\n\"NYC Mayor Eric Adams declares state of emergency over influx of migrants | CNN\",\"0\"\n\"Olympia woman facing fines over Black Lives Matter sign inside her home\",\"0\"\n\"Pregnancy complications spiked during the pandemic. No one knows exactly why.\",\"0\"\n\"San Antonio police officer fired after shooting teen suspect in McDonald's parking lot\",\"0\"\n\"Supreme Court allows defamation lawsuit against MyPillow CEO Mike Lindell to proceed\",\"0\"\n\"Supreme Court rejects bump stock ban cases\",\"0\"\n\"The Onion defends right to parody in very real supreme court brief supporting local satirist\",\"0\"\n\"U.N. body rejects debate on China's treatment of Uyghur Muslims in blow to West\",\"0\"\n\"Walmart, CVS must face lawsuit over placement of homeopathic products\",\"0\"\n\"Woman at center of Herschel Walker abortion firestorm says she also had a child of his\",\"0\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    },
    {
        "task_id": 50144,
        "sites": [
            "gitlab",
            "reddit"
        ],
        "start_url": "__GITLAB__",
        "start_url_lite": "__REDDIT__/f/movies/active",
        "storage_state": "./.auth/gitlab.reddit_state.json",
        "intent_template": "From Reddit, gather {{condition}} {{number}} submissions from reddit that are in the \"{{subreddit}}\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"{{csv_file_name}}\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "intent": "From Reddit, gather most active 25 submissions from reddit that are in the \"movies\" subreddit. Then, create a repository named \"byteblaze/reddit\" (if it does not already exist), and create a CSV file named \"most_active_25_movies.csv\" within this repository. Each row in the CSV file should include the gathered submission's full title and the number of votes, and all fields must be enclosed in double quotation marks. When a double quotation mark is in fields, escape it by adding another double quotation mark after it. The first row must be a header with the field names \"title\" and \"votes\". The items in the CSV file must be sorted primarily in descending order by votes, and secondarily in ascending order by title when votes are equal. An example of the CSV format is as follows:\n\"title\",\"votes\"\n\"title1\",\"123\"\n\"title2\",\"100\"",
        "required_obs": "any",
        "affects_environment": true,
        "type_main": "massive_memory",
        "description": "Access to the specified subreddit on Reddit and collect speccified number of submissions based on the specified condition. Then, create a repository and a CSV file in GitLab if it does not already exist. Finally, fill the CSV file with the gathered submissions.",
        "instantiation_dict": {
            "start_url": "__GITLAB__",
            "start_url_lite": "__REDDIT__/f/movies/active",
            "condition": "most active",
            "number": "25",
            "subreddit": "movies",
            "csv_file_name": "most_active_25_movies.csv",
            "csv_content": "\"title\",\"votes\"\n\"Martin Scorseses Killers of the Flower Moon Will Have World Premiere at Cannes Film Festival\",\"2792\"\n\"New 'Spider-Verse' Short Film Coming From Sony Pictures Animation\",\"1589\"\n\"Hollywoods Covid Protocols Get Expiration Date; Vaccine Mandate Will End\",\"151\"\n\"Favorite director hot streak?\",\"53\"\n\"Who else keeps their movie tickets/stubs for collecting purposes as such?\",\"34\"\n\"Late 90s-early 2000s suspense/thrillers\",\"28\"\n\"The LOTR The Return of the King is a great film but the confrontation with the Ghost Army has always puzzled me.\",\"24\"\n\"What are some r/movies tropes?\",\"24\"\n\"'Air' Review - Ben Affleck Returns to Directing with Certified Crowd-Pleaser | SXSW 2023\",\"19\"\n\"What movie trope are you a sucker for?\",\"12\"\n\"Freddy Got Fingered has become my favourite comedy\",\"10\"\n\"What are your top 5 favorite musical moments ever in cinema?\",\"7\"\n\"The Lost World: Jurassic Park; a great film dampened by it's third act?\",\"5\"\n\"Get out - Grandma scene\",\"2\"\n\"Movies with beautiful visuals and music?\",\"2\"\n\"Action movies have lost the plot\",\"0\"\n\"Avatar 2 Ummm did I miss something?\",\"0\"\n\"Brooke Shields' movies are so creepy and inappropriate. Imagine your entire film career being reduced to movies which seemed so exploitative of her.\",\"0\"\n\"Have you completely lost any desire to watch Everything, Everywhere All At Once?\",\"0\"\n\"Hot take: Taxi Driver (in my opinion) is bad\",\"0\"\n\"Rocky Horror or Phantom of the Paradise?\",\"0\"\n\"Thoughts on Tetris?\",\"0\"\n\"What are some weird movie age ratings, like films that dont deserve this very mature age rating or something like that?\",\"0\"\n\"Which movie has better 2 hour non-stop violence? John Wick 4 or Mad Max: Fury road?\",\"0\"\n\"Why do so few American movies let foreign language speaking characters speak their own language? Why does everything have to be in English...\",\"0\"",
            "difficulty": "hard"
        },
        "eval": {
            "eval_types": [
                "program_html"
            ],
            "reference_answers": {},
            "reference_url": "",
            "program_html": [
                {
                    "url": "__GITLAB__/byteblaze/reddit/-/raw/main/most_active_25_movies.csv",
                    "locator": "document.querySelector('pre').outerText",
                    "required_contents": {
                        "must_include": [
                            "\"title\",\"votes\"\n\"Martin Scorseses Killers of the Flower Moon Will Have World Premiere at Cannes Film Festival\",\"2792\"\n\"New 'Spider-Verse' Short Film Coming From Sony Pictures Animation\",\"1589\"\n\"Hollywoods Covid Protocols Get Expiration Date; Vaccine Mandate Will End\",\"151\"\n\"Favorite director hot streak?\",\"53\"\n\"Who else keeps their movie tickets/stubs for collecting purposes as such?\",\"34\"\n\"Late 90s-early 2000s suspense/thrillers\",\"28\"\n\"The LOTR The Return of the King is a great film but the confrontation with the Ghost Army has always puzzled me.\",\"24\"\n\"What are some r/movies tropes?\",\"24\"\n\"'Air' Review - Ben Affleck Returns to Directing with Certified Crowd-Pleaser | SXSW 2023\",\"19\"\n\"What movie trope are you a sucker for?\",\"12\"\n\"Freddy Got Fingered has become my favourite comedy\",\"10\"\n\"What are your top 5 favorite musical moments ever in cinema?\",\"7\"\n\"The Lost World: Jurassic Park; a great film dampened by it's third act?\",\"5\"\n\"Get out - Grandma scene\",\"2\"\n\"Movies with beautiful visuals and music?\",\"2\"\n\"Action movies have lost the plot\",\"0\"\n\"Avatar 2 Ummm did I miss something?\",\"0\"\n\"Brooke Shields' movies are so creepy and inappropriate. Imagine your entire film career being reduced to movies which seemed so exploitative of her.\",\"0\"\n\"Have you completely lost any desire to watch Everything, Everywhere All At Once?\",\"0\"\n\"Hot take: Taxi Driver (in my opinion) is bad\",\"0\"\n\"Rocky Horror or Phantom of the Paradise?\",\"0\"\n\"Thoughts on Tetris?\",\"0\"\n\"What are some weird movie age ratings, like films that dont deserve this very mature age rating or something like that?\",\"0\"\n\"Which movie has better 2 hour non-stop violence? John Wick 4 or Mad Max: Fury road?\",\"0\"\n\"Why do so few American movies let foreign language speaking characters speak their own language? Why does everything have to be in English...\",\"0\""
                        ]
                    }
                }
            ],
            "string_note": ""
        }
    }
]